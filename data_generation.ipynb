{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "import spike_queries\n",
    "import pandas as pd\n",
    "import tqdm\n",
    "import pickle\n",
    "import random\n",
    "import itertools\n",
    "\n",
    "import torch\n",
    "from transformers import BertTokenizer\n",
    "from torch.utils.data import TensorDataset, DataLoader, RandomSampler, SequentialSampler\n",
    "from transformers import AutoTokenizer, AutoModel, AutoConfig\n",
    "from transformers import BertForSequenceClassification, AdamW, BertConfig, BertModel, AutoTokenizer, AutoModel, PreTrainedTokenizerFast\n",
    "import numpy as np\n",
    "from typing import List\n",
    "from torch import nn\n",
    "import pytorch_lightning as pl\n",
    "from pytorch_lightning import Trainer\n",
    "from torch.utils.data import DataLoader\n",
    "from torch.utils.data import Dataset\n",
    "from typing import Dict, Tuple\n",
    "from scipy.spatial.distance import cosine as cosine_distance\n",
    "from collections import defaultdict\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"queries2.txt\", \"r\") as f:\n",
    "    queries = f.readlines()\n",
    "    queries = [l.strip() for l in queries]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i,q in enumerate(queries):\n",
    "    try:\n",
    "        assert len(q.split(\"\\t\")) == 2\n",
    "    except:\n",
    "        print(i, q, len(q.split(\"\\t\")))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i,q in enumerate(queries):\n",
    "    a = q.count(\"arg1:\") == q.count(\"arg2:\") == 1\n",
    "    if not a:\n",
    "        print(i,q)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['<>arg1:virus $infection $causes a <>arg2:condition', '<>arg1:virus $infection, which $causes a <>arg2:condition', '<>arg1:virus $infection $results $in <>arg2:condition', '<>arg1:virus $infection, which $results $in <>arg2:condition', '<>arg2:condition $is $the $result of <>arg1:virus $infection', '<>arg2:condition, which $is $the $result of <>arg1:virus $infection', '<>arg2:condition $is $[l=cause|trigger]caused $by <>arg1:virus $infection', 'as a result of <>arg1:virus $infection, <>arg2:condition $can $develop']\n"
     ]
    }
   ],
   "source": [
    "queries2results = defaultdict(list)\n",
    "id2query = defaultdict(list)\n",
    "\n",
    "for id_and_query in queries:\n",
    "    query,id = id_and_query.split(\"\\t\")\n",
    "    id2query[int(id)].append(query)\n",
    "    \n",
    "print(id2query[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# dataset_name = \"covid19\"\n",
    "# num_results = 100\n",
    "# query_type = \"syntactic\"\n",
    "\n",
    "# for i, q_and_id in tqdm.tqdm(enumerate(queries), total = len(queries)):\n",
    "#     q, id = q_and_id.split(\"\\t\")\n",
    "#     id = int(id)\n",
    "#     try:\n",
    "#         df = spike_queries.perform_query(q, dataset_name, num_results, query_type) #previously: word=Hawaii\n",
    "#         queries2results[id].append(df)\n",
    "#         time.sleep(2)\n",
    "#     except Exception as e:\n",
    "#         print(\"Error\", i+1)\n",
    "#         print(e)\n",
    "        \n",
    "#         continue"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# for id, dfs in queries2results.items():\n",
    "#      for i,df in enumerate(dfs):\n",
    "#          print(id, i)\n",
    "#          queries2results[id][i] = df.dropna(subset=['arg1_first_index',\"arg1_last_index\",\"arg2_first_index\",\"arg2_last_index\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "for id, dfs in queries2results.items():\n",
    "      for i,df in enumerate(dfs):\n",
    "            queries2results[id][i][\"spike_query\"] = id2query[id][i]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# with open(\"queries2results.pickle\", \"wb\") as f:\n",
    "#       pickle.dump(queries2results, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"queries2results.pickle\", \"rb\") as f:\n",
    "    queries2results = pickle.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict_keys([1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50, 51, 52, 53, 54, 55, 56])"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "queries2results.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# queries2results_new = dict()\n",
    "# for k,dfs in queries2results.items():\n",
    "#     if k == 0: continue\n",
    "#     queries2results_new[k] = pd.concat(dfs, axis=0)\n",
    "    \n",
    "# queries2results = queries2results_new"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "ids = set([int(l.split(\"\\t\")[-1]) for l in queries])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [],
   "source": [
    "def add_arguments(sent:str, arg1_start, arg1_end, arg2_start, arg2_end):\n",
    "    \n",
    "        s_lst = sent.split(\" \")\n",
    "        if arg1_start > arg2_start:\n",
    "            arg1_start, arg2_start = arg2_start, arg1_start\n",
    "            arg1_end, arg2_end = arg2_end, arg1_end\n",
    "            arg1_str, arg2_str = \"<<ARG2:\", \"<<ARG1:\"\n",
    "        else:\n",
    "            arg1_str, arg2_str = \"<<ARG1:\", \"<<ARG2:\"\n",
    "        \n",
    "        s_with_args = s_lst[:arg1_start] + [arg1_str] + s_lst[arg1_start:arg1_end+1] + [\">>\"] + s_lst[arg1_end+1:arg2_start] + [arg2_str] + s_lst[arg2_start:arg2_end+1] + [\">>\"] +s_lst[arg2_end+1:]  \n",
    "        #s_with_args = s_lst[:arg1_start] + [arg1_str+s_lst[arg1_ind]] + s_lst[arg1_ind+1:arg2_ind] + [arg2_str+s_lst[arg2_ind]] + s_lst[arg2_ind+1:]\n",
    "        s_with_args = \" \".join(s_with_args).replace(\"ARG1: \", \"ARG1:\").replace(\"ARG2: \", \"ARG2:\")\n",
    "        s_with_args = s_with_args.replace(\" >>\", \">>\")\n",
    "        return s_with_args\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 56/56 [00:08<00:00,  6.52it/s]\n"
     ]
    }
   ],
   "source": [
    "NUM_PAIRS_PER_RELATION = 250\n",
    "\n",
    "data = []\n",
    "\n",
    "for id in tqdm.tqdm(ids): #foreach relation\n",
    "    \n",
    "    pattern_pairs = list(itertools.product(range(len(id2query[id])), repeat=2))\n",
    "    pattern_pairs_different = [(p1,p2) for (p1,p2) in pattern_pairs if p1 != p2]\n",
    "    \n",
    "    sum_pattern = 0\n",
    "    relation_examples = []\n",
    "    \n",
    "    for p1, p2 in pattern_pairs_different:\n",
    "        df1,df2 = queries2results[id][p1], queries2results[id][p2]\n",
    "        if df1.empty or df2.empty: continue\n",
    "            \n",
    "        sentences1, sentences2 = df1[\"sentence_text\"].tolist(), df2[\"sentence_text\"].tolist()\n",
    "        query1, query2 = df1[\"spike_query\"].tolist()[0], df2[\"spike_query\"].tolist()[0]\n",
    "        arg1_first_start, arg1_first_end = df1[\"arg1_first_index\"].tolist(), df1[\"arg1_last_index\"].tolist()\n",
    "        arg2_first_start, arg2_first_end = df1[\"arg2_first_index\"].tolist(), df1[\"arg2_last_index\"].tolist()\n",
    "        arg1_second_start, arg1_second_end = df2[\"arg1_first_index\"].tolist(), df2[\"arg1_last_index\"].tolist()\n",
    "        arg2_second_start, arg2_second_end = df2[\"arg2_first_index\"].tolist(), df2[\"arg2_last_index\"].tolist()\n",
    "        \n",
    "        \n",
    "        all_pair_combinations = list(itertools.product(range(len(df1)), range(len(df2))))\n",
    "        random.shuffle(all_pair_combinations)\n",
    "        for combination in all_pair_combinations[:100]:\n",
    "            ind1, ind2 = combination\n",
    "            \n",
    "            sent1, sent2 = sentences1[ind1], sentences2[ind2]\n",
    "            sent1_arg1_start, sent1_arg1_end = arg1_first_start[ind1], arg1_first_end[ind1]\n",
    "            sent1_arg2_start, sent1_arg2_end = arg2_first_start[ind1], arg2_first_end[ind1]\n",
    "            sent2_arg1_start, sent2_arg1_end = arg1_second_start[ind2], arg1_second_end[ind2]\n",
    "            sent2_arg2_start, sent2_arg2_end = arg2_second_start[ind2], arg2_second_end[ind2]\n",
    "            sent1_with_args = add_arguments(sent1, sent1_arg1_start, sent1_arg1_end, sent1_arg2_start, sent1_arg2_end)\n",
    "            sent2_with_args = add_arguments(sent2, sent2_arg1_start, sent2_arg1_end, sent2_arg2_start, sent2_arg2_end)\n",
    "            d = {\"first\": sent1_with_args, \"second\": sent2, \"second_with_arguments\": sent2_with_args, \"query_first\": query1, \"query_second\": query2, \n",
    "                 \"first_arg1\": (sent1_arg1_start, sent1_arg1_end+1), \"first_arg2\": (sent1_arg2_start, sent1_arg2_end+1), \n",
    "                 \"second_arg1\": (sent2_arg1_start, sent2_arg1_end+1),\n",
    "                 \"second_arg2\": (sent2_arg2_start, sent2_arg2_end+1)}\n",
    "            relation_examples.append(d)\n",
    "    \n",
    "    random.shuffle(relation_examples)\n",
    "    relation_examples = relation_examples[:NUM_PAIRS_PER_RELATION]\n",
    "    data.extend(relation_examples)\n",
    "    \n",
    "random.shuffle(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"data.pickle\", \"wb\") as f:\n",
    "    pickle.dump(data, f)\n",
    "    \n",
    "import json\n",
    "\n",
    "with open(\"data.txt\", \"w\") as f:\n",
    "    for d in data:\n",
    "        first, second = d[\"first\"], d[\"second_with_arguments\"]\n",
    "        first_arg1 = d[\"first_arg1\"]\n",
    "        first_arg2 = d[\"first_arg2\"]\n",
    "        second_arg1 = d[\"second_arg1\"]\n",
    "        second_arg2 = d[\"second_arg2\"]\n",
    "        \n",
    "        elems = [first, second, first_arg1, first_arg2, second_arg1, second_arg2]\n",
    "        keys = [\"first\", \"second\", \"first_arg1\", \"first_arg2\"]\n",
    "        \n",
    "        f.write(json.dumps(d) + \"\\n\")\n",
    "        #f.write(d[\"first\"] + \"\\t\" + d[\"second\"] + \"\\t\" + d[\"query\"] + \"\\t\" + \"-\".join(d[\"first_arg1\"])+ \"\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<<ARG1:Virus>> was isolated from <<ARG2:the lung of one of two TGEV-inoculated piglets>> . (0, 1) (4, 12)\n",
      "<<ARG1:Bacteremia>> was documented in 108 patients ( <<ARG2:15 %>> ) .\n",
      "---------------\n",
      "<>arg1:something $was first $isolated $from <>arg2:soil\n",
      "<>arg1:something $was first $documented $in <>arg2:soil\n",
      "============================\n",
      "The reversal of burden of proof demanded by the precautionary principle is a dialectical stipulation about the party in inquiry which should assume responsibility for demonstrating that <<ARG1:a particular agent>> or activity poses no risk to health or to <<ARG2:the environment>> . (27, 30) (39, 41)\n",
      "67 On the contrary , Tamm and colleagues 68 showed in their series that <<ARG1:CMV pneumonitis>> , when treated with GCV , is not a risk factor for <<ARG2:BOS>> and does not affect survival .\n",
      "---------------\n",
      "<>arg1:asthma $poses $no $risk for <>arg2:asthma\n",
      "<>arg1:asthma $is $not $a $risk $factor for <>arg2:asthma\n",
      "============================\n",
      "If the system incorporates control strategies , then <<ARG1:the corresponding quantity>> is named control reproduction number and usually denoted by <<ARG2:R C>> ( obviously , R C < R 0 ) . (8, 11) (20, 22)\n",
      "Synthesis and <<ARG1:transformations of 6,10b-dihydropyrazolo-[1,5-c]quinazoline-5(1H)-thiones>> 112 was described by <<ARG2:Hull>> and Swain57 as a part of a series of works devoted to the study of the interaction of thiophosgene with heterocyclic compounds .\n",
      "---------------\n",
      "<>arg1:something was $named $by <>arg2:someone\n",
      "<>arg1:something was $[w=described|reported|observed]described $by <>arg2:someone\n",
      "============================\n",
      "The identification of resistant variants that maintain genome output with little impact on specific infectivity suggests that inhibition of <<ARG2:RdRp activity>> is the main mechanism of action for <<ARG1:5FU>> . (28, 29) (19, 21)\n",
      "The mechanism of action for <<ARG1:quicklime>> is <<ARG2:the resulting exothermic reaction>> that occurs when the chemical interacts with water and its ability to increase pH levels .\n",
      "---------------\n",
      "<>arg2:inhibition of kinases is the $mechanism $of $action of <>arg1:[e=CHEMICAL|SIMPLE_CHEMICAL]paracetamol\n",
      "The $mechanism $of $action of <>arg1:paracetamol is <>arg2:activation of glocuse\n",
      "============================\n",
      "Other virulence factors included in Table 2 are <<ARG1:iss>> , which encodes an increased serum survival protein and is associated with non-bloody diarrhoea as well as <<ARG2:extra-intestinal pathogenic infections>> [ 34 ] , subAB , which is an emerging pathogenic factor among eae negative human pathogenic STEC isolates [ 17 ] , and astA encoding a heat-stable enterotoxin EAST1 that is found mostly in enterohaemorrhagic and enteroaggregative E. coli [ 35 ] . (8, 9) (26, 29)\n",
      "Uncertainty remains about whether <<ARG1:immunotherapies>> increase the risk of infection with severe acute respiratory syndrome coronavirus 2 ( SARS-CoV-2 ) or increase the risk of severe disease and death upon <<ARG2:infection>> .\n",
      "---------------\n",
      "<>arg1:something, that improved $survival in <>arg2:[e=DISEASE|PATHOLOGICAL_FORMATION|CANCER]something\n",
      "<>arg1:something can $[w=decrease|prevent|increase]decrease $death rates in <>arg2:[e=DISEASE|CANCER|PATHOLOGICAL_FORMATION]something\n",
      "============================\n",
      "Our study reveals an evolutionarily conserved mechanism of protein-protein interaction between <<ARG1:host>> and <<ARG2:virus>> that can serve as a broad-spectrum antiviral target . (11, 12) (13, 14)\n",
      "In particular , <<ARG1:the viral surface antigen S-host antibodies>> ( anti-Spike IgG ) complex promotes the FcR-mediated internalization of the virus in macrophages ( ADE ) and activates intracellular signaling of <<ARG2:FcR.>> This interaction results in the up-regulation and release of the pro-inflammatory cytokines responsible for severe lung disease .\n",
      "---------------\n",
      "$protein-protein $interaction between <>arg1:something :and <>arg2:something\n",
      "the <>arg1:[e=PROTEIN]A $[l=influence|inhibit|activate|regulate]activate <>arg2:[e=PROTEIN]B\n",
      "============================\n",
      "Aging is characterized by a general condition of low-grade inflammation , also connected to chronic inflammation of <<ARG2:the brain>> ( <<ARG1:neuroinflammation>> ) , which is involved in frailty syndrome and contributes to several age-associated diseases , including neurodegenerative and neuropsychiatric disorders . (20, 21) (17, 19)\n",
      "<<ARG2:Liver involvement>> in <<ARG1:immunodeficiency>> and miscellaneous disorders precede the final section on anatomical anomalies .\n",
      "---------------\n",
      "<>arg1:[e=DISEASE]flu, which may $[l]involve the <>arg2:[e=ORGAN]liver\n",
      "<>arg2:[e=ORGAN]liver $involvement in <>arg1:[e=DISEASE]flu\n",
      "============================\n",
      "In farrow-tofinish ( FF ) systems , in which piglets remain until slaughter , transmission of infection from <<ARG1:sows>> to <<ARG2:piglets>> and from older to younger pigs occurs . (18, 19) (20, 21)\n",
      "In the first stage of an infectious epidemic , <<ARG1:a small number of infected people>> begins to transmit the disease to <<ARG2:a large population>> .\n",
      "---------------\n",
      "$transmission $of something $from <>arg1:[e]bats $to <>arg2:someone\n",
      "<>arg1:someone can $[l=transmit|cross]transmit something $to <>arg2:someone\n",
      "============================\n",
      "Pharyngeal swab specimen of the neonate was sent for examination 3 days after birth , and was positive for novel coronavirus nucleic acid by fluorescence reverse transcript polymerase chain reaction.@*Conclusion@#2019-nCoV may be transmitted vertically from <<ARG1:mother>> to <<ARG2:child>> . (35, 36) (37, 38)\n",
      "In farrow-tofinish ( FF ) systems , in which piglets remain until slaughter , transmission of infection from <<ARG1:sows>> to <<ARG2:piglets>> and from older to younger pigs occurs .\n",
      "---------------\n",
      "something can be $[l=transmit|cross]transmitted $from <>arg1:something $to <>arg2:something\n",
      "$transmission $of something $from <>arg1:[e]bats $to <>arg2:someone\n",
      "============================\n",
      "The first <<ARG2:targeted>> recombination system was developed for <<ARG1:mouse hepatitis virus>> ( MHV ) , and used a temperature-sensitive trait to select and screen for template switching between the original temperature-sensitive virus containing a mutation in the nucleocapsid gene and the new recombinant virus that had lost the temperaturesensitive phenotype due to recombination ( Koetzner et al. , 1992 ) . (8, 11) (2, 3)\n",
      "Carmen Ledesma-Feliciano ( Colorado State University , Fort Collins , CO , USA ) presented work on a vaccine system and found that Feline foamy virus Bet can be replaced by <<ARG1:feline immunodeficiency virus Vif>> in a <<ARG2:novel>> chimeric vaccine system .\n",
      "---------------\n",
      "the <>arg2:immune $system is influenced from <>arg1:flu $virus\n",
      "<>arg1:[e=ORGANISM|ORGANISM_SUBDIVISION|ORGANISM_SUBSTANCE]flu interacts with the <>arg2:immune $system\n",
      "============================\n",
      "Seminal studies by Albert Sabin , dating from the WWII era [ 148 ] , have demonstrated that volunteers exposed to <<ARG1:DENV>> showed long-lived homotypic immunity but short-lived cross-protection against <<ARG2:viruses of a different serotype>> . (21, 22) (30, 35)\n",
      "Moreover , the ability of TNF/CHP nanoparticles to stimulate comparatively balanced systemic as well as mucosal immune responses makes <<ARG1:them>> a potentially promising vaccine adjuvant for inducing immunity against <<ARG2:infectious pathogens>> .\n",
      "---------------\n",
      "patients treated with <>arg1:something $showed $[l=immunity|resistence]immunity $against <>arg2:something\n",
      "<>arg1:something $[l=induce|trigger|cause|create]induces $[l=immunity|resistence]immunity $against <>arg2:something\n",
      "============================\n",
      "Moreover , SARS-CoV-2 could be affecting other organs or systems where ACE2 is expressed , including the central <<ARG2:nervous>> system , where <<ARG1:other coronaviruses>> such as SARS have shown the ability to infect certain brain areas entering by the olfactory bulb . (22, 24) (18, 19)\n",
      "For the reasons stated above and because Zika virus had been circulating 146 in the Americas for at least two years before it was reported in the Dominican Republic ( Faria et al. , 2016 , 147 2017 ) , this observation suggested that <<ARG1:Zika virus>> was already circulating in those provinces before the 148 <<ARG2:national>> reporting system was implemented at the beginning of January .\n",
      "---------------\n",
      "<>arg1:[e=ORGANISM|ORGANISM_SUBDIVISION|ORGANISM_SUBSTANCE]flu interacts with the <>arg2:immune $system\n",
      "<>arg1:flu $virus interacts with the <>arg2:immune $system\n",
      "============================\n",
      "The pro-oncogenic function of <<ARG1:NCoR-HDAC3 complex>> was first documented in <<ARG2:pro-myelocytic leukemia-retinoic acid receptor-α>> ( PML-RARα ) , pro-myelocytic leukemia zinc-finger retinoic acid receptor α ( PLZF-RARα ) , and AML1-ETO leukemias . (4, 6) (10, 14)\n",
      "<<ARG1:The virus>> was first detected in <<ARG2:December>> 2019 in Wuhan , China 1 and quickly spread to other continents within 2 - 3 months .\n",
      "---------------\n",
      "<>arg1:something $was first $documented $in <>arg2:soil\n",
      "<>arg1:something $was $first $detected $in <>arg2:soil\n",
      "============================\n",
      "In addition to inhibiting <<ARG2:IRF-3 activation>> and type I IFN-induced signaling , C6-induced degradation of <<ARG1:HDAC5>> joins the increasing panoply of functions encoded by VACV to evade viral restriction . (15, 16) (4, 6)\n",
      "Synthetic peptides corresponding to the calmodulin like binding site ( CLBS ) as well as <<ARG1:the calmodulin-binding site ( CBS ) of the enzyme>> prevented gangliosides from inhibiting <<ARG2:the enzyme activity>> .\n",
      "---------------\n",
      "the <>arg1:[e=PROTEIN]A $[l=influence|inhibit|activate|regulate]activate <>arg2:[e=PROTEIN]B\n",
      "the $enzyme <>arg1:A $[l]inhibits the $enzyme <>arg2:B\n",
      "============================\n",
      "Our studies have shown that a major mechanism of both retrograde and anterograde axonal transport of neurovirulent MHV is mediated by spike protein and further experiments will focus on identifying the molecular mechanisms by which <<ARG1:the DM virus>> interacts with the <<ARG2:axonal>> transport system and whether specific interventions targeting the transport system can delay or prevent the DM strain-induced axonal loss and demyelination . (35, 38) (41, 42)\n",
      "The best characterized conventional <<ARG2:RNA-capping>> system is that exemplified by <<ARG1:the dsDNA virus vaccinia virus>> , which expresses a multifunctional mRNA capsynthesizing enzyme ( D1 ) containing RTPase , GTase and N7MTase domains 24 .\n",
      "---------------\n",
      "<>arg1:flu $virus interacts with the <>arg2:immune $system\n",
      "the <>arg2:immune $system is influenced from <>arg1:flu $virus\n",
      "============================\n",
      "Also , <<ARG1:a high blood eosinophil count>> may be a sign of <<ARG2:an increased risk of persistent wheezing>> and atopy [ 35 ] . (2, 7) (12, 18)\n",
      "Additionally , decreased <<ARG1:peak diastolic blood pressures>> may be an early indication of <<ARG2:an HC>> in bariatric patients .\n",
      "---------------\n",
      "$high $blood <>arg1:glocuse is a $sign of <>arg2:something\n",
      "low $blood <>arg1:glocuse is a $[l=sign|indication|symptom]sign of <>arg2:something\n",
      "============================\n",
      "<<ARG1:A virus>> with about 50 % nucleotide sequence identity with mammalian HEVs , called avian HEV , was isolated from <<ARG2:chickens>> affected by the hepatitis-splenomegaly syndrome Huang et al. , 2004 ) . (0, 2) (20, 21)\n",
      "Novel coronavirus disease ( <<ARG1:COVID-19>> ) was first detected in Wuhan City , <<ARG2:Hubei Province>> in China , at the end of 2019 [ 1 ] .\n",
      "---------------\n",
      "<>arg1:something $was first $isolated $from <>arg2:soil\n",
      "<>arg1:something $was $first $detected $in <>arg2:soil\n",
      "============================\n",
      "<<ARG1:Chest radiograph>> can show signs of adult <<ARG2:respiratory>> distress syndrome ( ARDS ) . (0, 2) (7, 8)\n",
      "Canine infectious respiratory disease ( CIRD ) , previously known as kennel cough , is an endemic <<ARG2:respiratory>> syndrome , which is frequently observed in densely <<ARG1:housed environments>> , such as kennels and animal shelters , due to overpopulation and continuous introduction of pathogens .\n",
      "---------------\n",
      "infected <>arg1:patients $show $signs $of <>arg2:[entity]respiratory illness\n",
      "<>arg2:[entity]respiratory illness $is $observed in infected <>arg1:patients\n",
      "============================\n",
      "Newer aircraft , such as the Boeing 787 and <<ARG1:Airbus A350>> , are manufactured from <<ARG2:composite material>> enabling them to operate at lower cabin altitudes of around 5000 - 6000 feet . (9, 11) (15, 17)\n",
      "JNJ-54257099 -As an NS5B inhibitor , <<ARG1:JNJ-54257099>> is <<ARG2:a cyclic phosphate ester derivative>> in the class of 2'-deoxy-2'-spirooxetane uridine nucleotide prodrugs ( Jonckers et al. , 2016 ) .\n",
      "---------------\n",
      "<>arg1:something is $manufactured $from <>arg2:something\n",
      "<>arg1:it $is $a <>arg2:purine $derivative\n",
      "============================\n",
      "and <<ARG1:enteric tract cultures>> have been used to study <<ARG2:influenza virus infections>> in their natural target cells [ 23 ] [ 24 ] [ 25 ] . (1, 4) (9, 12)\n",
      "SFTSV was isolated from an acutely infected patient 's serum and propagated in Vero cells .. The supernatant was diluted into tenfold serial dilutions with <<ARG1:DMEM>> , which was used to inoculate <<ARG2:Vero cells>> in 12-well plates .\n",
      "---------------\n",
      "<>arg1:[e=CELL_LINE]something is used to $[l=simulate|study|develop|measure|propagate|investigate|detect|isolate]study <>arg2:[e=DISEASE]something\n",
      "<>arg1:[e=DISEASE|ORGANISM|ORGANISM_SUBSTANCE]something, which was $[l=perform|simulate|show|use|observe|measure|examine|test|establish|determine|assess|make|diagnose|utilize|isolate]studied using <>arg2:[e=CELL_LINE]something\n",
      "============================\n"
     ]
    }
   ],
   "source": [
    "for i in range(20):\n",
    "    print(data[i][\"first\"], data[i][\"first_arg1\"], data[i][\"first_arg2\"])\n",
    "    print(data[i][\"second_with_arguments\"])\n",
    "    print(\"---------------\")\n",
    "    print(data[i][\"query_first\"])\n",
    "    print(data[i][\"query_second\"])\n",
    "    print(\"============================\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "12896\n"
     ]
    }
   ],
   "source": [
    "print(len(data))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
