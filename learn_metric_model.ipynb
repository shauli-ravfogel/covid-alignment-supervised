{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "import spike_queries\n",
    "import pandas as pd\n",
    "import tqdm\n",
    "import pickle\n",
    "import random\n",
    "import itertools\n",
    "\n",
    "import torch\n",
    "from transformers import BertTokenizer\n",
    "from torch.utils.data import TensorDataset, DataLoader, RandomSampler, SequentialSampler\n",
    "from transformers import AutoTokenizer, AutoModel, AutoConfig\n",
    "from transformers import BertForSequenceClassification, AdamW, BertConfig, BertModel, AutoTokenizer, AutoModel, PreTrainedTokenizerFast\n",
    "import numpy as np\n",
    "from typing import List\n",
    "from torch import nn\n",
    "import pytorch_lightning as pl\n",
    "from pytorch_lightning import Trainer\n",
    "from torch.utils.data import DataLoader\n",
    "from torch.utils.data import Dataset\n",
    "from typing import Dict, Tuple\n",
    "from scipy.spatial.distance import cosine as cosine_distance\n",
    "from collections import defaultdict\n",
    "from nltk import ngrams as get_ngrams\n",
    "from termcolor import colored"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"queries2.txt\", \"r\") as f:\n",
    "    queries = f.readlines()\n",
    "    queries = [l.strip() for l in queries]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# for i,q in enumerate(queries):\n",
    "#     try:\n",
    "#         assert len(q.split(\"\\t\")) == 2\n",
    "#     except:\n",
    "#         print(i, q, len(q.split(\"\\t\")))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# for i,q in enumerate(queries):\n",
    "#     a = q.count(\"arg1:\") == q.count(\"arg2:\") == 1\n",
    "#     if not a:\n",
    "#         print(i,q)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# queries2results = defaultdict(list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# dataset_name = \"covid19\"\n",
    "# num_results = 100\n",
    "# query_type = \"syntactic\"\n",
    "\n",
    "# for i, q_and_id in tqdm.tqdm(enumerate(queries), total = len(queries)):\n",
    "#     q, id = q_and_id.split(\"\\t\")\n",
    "#     id = int(id)\n",
    "#     try:\n",
    "#         df = spike_queries.perform_query(q, dataset_name, num_results, query_type) #previously: word=Hawaii\n",
    "#         queries2results[id].append(df)\n",
    "#         time.sleep(2)\n",
    "#     except Exception as e:\n",
    "#         print(\"Error\", i+1)\n",
    "#         print(e)\n",
    "        \n",
    "#         continue"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# for id, dfs in queries2results.items():\n",
    "#     for i,df in enumerate(dfs):\n",
    "#         print(id, i)\n",
    "#         queries2results[id][i] = df.dropna(subset=['arg1_first_index',\"arg1_last_index\",\"arg2_first_index\",\"arg2_last_index\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# len(queries2results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# with open(\"queries2results.pickle\", \"wb\") as f:\n",
    "#      pickle.dump(queries2results, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"queries2results.pickle\", \"rb\") as f:\n",
    "    queries2results = pickle.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# queries2results.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# queries2results_new = dict()\n",
    "# for k,dfs in queries2results.items():\n",
    "#     if k == 0: continue\n",
    "#     queries2results_new[k] = pd.concat(dfs, axis=0)\n",
    "    \n",
    "# queries2results = queries2results_new"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# df = queries2results[12]\n",
    "# len(df)\n",
    "# df2 = df.dropna(subset=['arg1_first_index',\"arg1_last_index\",\"arg2_first_index\",\"arg2_last_index\"])\n",
    "# df2[\"arg2_first_index\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ids = set([int(l.split(\"\\t\")[-1]) for l in queries])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# data = []\n",
    "# for id in ids:\n",
    "#     results = queries2results[id]\n",
    "#     sents, arg1_first, arg2_first = results[\"sentence_text\"].tolist(), results[\"arg1_first_index\"].tolist(), results[\"arg2_first_index\"].tolist()\n",
    "#     arg1_last, arg2_last = results[\"arg1_last_index\"].tolist(), results[\"arg2_last_index\"].tolist()\n",
    "    \n",
    "#     sents_with_args = []\n",
    "#     for s,arg1_ind,arg2_ind, arg1_ind_last, arg2_ind_last in zip(sents,arg1_first,arg2_first, arg1_last, arg2_last):\n",
    "#         s_lst = s.split(\" \")\n",
    "#         if arg1_ind > arg2_ind:\n",
    "#             arg1_ind, arg2_ind = arg2_ind, arg1_ind\n",
    "#             arg1_ind_last, arg2_ind_last = arg2_ind_last, arg1_ind_last\n",
    "#             arg1_str, arg2_str = \"ARG2:\", \"ARG1:\"\n",
    "#         else:\n",
    "#             arg1_str, arg2_str = \"ARG1:\", \"ARG2:\"\n",
    "#         s_with_args = s_lst[:arg1_ind] + [arg1_str+s_lst[arg1_ind]] + s_lst[arg1_ind+1:arg2_ind] + [arg2_str+s_lst[arg2_ind]] + s_lst[arg2_ind+1:]\n",
    "#         s_with_args = \" \".join(s_with_args)\n",
    "#         sents_with_args.append({\"sent\": s_with_args, \"start_1\": arg1_ind, \"start_2\": arg2_ind, \"end_1\": arg1_ind_last,\n",
    "#                                \"end_2\": arg2_ind_last})\n",
    "    \n",
    "#     max_number_of_pairs = 450\n",
    "#     pairs = list(itertools.product(sents_with_args, repeat=2))\n",
    "#     print(id, len(pairs))\n",
    "#     random.shuffle(pairs)\n",
    "#     for pair in pairs[:max_number_of_pairs]:\n",
    "#         data.append({\"first\": pair[0][\"sent\"], \"second\": pair[1][\"sent\"], \"query\": q, \"first_arg1\": (pair[0][\"start_1\"], pair[0][\"end_1\"]),\n",
    "#                     \"first_arg2\": (pair[0][\"start_2\"], pair[0][\"end_2\"]), \"second_arg1\": (pair[1][\"start_1\"], pair[1][\"end_1\"]),\n",
    "#                    \"second_arg2\": (pair[1][\"start_2\"], pair[1][\"end_2\"])})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# len(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# random.shuffle(data)\n",
    "# data[0]\n",
    "\n",
    "# with open(\"data.pickle\", \"wb\") as f:\n",
    "#     pickle.dump(data, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"data.pickle\", \"rb\") as f:\n",
    "    data = pickle.load(f)\n",
    "    \n",
    "    \n",
    "with open(\"data_dev.pickle\", \"rb\") as f:\n",
    "    data_dev = pickle.load(f)\n",
    "    \n",
    "with open(\"data_train.pickle\", \"rb\") as f:\n",
    "    data_train = pickle.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "#data = data[:10000]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import json\n",
    "\n",
    "# with open(\"data.txt\", \"w\") as f:\n",
    "#     for d in data:\n",
    "#         first, second = d[\"first\"], d[\"second\"]\n",
    "#         first_arg1 = d[\"first_arg1\"]\n",
    "#         first_arg2 = d[\"first_arg2\"]\n",
    "#         second_arg1 = d[\"second_arg1\"]\n",
    "#         second_arg2 = d[\"second_arg2\"]\n",
    "        \n",
    "#         elems = [first, second, first_arg1, first_arg2, second_arg1, second_arg2]\n",
    "#         keys = [\"first\", \"second\", \"first_arg1\", \"first_arg2\"]\n",
    "        \n",
    "#         f.write(json.dumps(d) + \"\\n\")\n",
    "#         #f.write(d[\"first\"] + \"\\t\" + d[\"second\"] + \"\\t\" + d[\"query\"] + \"\\t\" + \"-\".join(d[\"first_arg1\"])+ \"\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'first': '<<ARG1:Griseofulvin>> should not be used to treat <<ARG2:dermatophytosis>> , because it has been associated with bone marrow suppression in FIV-positive cats.79 Recombinant human erythropoietin or darbepoetin may be useful for some cats with nonregenerative anemia and does not appear to increase viral load through activation of transcription of latent virus.80 Although recombinant human granulocyte colony stimulating factor ( G-CSF ) can increase neutrophil counts in cats infected with FIV , antibodies can develop within a few weeks that cross-react with endogenous G-CSF .', 'second': 'Vitamin C is contraindicated in liver disease associated with transition metal accumulation ( copper , iron ) because it may enhance oxidative injury .', 'second_with_arguments': '<<ARG1:Vitamin C>> is contraindicated in <<ARG2:liver disease>> associated with transition metal accumulation ( copper , iron ) because it may enhance oxidative injury .', 'query_first': '<>arg1:[e=CHEMICAL|SIMPLE_CHEMICAL]paracetamol $should $not $be $used to $treat <>arg2:[e=DISEASE|PATHOLOGICAL_FORMATION]asthma', 'query_second': '<>arg1:something $is $contraindicated in <>arg2:[e=DISEASE]asthma', 'first_arg1': (0, 0), 'first_arg2': (7, 7), 'second_arg1': (0, 1), 'second_arg2': (5, 6), 'first_arg1_words': ['dermatophytosis'], 'first_arg2_words': ['dermatophytosis'], 'second_arg1_words': ['Vitamin', 'C'], 'second_arg2_words': ['liver', 'disease'], 'query_id': 6}\n"
     ]
    }
   ],
   "source": [
    "global count\n",
    "count = 0\n",
    "global total\n",
    "total = 0\n",
    "\n",
    "print(data[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "class BertModel(pl.LightningModule):\n",
    "\n",
    "    def __init__(self, train_dataset: Dataset, dev_dataset: Dataset, batch_size, device: str, mode: str = \"eval\"):\n",
    "        \n",
    "        super().__init__()\n",
    "        \n",
    "        self.device = device\n",
    "        config = AutoConfig.from_pretrained('allenai/scibert_scivocab_uncased', output_hidden_states=True)\n",
    "        self.tokenizer = AutoTokenizer.from_pretrained('allenai/scibert_scivocab_uncased')\n",
    "        self.model = AutoModel.from_pretrained('allenai/scibert_scivocab_uncased', config=config)    \n",
    "        self.train_dataset = train_dataset\n",
    "        self.dev_dataset = dev_dataset\n",
    "        self.linear_arg1_1 = torch.nn.Linear(768, 64)\n",
    "        self.linear_arg2_1 = torch.nn.Linear(768, 64)\n",
    "        self.linear_arg1_2 = torch.nn.Linear(768, 64)\n",
    "        self.linear_arg2_2 = torch.nn.Linear(768, 64)\n",
    "        \n",
    "        if mode == \"eval\":\n",
    "            \n",
    "            self.model.eval()\n",
    "        else:\n",
    "            self.model.train()\n",
    "        \n",
    "        for p in self.model.parameters():\n",
    "            p.requires_grad = True\n",
    "        for p in self.model.encoder.layer[-1].parameters():\n",
    "            p.requires_grad = True\n",
    "        for p in self.model.encoder.layer[-2].parameters():\n",
    "            p.requires_grad = True       \n",
    "        for p in self.model.encoder.layer[-3].parameters():\n",
    "            p.requires_grad = True    \n",
    "        for p in self.model.encoder.layer[-4].parameters():\n",
    "            p.requires_grad = True \n",
    "            \n",
    "        for p in self.model.embeddings.parameters():\n",
    "            p.requires_grad = True\n",
    "            \n",
    "        self.linear_arg1_1.requires_grad = True\n",
    "        self.linear_arg2_1.requires_grad = True\n",
    "        self.linear_arg1_2.requires_grad = True\n",
    "        self.linear_arg2_2.requires_grad = True\n",
    "        \n",
    "    \n",
    "        self.train_gen = torch.utils.data.DataLoader(self.train_dataset, batch_size=batch_size, drop_last=False, shuffle=True)\n",
    "        self.dev_gen = torch.utils.data.DataLoader(self.dev_dataset, batch_size=batch_size, drop_last=False, shuffle=False)\n",
    "        self.acc = None\n",
    "\n",
    "        \n",
    "    def tokenize(self, original_sentence: List[str]) -> Tuple[List[str], Dict[int, int]]:\n",
    "\n",
    "        \"\"\"\n",
    "        Parameters\n",
    "        ----------\n",
    "        Returns\n",
    "        -------\n",
    "        bert_tokens: The sentence, tokenized by BERT tokenizer.\n",
    "        orig_to_tok_map: An output dictionary consisting of a mapping (alignment) between indices in the original tokenized sentence, and indices in the sentence tokenized by the BERT tokenizer. See https://github.com/google-research/bert\n",
    "        \"\"\"\n",
    "\n",
    "        bert_tokens = [\"[CLS]\"]\n",
    "        orig_to_tok_map = {}\n",
    "        tok_to_orig_map = {}\n",
    "        has_subwords = False\n",
    "        is_subword = []\n",
    "\n",
    "        for i, w in enumerate(original_sentence):\n",
    "            tokenized_w = self.tokenizer.tokenize(w)\n",
    "            has_subwords = len(tokenized_w) > 1\n",
    "            is_subword.append(has_subwords)\n",
    "            bert_tokens.extend(tokenized_w)\n",
    "\n",
    "            orig_to_tok_map[i] = len(bert_tokens) - 1\n",
    "\n",
    "        tok_to_orig_map = {}\n",
    "\n",
    "        bert_tokens.append(\"[SEP]\")\n",
    "        tok_to_orig_map = get_tok_to_orig_map(orig_to_tok_map, len(original_sentence), len(bert_tokens))        \n",
    "        indexed_tokens = self.tokenizer.convert_tokens_to_ids(bert_tokens)\n",
    "        tokens_tensor = torch.tensor([indexed_tokens]).to(self.device)\n",
    "\n",
    "        return (bert_tokens, orig_to_tok_map, tok_to_orig_map, tokens_tensor)\n",
    "    \n",
    "    \n",
    "    def forward(self, x):\n",
    "        \n",
    "        outputs = self.model(x)\n",
    "        states = outputs[0][0] #[seq_len, 768]\n",
    "        return states\n",
    "    \n",
    "    def forward_with_loss_calculation2(self, bert_tokens, x, range_sent1, range_sent2, orig_to_tok_map, l, l_tokens,\n",
    "                                      metric = \"l2\", n_max = 5, alpha = 1, mode = \"train\", normalize=False, nb=0):\n",
    "        \n",
    "        range_sent2[0][0] -= l_tokens\n",
    "        range_sent2[0][1] -= l_tokens\n",
    "        range_sent2[1][0] -= l_tokens\n",
    "        range_sent2[1][1] -= l_tokens\n",
    "        \n",
    "        idx_arg1_all, idx_arg2_all, all_ngrams = None, None, None\n",
    "        \n",
    "        x_1, x_2 = x[0,:l_tokens], x[0,l_tokens:]\n",
    "        x_1, x_2 = torch.unsqueeze(x_1,0), torch.unsqueeze(x_2,0)\n",
    "        \n",
    "        outputs_1, outputs_2 = self.model(x_1), self.model(x_2)\n",
    "        states_1 = outputs_1[0][0] #[seq_len, 768]\n",
    "        states_2 = outputs_2[0][0] #[seq_len, 768]\n",
    "        \n",
    "        if metric == \"cosine\" or normalize:\n",
    "            states_1 = states_1 / (torch.norm(states_1, dim = 1, keepdim = True)+1e-8)\n",
    "            states_2 = states_2 / (torch.norm(states_2, dim = 1, keepdim = True)+1e-8)\n",
    "        \n",
    "        states_1 = self.linear_arg1_1(states_1)\n",
    "        states_2 = self.linear_arg1_2(states_2)\n",
    "        states = torch.cat([states_1, states_2], dim = 0)\n",
    "        \n",
    "        arg1_sent1, arg2_sent1 = range_sent1\n",
    "        arg1_sent2, arg2_sent2 = range_sent2\n",
    "        \n",
    "        sent1_arg1_vec, sent1_arg2_vec = states_1[arg1_sent1[0]:arg1_sent1[1]].mean(dim=0), states_1[arg2_sent1[0]:arg2_sent1[1]].mean(dim=0)\n",
    "        sent2_arg1_vec, sent2_arg2_vec = states_2[arg1_sent2[0]:arg1_sent2[1]].mean(dim=0), states_2[arg2_sent2[0]:arg2_sent2[1]].mean(dim=0)        \n",
    "        \n",
    "        all_false_ngrams_ranges = get_all_ngrams_spans(len(states_2), [arg1_sent2, arg2_sent2], start_ind = 0,\n",
    "                                                      n_max = n_max)      \n",
    "        negatives = [states_2[ngram[0]:ngram[1]].mean(dim=0) for ngram in all_false_ngrams_ranges]\n",
    "        negatives_arg1 = negatives + [sent2_arg2_vec]\n",
    "        negatives_arg2 = negatives + [sent2_arg1_vec]\n",
    "        negatives_arg1 = torch.stack(negatives_arg1).to(self.device)\n",
    "        negatives_arg2 = torch.stack(negatives_arg2).to(self.device)\n",
    "        \n",
    "\n",
    "        if mode == \"eval\":\n",
    "            all_ngrams = get_all_ngrams_spans(len(states), [], start_ind = l_tokens,\n",
    "                                                      n_max = n_max)\n",
    "            ngrams = [states[ngram[0]:ngram[1]].mean(dim=0) for ngram in all_ngrams]\n",
    "            ngrams = torch.stack(ngrams).to(self.device)\n",
    "        \n",
    "        \n",
    "        if metric == \"l2\":\n",
    "            dists_arg1 = torch.sqrt(((negatives_arg1-sent1_arg1_vec)**2).sum(dim = 1))\n",
    "            dists_arg2 = torch.sqrt(((negatives_arg2-sent1_arg2_vec)**2).sum(dim = 1))\n",
    "            dist_arg1_gold = (sent1_arg1_vec - sent2_arg1_vec).norm()\n",
    "            dist_arg2_gold = (sent1_arg2_vec - sent2_arg2_vec).norm()\n",
    "            if mode == \"eval\":\n",
    "                dist_arg1_all = torch.sqrt(((ngrams-sent1_arg1_vec)**2).sum(dim = 1))\n",
    "                dist_arg2_all = torch.sqrt(((ngrams-sent1_arg2_vec)**2).sum(dim = 1))\n",
    "                idx_arg1_all = torch.argsort(dist_arg1_all).detach().cpu().numpy()\n",
    "                idx_arg2_all = torch.argsort(dist_arg2_all).detach().cpu().numpy()   \n",
    "                \n",
    "        elif metric == \"cosine\":\n",
    "            dists_arg1 = 1 - negatives_arg1@sent1_arg1_vec.T\n",
    "            dists_arg2 = 1 - negatives_arg2@sent1_arg2_vec.T\n",
    "            dist_arg1_gold = 1 - sent1_arg1_vec@sent2_arg1_vec.T\n",
    "            dist_arg2_gold = 1 - sent1_arg2_vec@sent2_arg2_vec.T\n",
    "        \n",
    "        idx_arg1 = torch.argsort(dists_arg1).detach().cpu().numpy()\n",
    "        idx_arg2 = torch.argsort(dists_arg2).detach().cpu().numpy()\n",
    "        l = max(int(len(negatives)*0.3),1)\n",
    "        k = random.choice(range(min(len(negatives), 4))) if np.random.random() < 0.5 else random.choice(range(l))\n",
    "\n",
    "        dist_arg1_argmax = dists_arg1[idx_arg1[k]]\n",
    "        dist_arg2_argmax = dists_arg2[idx_arg2[k]]\n",
    "        \n",
    "        loss_arg1 = torch.max(torch.zeros(1).to(self.device), dist_arg1_gold - dist_arg1_argmax + alpha)\n",
    "        loss_arg2 = torch.max(torch.zeros(1).to(self.device), dist_arg2_gold - dist_arg2_argmax + alpha)\n",
    "        \n",
    "        loss = states[0,0:1]**2 #torch.zeros(1).to(self.device)\n",
    "        loss2_isnan = np.isnan(loss_arg2.detach().cpu().numpy().item())\n",
    "        loss1_isnan = np.isnan(loss_arg1.detach().cpu().numpy().item())\n",
    "        if not loss2_isnan:\n",
    "            loss += loss_arg2\n",
    "        if not loss1_isnan:\n",
    "            loss += loss_arg1\n",
    "        \n",
    "        if loss1_isnan or loss2_isnan:\n",
    "            print(\"ERROR: nan loss\", loss1_isnan, loss2_isnan, nb)\n",
    "            return\n",
    "        \n",
    "        global count\n",
    "        global total\n",
    "        total += 1                                                      \n",
    "        #if loss.detach().cpu().numpy().item() < 1e-5:\n",
    "        if (dist_arg1_gold - dist_arg1_argmax).detach().cpu().numpy().item() < 0 and (dist_arg2_gold - dist_arg2_argmax).detach().cpu().numpy().item() < 0:\n",
    "            count += 1\n",
    "        \n",
    "        return loss, idx_arg1, idx_arg2, idx_arg1_all, idx_arg2_all, all_false_ngrams_ranges, all_ngrams\n",
    "        #return loss, np.argsort(dists_arg1+mask_gold_arg1)\n",
    "\n",
    "    def forward_with_loss_calculation(self, bert_tokens, x, range_sent1, range_sent2, orig_to_tok_map, l, l_tokens,\n",
    "                                      metric = \"l2\", n_max = 5, alpha = 0.075, mode = \"train\", normalize=False, nb=0):\n",
    "        idx_arg1_all, idx_arg2_all, all_ngrams = None, None, None\n",
    "        \n",
    "        outputs = self.model(x)\n",
    "        states = outputs[0][0] #[seq_len, 768]\n",
    "        if metric == \"cosine\" or normalize:\n",
    "            states = states / (torch.norm(states, dim = 1, keepdim = True)+1e-8)\n",
    "        \n",
    "        states = self.linear_arg1_1(states)\n",
    "        arg1_sent1, arg2_sent1 = range_sent1\n",
    "        arg1_sent2, arg2_sent2 = range_sent2\n",
    "        \n",
    "        sent1_arg1_vec, sent1_arg2_vec = states[arg1_sent1[0]:arg1_sent1[1]].mean(dim=0), states[arg2_sent1[0]:arg2_sent1[1]].mean(dim=0)\n",
    "        sent2_arg1_vec, sent2_arg2_vec = states[arg1_sent2[0]:arg1_sent2[1]].mean(dim=0), states[arg2_sent2[0]:arg2_sent2[1]].mean(dim=0)        \n",
    "        \n",
    "        all_false_ngrams_ranges = get_all_ngrams_spans(len(states), [arg1_sent1, arg1_sent2, arg2_sent1, arg2_sent2], start_ind = 0,\n",
    "                                                      n_max = n_max)      \n",
    "        negatives = [states[ngram[0]:ngram[1]].mean(dim=0) for ngram in all_false_ngrams_ranges]\n",
    "        negatives_arg1 = negatives + [sent1_arg2_vec, sent2_arg2_vec]\n",
    "        negatives_arg2 = negatives + [sent1_arg1_vec, sent2_arg1_vec]\n",
    "        negatives_arg1 = torch.stack(negatives_arg1).to(self.device)\n",
    "        negatives_arg2 = torch.stack(negatives_arg2).to(self.device)\n",
    "        \n",
    "\n",
    "        if mode == \"eval\":\n",
    "            all_ngrams = get_all_ngrams_spans(len(states), [], start_ind = l_tokens,\n",
    "                                                      n_max = n_max)\n",
    "            ngrams = [states[ngram[0]:ngram[1]].mean(dim=0) for ngram in all_ngrams]\n",
    "            ngrams = torch.stack(ngrams).to(self.device)\n",
    "        \n",
    "        \n",
    "        if metric == \"l2\":\n",
    "            dists_arg1 = torch.sqrt(((negatives_arg1-sent1_arg1_vec)**2).sum(dim = 1))\n",
    "            dists_arg2 = torch.sqrt(((negatives_arg2-sent1_arg2_vec)**2).sum(dim = 1))\n",
    "            dist_arg1_gold = (sent1_arg1_vec - sent2_arg1_vec).norm()\n",
    "            dist_arg2_gold = (sent1_arg2_vec - sent2_arg2_vec).norm()\n",
    "            if mode == \"eval\":\n",
    "                dist_arg1_all = torch.sqrt(((ngrams-sent1_arg1_vec)**2).sum(dim = 1))\n",
    "                dist_arg2_all = torch.sqrt(((ngrams-sent1_arg2_vec)**2).sum(dim = 1))\n",
    "                idx_arg1_all = torch.argsort(dist_arg1_all).detach().cpu().numpy()\n",
    "                idx_arg2_all = torch.argsort(dist_arg2_all).detach().cpu().numpy()   \n",
    "                \n",
    "        elif metric == \"cosine\":\n",
    "            dists_arg1 = 1 - negatives_arg1@sent1_arg1_vec.T\n",
    "            dists_arg2 = 1 - negatives_arg2@sent1_arg2_vec.T\n",
    "            dist_arg1_gold = 1 - sent1_arg1_vec@sent2_arg1_vec.T\n",
    "            dist_arg2_gold = 1 - sent1_arg2_vec@sent2_arg2_vec.T\n",
    "        \n",
    "        idx_arg1 = torch.argsort(dists_arg1).detach().cpu().numpy()\n",
    "        idx_arg2 = torch.argsort(dists_arg2).detach().cpu().numpy()\n",
    "        l = max(int(len(negatives)*0.3),1)\n",
    "        k = random.choice(range(min(len(negatives), 2))) if np.random.random() < 0.5 else random.choice(range(l))\n",
    "\n",
    "        dist_arg1_argmax = dists_arg1[idx_arg1[k]]\n",
    "        dist_arg2_argmax = dists_arg2[idx_arg2[k]]\n",
    "        \n",
    "        loss_arg1 = torch.max(torch.zeros(1).to(self.device), dist_arg1_gold - dist_arg1_argmax + alpha)\n",
    "        loss_arg2 = torch.max(torch.zeros(1).to(self.device), dist_arg2_gold - dist_arg2_argmax + alpha)\n",
    "        \n",
    "        # softmax triplet\n",
    "        \n",
    "        z = torch.max(dist_arg1_argmax, dist_arg1_gold)\n",
    "        temp = 1\n",
    "        pos_arg1 = torch.exp((dist_arg1_gold - z)/temp)\n",
    "        neg_arg1 = torch.exp((dist_arg1_argmax - z)/temp)\n",
    "        loss_arg1 = (pos_arg1 / (pos_arg1 + neg_arg1))**2\n",
    "\n",
    "        z = torch.max(dist_arg2_argmax, dist_arg2_gold)\n",
    "        pos_arg2 = torch.exp((dist_arg2_gold - z)/temp)\n",
    "        neg_arg2 = torch.exp((dist_arg2_argmax - z)/temp)\n",
    "        loss_arg2 = (pos_arg2 / (pos_arg2 + neg_arg2))**2\n",
    "\n",
    "        \n",
    "        loss = states[0,0:1]**2 #torch.zeros(1).to(self.device)\n",
    "        loss2_isnan = np.isnan(loss_arg2.detach().cpu().numpy().item())\n",
    "        loss1_isnan = np.isnan(loss_arg1.detach().cpu().numpy().item())\n",
    "        if not loss2_isnan:\n",
    "            loss += loss_arg2\n",
    "        if not loss1_isnan:\n",
    "            loss += loss_arg1\n",
    "        \n",
    "        if loss1_isnan or loss2_isnan:\n",
    "            print(\"ERROR: nan loss\", loss1_isnan, loss2_isnan, nb)\n",
    "            return\n",
    "        \n",
    "        global count\n",
    "        global total\n",
    "        total += 1                                                      \n",
    "        #if loss.detach().cpu().numpy().item() < 1e-5:\n",
    "        if (dist_arg1_gold - dist_arg1_argmax).detach().cpu().numpy().item() < 0 and (dist_arg2_gold - dist_arg2_argmax).detach().cpu().numpy().item() < 0:\n",
    "            count += 1\n",
    "        \n",
    "        return loss, idx_arg1, idx_arg2, idx_arg1_all, idx_arg2_all, all_false_ngrams_ranges, all_ngrams\n",
    "        #return loss, np.argsort(dists_arg1+mask_gold_arg1)\n",
    "        \n",
    "    def training_step(self, batch, batch_nb):\n",
    "        \n",
    "        sents_concat, idx, l, sent2_with_args = batch\n",
    "        idx = idx.detach().cpu().numpy()[0]\n",
    "\n",
    "        bert_tokens, orig_to_tok_map, tok_to_orig_map, tokens_tensor = self.tokenize(sents_concat[0].split(\" \"))        \n",
    "        \n",
    "        l_tokens = len(bert_tokens[:orig_to_tok_map[l.detach().cpu().numpy().item()-1]]) \n",
    "        sent1_range_arg1 = get_entity_range_multiword_expression(idx[0][0], orig_to_tok_map)\n",
    "        sent1_range_arg2 = get_entity_range_multiword_expression(idx[0][1], orig_to_tok_map)\n",
    "        sent2_range_arg1 = get_entity_range_multiword_expression(idx[1][0], orig_to_tok_map)\n",
    "        sent2_range_arg2 = get_entity_range_multiword_expression(idx[1][1], orig_to_tok_map)\n",
    "\n",
    "        range_sent1 = [sent1_range_arg1, sent1_range_arg2]\n",
    "        range_sent2 = [sent2_range_arg1, sent2_range_arg2]\n",
    "        \n",
    "#         print(\"******************From training:*********\", len(bert_tokens),l_tokens)\n",
    "#         print(sents_concat)\n",
    "#         print(\"****************END FROM TRAINING**********\")\n",
    "        loss, _, _, _, _, _, _ = self.forward_with_loss_calculation(bert_tokens, tokens_tensor, range_sent1, range_sent2, orig_to_tok_map, l, l_tokens, nb = batch_nb)\n",
    "        \n",
    "#         if np.isnan(loss.detach().cpu().numpy().item()) or loss.detach().cpu().numpy().item() > 1e4:\n",
    "#             print(\"ERRROR!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!\")\n",
    "#             print(sents_concat, range_sent1, range_sent2, sent1_idx, sent2_idx)\n",
    "#             return {\"loss\": loss*0}\n",
    "\n",
    "        if total%1000 == 0:\n",
    "            print(\"count\", count/total)\n",
    "        return {'loss': loss}\n",
    "    \n",
    "    def validation_step(self, batch, batch_nb):\n",
    "\n",
    "        sents_concat, idx, l, sent2_with_args = batch\n",
    "        idx = idx.detach().cpu().numpy()[0]\n",
    "        bert_tokens, orig_to_tok_map, tok_to_orig_map, tokens_tensor = self.tokenize(sents_concat[0].split(\" \"))\n",
    "        l_tokens = len(bert_tokens[:orig_to_tok_map[l.detach().cpu().numpy().item()-1]]) \n",
    "        sent1_range_arg1 = get_entity_range_multiword_expression(idx[0][0], orig_to_tok_map)\n",
    "        sent1_range_arg2 = get_entity_range_multiword_expression(idx[0][1], orig_to_tok_map)\n",
    "        sent2_range_arg1 = get_entity_range_multiword_expression(idx[1][0], orig_to_tok_map)\n",
    "        sent2_range_arg2 = get_entity_range_multiword_expression(idx[1][1], orig_to_tok_map)\n",
    "        \n",
    "        range_sent1 = [sent1_range_arg1,sent1_range_arg2]\n",
    "        range_sent2 = [sent2_range_arg1,sent2_range_arg2]\n",
    "        loss, _, _, _, _, _, _ = self.forward_with_loss_calculation(bert_tokens, tokens_tensor, range_sent1, range_sent2, orig_to_tok_map, l, l_tokens)\n",
    "        \n",
    "#         print(sents_concat)\n",
    "#         print(\"---------------\")\n",
    "#         print(sent2_with_args)\n",
    "#         print(\"------------\")\n",
    "#         print(\" \".join(bert_tokens[sent1_range_arg1[0]:sent1_range_arg1[1]]))\n",
    "#         print(\" \".join(bert_tokens[sent1_range_arg2[0]:sent1_range_arg2[1]]))\n",
    "#         print(\" \".join(bert_tokens[sent2_range_arg1[0]:sent2_range_arg1[1]]))\n",
    "#         print(\" \".join(bert_tokens[sent2_range_arg2[0]:sent2_range_arg2[1]]))\n",
    "#         print(\"============================================\")\n",
    "        #loss, argsort = self.forward_with_loss_calculation(tokens_tensor, sent1_idx, sent2_idx, orig_to_tok_map, tok_to_orig_map, l, l_tokens)\n",
    "\n",
    "        return {'val_loss': loss}\n",
    "    \n",
    "    def validation_end(self, outputs):\n",
    "        avg_loss = torch.stack([x['val_loss'] for x in outputs]).mean()\n",
    "        print(\"Loss is {}\".format(avg_loss))\n",
    "        return {'avg_val_loss': avg_loss}\n",
    "    \n",
    "    def configure_optimizers(self):\n",
    "        #return torch.optim.RMSprop(self.parameters())\n",
    "        #return torch.optim.ASGD(self.parameters())\n",
    "        return torch.optim.SGD(self.parameters(), lr=1e-4, momentum=0.75)        \n",
    "        #return torch.optim.Adam(self.parameters())\n",
    "    \n",
    "    @pl.data_loader\n",
    "    def train_dataloader(self):\n",
    "        return self.train_gen\n",
    "\n",
    "    @pl.data_loader\n",
    "    def val_dataloader(self):\n",
    "        # OPTIONAL\n",
    "        # can also return a list of val dataloaders\n",
    "        return self.dev_gen\n",
    "    \n",
    "\n",
    "def evaluate_model(dev_dataset, model, max_ngrams = 2, num_examples = 200):\n",
    "    \n",
    "    preds = []\n",
    "    count = 0\n",
    "    \n",
    "    for batch in tqdm.tqdm(dev_dataset):\n",
    "        if count > num_examples: break\n",
    "        count += 1\n",
    "        sents_concat, idx, l, sent2_with_args = batch\n",
    "        idx = idx.detach().cpu().numpy()\n",
    "        bert_tokens, orig_to_tok_map, tok_to_orig_map, tokens_tensor = model.tokenize(sents_concat.split(\" \"))\n",
    "        l_tokens = len(bert_tokens[:orig_to_tok_map[l-1]]) \n",
    "        sent1_range_arg1 = get_entity_range_multiword_expression(idx[0][0], orig_to_tok_map)\n",
    "        sent1_range_arg2 = get_entity_range_multiword_expression(idx[0][1], orig_to_tok_map)\n",
    "        sent2_range_arg1 = get_entity_range_multiword_expression(idx[1][0], orig_to_tok_map)\n",
    "        sent2_range_arg2 = get_entity_range_multiword_expression(idx[1][1], orig_to_tok_map)\n",
    "\n",
    "        range_sent1 = (sent1_range_arg1,sent1_range_arg2)\n",
    "        range_sent2 = (sent2_range_arg1,sent2_range_arg2)\n",
    "        \n",
    "        loss, idx_arg1, idx_arg2, idx_arg1_all, idx_arg2_all, all_false_ngrams_ranges, all_ngrams = model.forward_with_loss_calculation(bert_tokens, tokens_tensor, range_sent1, range_sent2, orig_to_tok_map, l, l_tokens, mode = \"eval\", n_max=max_ngrams)\n",
    "        preds.append({\"sent\": sents_concat, \"tokens\": bert_tokens, \"tok2orig\": tok_to_orig_map, \"orig2tok\": orig_to_tok_map,\n",
    "                     \"preds_arg1_tokens\": idx_arg1_all, \"preds_arg2_tokens\": idx_arg2_all, \"false_ngrams\": all_false_ngrams_ranges,\n",
    "                      \"all_ngrams\": all_ngrams, \"gold_arg1_range_tokens\": sent2_range_arg1, \"gold_arg2_range_tokens\": sent2_range_arg2})\n",
    "        \n",
    "    return preds\n",
    "\n",
    "\n",
    "def get_entity_range(index_orig, orig_to_tok_map):\n",
    "    \n",
    "    m = min(orig_to_tok_map.keys())\n",
    "    if orig_to_tok_map[index_orig] == 1: return (1,2)\n",
    "    if index_orig == 0: return (1, orig_to_tok_map[index_orig] + 1)\n",
    "    \n",
    "    before = index_orig - 1\n",
    "    tok_range = (orig_to_tok_map[before] + 1, orig_to_tok_map[index_orig] + 1)\n",
    "    return tok_range\n",
    "\n",
    "def get_entity_range_multiword_expression(start_and_end, orig_to_tok_map):\n",
    "    \n",
    "    start, end = start_and_end\n",
    "    start_range = get_entity_range(start, orig_to_tok_map)\n",
    "    end_range = get_entity_range(end, orig_to_tok_map)\n",
    "    return [start_range[0], end_range[1]]\n",
    "\n",
    "def get_tok_to_orig_map(orig_to_tok_map, num_words, num_tokens):\n",
    "    \n",
    "    ranges = [get_entity_range(i, orig_to_tok_map) for i in range(num_words)]\n",
    "    tok_to_orig_map = {}\n",
    "    for i in range(num_words):\n",
    "        min,max = ranges[i]\n",
    "        for tok in range(min,max):\n",
    "            tok_to_orig_map[tok] = i\n",
    "    \n",
    "    for tok in range(num_tokens):\n",
    "        if tok not in tok_to_orig_map:\n",
    "            tok_to_orig_map[tok] = num_words -1\n",
    "    \n",
    "    return tok_to_orig_map\n",
    "        \n",
    "def get_all_ngrams_spans(seq_len, forbidden_ranges: List[tuple], start_ind = 0, n_max = 15):\n",
    "    \n",
    "    def is_intersecting(ngram, forbidden_ranges):\n",
    "        \n",
    "        return [(r[1] > ngram[0] >= r[0]) or(r[1] > ngram[1] >= r[0]) for r in forbidden_ranges]\n",
    "    \n",
    "    all_ngrams = []\n",
    "    for n in range(2,n_max+1):\n",
    "        ngrams = list(get_ngrams(range(start_ind, seq_len), n))\n",
    "        all_ngrams.extend(ngrams)\n",
    "    \n",
    "    all_ngrams = [(ngram[0], ngram[-1]) for ngram in all_ngrams]\n",
    "    all_ngrams = [ngram for ngram in all_ngrams if not any(is_intersecting(ngram, forbidden_ranges))]\n",
    "    return all_ngrams\n",
    "    \n",
    "    \n",
    "def get_prediction(sent1, sent2, model):\n",
    "    \n",
    "    l = len(sent1.split(\" \")) + 1 \n",
    "    sent2 = sent2.replace(\"ARG1:\", \"\").replace(\"ARG2:\", \"\")\n",
    "    \n",
    "    sents_concat = sent1 + \" ***** \" + sent2\n",
    "    sent1_arg1 = [i for i,w in enumerate(sent1.split(\" \")) if \"ARG1:\" in w][0]\n",
    "    sent1_arg2 = [i for i,w in enumerate(sent1.split(\" \")) if \"ARG2:\" in w][0]\n",
    "    words = sents_concat.split(\" \")\n",
    "    \n",
    "    bert_tokens, orig_to_tok_map, tok_to_orig_map, tokens_tensor = model.tokenize(sents_concat.split(\" \"))\n",
    "    range_arg1 = get_entity_range(sent1_arg1, orig_to_tok_map)\n",
    "    range_arg2 = get_entity_range(sent1_arg2, orig_to_tok_map)\n",
    "    \n",
    "    l_tokens = len(bert_tokens[:orig_to_tok_map[l-1]])    \n",
    "    outputs = model.model(tokens_tensor)\n",
    "    states = outputs[0][0] #[seq_len, 768]\n",
    "\n",
    "    states = states#/torch.norm(states, dim = 1, keepdim = True)\n",
    "    \n",
    "    sent1_arg1_vec, sent1_arg2_vec = states[range_arg1[0]:range_arg1[1]].mean(dim=0), states[range_arg2[0]:range_arg2[1]].mean(dim=0)\n",
    "    \n",
    "    print(\"GOLD ARG1, ARG2:\", bert_tokens[orig_to_tok_map[sent1_arg1]], bert_tokens[orig_to_tok_map[sent1_arg2]])\n",
    "    sims_arg1 = (model.linear_arg1_1(states)-model.linear_arg1_2(sent1_arg1_vec)).norm(dim=1)\n",
    "    sims_arg2 = (model.linear_arg2_1(states)-model.linear_arg2_2(sent1_arg2_vec)).norm(dim=1)\n",
    "\n",
    "    mask_gold_arg1 = torch.zeros_like(sims_arg1).to(model.device)\n",
    "    mask_gold_arg2 = torch.zeros_like(sims_arg2).to(model.device)\n",
    "    #mask_gold_arg1[range_arg1[0]:range_arg1[1]] = 1e6\n",
    "    #mask_gold_arg2[range_arg2[0]:range_arg2[1]] = 1e6\n",
    "    mask_gold_arg2[:l_tokens] = 1e6\n",
    "    mask_gold_arg1[:l_tokens] = 1e6\n",
    "        \n",
    "    idx_arg1 = torch.argsort(sims_arg1+mask_gold_arg1).detach().cpu().numpy()\n",
    "    idx_arg2 = torch.argsort(sims_arg2+mask_gold_arg2).detach().cpu().numpy()\n",
    "    \n",
    "    print(\"all arg1 preds\", [words[tok_to_orig_map[idx_arg1[i]]] for i in range(len(idx_arg1))][:7])\n",
    "    print(\"---------------------------------------------------\")\n",
    "    print(\"all arg2 preds\", [words[tok_to_orig_map[idx_arg2[i]]] for i in range(len(idx_arg2))][:7])\n",
    "    print(\"---------------------------------------------------\")\n",
    "    \n",
    "    #print(bert_tokens[idx_arg1[-4]], bert_tokens[idx_arg2[-4]])\n",
    "    \n",
    "    return\n",
    "    \n",
    "    most_sim_arg1, most_sim_arg2 = sims_arg1[idx_arg1[-2]], sims_arg2[idx_arg2[-2]]\n",
    "    ind_arg1, ind_arg2 = idx_arg1[-2].detach().cpu().numpy().item(), idx_arg2[-2].detach().cpu().numpy().item()\n",
    "    ind_arg1, ind_arg2 = ind_arg1 + l_tokens, ind_arg2 + l_tokens\n",
    "    \n",
    "    return sents_concat, tok_to_orig_map[ind_arg1], tok_to_orig_map[ind_arg2], bert_tokens[ind_arg1], bert_tokens[ind_arg2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Dataset(torch.utils.data.Dataset):\n",
    "    \"\"\"Simple torch dataset class\"\"\"\n",
    "\n",
    "    def __init__(self, data: List[Dict], device = \"cpu\"):\n",
    "\n",
    "        self.data = data\n",
    "        self.device = device\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.data)\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "        with torch.no_grad():\n",
    "            \n",
    "            d = self.data[index]\n",
    "            sent1, sent2 = d[\"first\"], d[\"second\"]\n",
    "            sent1_arg1, sent1_arg2 = list(d[\"first_arg1\"]), list(d[\"first_arg2\"])\n",
    "            sent2_arg1, sent2_arg2 = list(d[\"second_arg1\"]), list(d[\"second_arg2\"])\n",
    "            \n",
    "            l = len(sent1.split(\" \")) + 1 \n",
    "            #sent2_arg1, sent2_arg2 = sent2_arg1 + l, sent2_arg2 + l\n",
    "            sent2_arg1[0] += l\n",
    "            sent2_arg1[1] += l\n",
    "            sent2_arg2[0] += l\n",
    "            sent2_arg2[1] += l\n",
    "\n",
    "            sent2 = sent2.replace(\"ARG1:\", \"\").replace(\"ARG2:\", \"\")\n",
    "            sents_concat = sent1 + \" ***** \" + sent2 #sents_concat.split(\" \")[l] is the first token in the 2nd sent\n",
    "            #create idx tensor. # 1stdim: sents, 2st dim: arg, 3st dim: start and end\n",
    "            idx = [[[sent1_arg1[0], sent1_arg1[1]], [sent1_arg2[0], sent1_arg2[1]]], [[sent2_arg1[0], sent2_arg1[1]], [sent2_arg2[0], sent2_arg2[1]]] ] \n",
    "            sent2_with_args = d[\"second_with_arguments\"]\n",
    "            return sents_concat, torch.tensor(idx).int(), l, sent2_with_args"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<<ARG1:Griseofulvin>> should not be used to treat <<ARG2:dermatophytosis>> , because it has been associated with bone marrow suppression in FIV-positive cats.79 Recombinant human erythropoietin or darbepoetin may be useful for some cats with nonregenerative anemia and does not appear to increase viral load through activation of transcription of latent virus.80 Although recombinant human granulocyte colony stimulating factor ( G-CSF ) can increase neutrophil counts in cats infected with FIV , antibodies can develop within a few weeks that cross-react with endogenous G-CSF . ***** Vitamin C is contraindicated in liver disease associated with transition metal accumulation ( copper , iron ) because it may enhance oxidative injury .\n",
      "tensor([[[ 0,  0],\n",
      "         [ 7,  7]],\n",
      "\n",
      "        [[84, 85],\n",
      "         [89, 90]]], dtype=torch.int32) torch.Size([2, 2, 2])\n"
     ]
    }
   ],
   "source": [
    "l = int(0.8 * len(data))\n",
    "#train_dataset, dev_dataset = Dataset(data[:l], \"cpu\"), Dataset(data[l:], \"cpu\")\n",
    "train_dataset, dev_dataset = Dataset(data_train, \"cpu\"), Dataset(data_dev, \"cpu\")\n",
    "\n",
    "sents_concat, idx, l, sent2_with_args = train_dataset[0]\n",
    "print(sents_concat)\n",
    "print(idx, idx.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "try:\n",
    "    del model\n",
    "except:\n",
    "    pass\n",
    "model = BertModel(train_dataset, dev_dataset, 1, \"cuda\", \"train\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2020-11-09 01:04:14.813 INFO    lightning: GPU available: True, used: True\n",
      "2020-11-09 01:04:14.814 INFO    lightning: CUDA_VISIBLE_DEVICES: [0]\n",
      "/home/shauli/miniconda3/envs/py3/lib/python3.7/site-packages/pytorch_lightning/utilities/distributed.py:23: RuntimeWarning: You have defined a `val_dataloader()` and have defined a `validation_step()`, you may also want to define `validation_epoch_end()` for accumulating stats.\n",
      "  warnings.warn(*args, **kwargs)\n",
      "2020-11-09 01:04:16.484 INFO    lightning: \n",
      "    | Name                                              | Type              | Params\n",
      "------------------------------------------------------------------------------------\n",
      "0   | model                                             | BertModel         | 109 M \n",
      "1   | model.embeddings                                  | BertEmbeddings    | 24 M  \n",
      "2   | model.embeddings.word_embeddings                  | Embedding         | 23 M  \n",
      "3   | model.embeddings.position_embeddings              | Embedding         | 393 K \n",
      "4   | model.embeddings.token_type_embeddings            | Embedding         | 1 K   \n",
      "5   | model.embeddings.LayerNorm                        | LayerNorm         | 1 K   \n",
      "6   | model.embeddings.dropout                          | Dropout           | 0     \n",
      "7   | model.encoder                                     | BertEncoder       | 85 M  \n",
      "8   | model.encoder.layer                               | ModuleList        | 85 M  \n",
      "9   | model.encoder.layer.0                             | BertLayer         | 7 M   \n",
      "10  | model.encoder.layer.0.attention                   | BertAttention     | 2 M   \n",
      "11  | model.encoder.layer.0.attention.self              | BertSelfAttention | 1 M   \n",
      "12  | model.encoder.layer.0.attention.self.query        | Linear            | 590 K \n",
      "13  | model.encoder.layer.0.attention.self.key          | Linear            | 590 K \n",
      "14  | model.encoder.layer.0.attention.self.value        | Linear            | 590 K \n",
      "15  | model.encoder.layer.0.attention.self.dropout      | Dropout           | 0     \n",
      "16  | model.encoder.layer.0.attention.output            | BertSelfOutput    | 592 K \n",
      "17  | model.encoder.layer.0.attention.output.dense      | Linear            | 590 K \n",
      "18  | model.encoder.layer.0.attention.output.LayerNorm  | LayerNorm         | 1 K   \n",
      "19  | model.encoder.layer.0.attention.output.dropout    | Dropout           | 0     \n",
      "20  | model.encoder.layer.0.intermediate                | BertIntermediate  | 2 M   \n",
      "21  | model.encoder.layer.0.intermediate.dense          | Linear            | 2 M   \n",
      "22  | model.encoder.layer.0.output                      | BertOutput        | 2 M   \n",
      "23  | model.encoder.layer.0.output.dense                | Linear            | 2 M   \n",
      "24  | model.encoder.layer.0.output.LayerNorm            | LayerNorm         | 1 K   \n",
      "25  | model.encoder.layer.0.output.dropout              | Dropout           | 0     \n",
      "26  | model.encoder.layer.1                             | BertLayer         | 7 M   \n",
      "27  | model.encoder.layer.1.attention                   | BertAttention     | 2 M   \n",
      "28  | model.encoder.layer.1.attention.self              | BertSelfAttention | 1 M   \n",
      "29  | model.encoder.layer.1.attention.self.query        | Linear            | 590 K \n",
      "30  | model.encoder.layer.1.attention.self.key          | Linear            | 590 K \n",
      "31  | model.encoder.layer.1.attention.self.value        | Linear            | 590 K \n",
      "32  | model.encoder.layer.1.attention.self.dropout      | Dropout           | 0     \n",
      "33  | model.encoder.layer.1.attention.output            | BertSelfOutput    | 592 K \n",
      "34  | model.encoder.layer.1.attention.output.dense      | Linear            | 590 K \n",
      "35  | model.encoder.layer.1.attention.output.LayerNorm  | LayerNorm         | 1 K   \n",
      "36  | model.encoder.layer.1.attention.output.dropout    | Dropout           | 0     \n",
      "37  | model.encoder.layer.1.intermediate                | BertIntermediate  | 2 M   \n",
      "38  | model.encoder.layer.1.intermediate.dense          | Linear            | 2 M   \n",
      "39  | model.encoder.layer.1.output                      | BertOutput        | 2 M   \n",
      "40  | model.encoder.layer.1.output.dense                | Linear            | 2 M   \n",
      "41  | model.encoder.layer.1.output.LayerNorm            | LayerNorm         | 1 K   \n",
      "42  | model.encoder.layer.1.output.dropout              | Dropout           | 0     \n",
      "43  | model.encoder.layer.2                             | BertLayer         | 7 M   \n",
      "44  | model.encoder.layer.2.attention                   | BertAttention     | 2 M   \n",
      "45  | model.encoder.layer.2.attention.self              | BertSelfAttention | 1 M   \n",
      "46  | model.encoder.layer.2.attention.self.query        | Linear            | 590 K \n",
      "47  | model.encoder.layer.2.attention.self.key          | Linear            | 590 K \n",
      "48  | model.encoder.layer.2.attention.self.value        | Linear            | 590 K \n",
      "49  | model.encoder.layer.2.attention.self.dropout      | Dropout           | 0     \n",
      "50  | model.encoder.layer.2.attention.output            | BertSelfOutput    | 592 K \n",
      "51  | model.encoder.layer.2.attention.output.dense      | Linear            | 590 K \n",
      "52  | model.encoder.layer.2.attention.output.LayerNorm  | LayerNorm         | 1 K   \n",
      "53  | model.encoder.layer.2.attention.output.dropout    | Dropout           | 0     \n",
      "54  | model.encoder.layer.2.intermediate                | BertIntermediate  | 2 M   \n",
      "55  | model.encoder.layer.2.intermediate.dense          | Linear            | 2 M   \n",
      "56  | model.encoder.layer.2.output                      | BertOutput        | 2 M   \n",
      "57  | model.encoder.layer.2.output.dense                | Linear            | 2 M   \n",
      "58  | model.encoder.layer.2.output.LayerNorm            | LayerNorm         | 1 K   \n",
      "59  | model.encoder.layer.2.output.dropout              | Dropout           | 0     \n",
      "60  | model.encoder.layer.3                             | BertLayer         | 7 M   \n",
      "61  | model.encoder.layer.3.attention                   | BertAttention     | 2 M   \n",
      "62  | model.encoder.layer.3.attention.self              | BertSelfAttention | 1 M   \n",
      "63  | model.encoder.layer.3.attention.self.query        | Linear            | 590 K \n",
      "64  | model.encoder.layer.3.attention.self.key          | Linear            | 590 K \n",
      "65  | model.encoder.layer.3.attention.self.value        | Linear            | 590 K \n",
      "66  | model.encoder.layer.3.attention.self.dropout      | Dropout           | 0     \n",
      "67  | model.encoder.layer.3.attention.output            | BertSelfOutput    | 592 K \n",
      "68  | model.encoder.layer.3.attention.output.dense      | Linear            | 590 K \n",
      "69  | model.encoder.layer.3.attention.output.LayerNorm  | LayerNorm         | 1 K   \n",
      "70  | model.encoder.layer.3.attention.output.dropout    | Dropout           | 0     \n",
      "71  | model.encoder.layer.3.intermediate                | BertIntermediate  | 2 M   \n",
      "72  | model.encoder.layer.3.intermediate.dense          | Linear            | 2 M   \n",
      "73  | model.encoder.layer.3.output                      | BertOutput        | 2 M   \n",
      "74  | model.encoder.layer.3.output.dense                | Linear            | 2 M   \n",
      "75  | model.encoder.layer.3.output.LayerNorm            | LayerNorm         | 1 K   \n",
      "76  | model.encoder.layer.3.output.dropout              | Dropout           | 0     \n",
      "77  | model.encoder.layer.4                             | BertLayer         | 7 M   \n",
      "78  | model.encoder.layer.4.attention                   | BertAttention     | 2 M   \n",
      "79  | model.encoder.layer.4.attention.self              | BertSelfAttention | 1 M   \n",
      "80  | model.encoder.layer.4.attention.self.query        | Linear            | 590 K \n",
      "81  | model.encoder.layer.4.attention.self.key          | Linear            | 590 K \n",
      "82  | model.encoder.layer.4.attention.self.value        | Linear            | 590 K \n",
      "83  | model.encoder.layer.4.attention.self.dropout      | Dropout           | 0     \n",
      "84  | model.encoder.layer.4.attention.output            | BertSelfOutput    | 592 K \n",
      "85  | model.encoder.layer.4.attention.output.dense      | Linear            | 590 K \n",
      "86  | model.encoder.layer.4.attention.output.LayerNorm  | LayerNorm         | 1 K   \n",
      "87  | model.encoder.layer.4.attention.output.dropout    | Dropout           | 0     \n",
      "88  | model.encoder.layer.4.intermediate                | BertIntermediate  | 2 M   \n",
      "89  | model.encoder.layer.4.intermediate.dense          | Linear            | 2 M   \n",
      "90  | model.encoder.layer.4.output                      | BertOutput        | 2 M   \n",
      "91  | model.encoder.layer.4.output.dense                | Linear            | 2 M   \n",
      "92  | model.encoder.layer.4.output.LayerNorm            | LayerNorm         | 1 K   \n",
      "93  | model.encoder.layer.4.output.dropout              | Dropout           | 0     \n",
      "94  | model.encoder.layer.5                             | BertLayer         | 7 M   \n",
      "95  | model.encoder.layer.5.attention                   | BertAttention     | 2 M   \n",
      "96  | model.encoder.layer.5.attention.self              | BertSelfAttention | 1 M   \n",
      "97  | model.encoder.layer.5.attention.self.query        | Linear            | 590 K \n",
      "98  | model.encoder.layer.5.attention.self.key          | Linear            | 590 K \n",
      "99  | model.encoder.layer.5.attention.self.value        | Linear            | 590 K \n",
      "100 | model.encoder.layer.5.attention.self.dropout      | Dropout           | 0     \n",
      "101 | model.encoder.layer.5.attention.output            | BertSelfOutput    | 592 K \n",
      "102 | model.encoder.layer.5.attention.output.dense      | Linear            | 590 K \n",
      "103 | model.encoder.layer.5.attention.output.LayerNorm  | LayerNorm         | 1 K   \n",
      "104 | model.encoder.layer.5.attention.output.dropout    | Dropout           | 0     \n",
      "105 | model.encoder.layer.5.intermediate                | BertIntermediate  | 2 M   \n",
      "106 | model.encoder.layer.5.intermediate.dense          | Linear            | 2 M   \n",
      "107 | model.encoder.layer.5.output                      | BertOutput        | 2 M   \n",
      "108 | model.encoder.layer.5.output.dense                | Linear            | 2 M   \n",
      "109 | model.encoder.layer.5.output.LayerNorm            | LayerNorm         | 1 K   \n",
      "110 | model.encoder.layer.5.output.dropout              | Dropout           | 0     \n",
      "111 | model.encoder.layer.6                             | BertLayer         | 7 M   \n",
      "112 | model.encoder.layer.6.attention                   | BertAttention     | 2 M   \n",
      "113 | model.encoder.layer.6.attention.self              | BertSelfAttention | 1 M   \n",
      "114 | model.encoder.layer.6.attention.self.query        | Linear            | 590 K \n",
      "115 | model.encoder.layer.6.attention.self.key          | Linear            | 590 K \n",
      "116 | model.encoder.layer.6.attention.self.value        | Linear            | 590 K \n",
      "117 | model.encoder.layer.6.attention.self.dropout      | Dropout           | 0     \n",
      "118 | model.encoder.layer.6.attention.output            | BertSelfOutput    | 592 K \n",
      "119 | model.encoder.layer.6.attention.output.dense      | Linear            | 590 K \n",
      "120 | model.encoder.layer.6.attention.output.LayerNorm  | LayerNorm         | 1 K   \n",
      "121 | model.encoder.layer.6.attention.output.dropout    | Dropout           | 0     \n",
      "122 | model.encoder.layer.6.intermediate                | BertIntermediate  | 2 M   \n",
      "123 | model.encoder.layer.6.intermediate.dense          | Linear            | 2 M   \n",
      "124 | model.encoder.layer.6.output                      | BertOutput        | 2 M   \n",
      "125 | model.encoder.layer.6.output.dense                | Linear            | 2 M   \n",
      "126 | model.encoder.layer.6.output.LayerNorm            | LayerNorm         | 1 K   \n",
      "127 | model.encoder.layer.6.output.dropout              | Dropout           | 0     \n",
      "128 | model.encoder.layer.7                             | BertLayer         | 7 M   \n",
      "129 | model.encoder.layer.7.attention                   | BertAttention     | 2 M   \n",
      "130 | model.encoder.layer.7.attention.self              | BertSelfAttention | 1 M   \n",
      "131 | model.encoder.layer.7.attention.self.query        | Linear            | 590 K \n",
      "132 | model.encoder.layer.7.attention.self.key          | Linear            | 590 K \n",
      "133 | model.encoder.layer.7.attention.self.value        | Linear            | 590 K \n",
      "134 | model.encoder.layer.7.attention.self.dropout      | Dropout           | 0     \n",
      "135 | model.encoder.layer.7.attention.output            | BertSelfOutput    | 592 K \n",
      "136 | model.encoder.layer.7.attention.output.dense      | Linear            | 590 K \n",
      "137 | model.encoder.layer.7.attention.output.LayerNorm  | LayerNorm         | 1 K   \n",
      "138 | model.encoder.layer.7.attention.output.dropout    | Dropout           | 0     \n",
      "139 | model.encoder.layer.7.intermediate                | BertIntermediate  | 2 M   \n",
      "140 | model.encoder.layer.7.intermediate.dense          | Linear            | 2 M   \n",
      "141 | model.encoder.layer.7.output                      | BertOutput        | 2 M   \n",
      "142 | model.encoder.layer.7.output.dense                | Linear            | 2 M   \n",
      "143 | model.encoder.layer.7.output.LayerNorm            | LayerNorm         | 1 K   \n",
      "144 | model.encoder.layer.7.output.dropout              | Dropout           | 0     \n",
      "145 | model.encoder.layer.8                             | BertLayer         | 7 M   \n",
      "146 | model.encoder.layer.8.attention                   | BertAttention     | 2 M   \n",
      "147 | model.encoder.layer.8.attention.self              | BertSelfAttention | 1 M   \n",
      "148 | model.encoder.layer.8.attention.self.query        | Linear            | 590 K \n",
      "149 | model.encoder.layer.8.attention.self.key          | Linear            | 590 K \n",
      "150 | model.encoder.layer.8.attention.self.value        | Linear            | 590 K \n",
      "151 | model.encoder.layer.8.attention.self.dropout      | Dropout           | 0     \n",
      "152 | model.encoder.layer.8.attention.output            | BertSelfOutput    | 592 K \n",
      "153 | model.encoder.layer.8.attention.output.dense      | Linear            | 590 K \n",
      "154 | model.encoder.layer.8.attention.output.LayerNorm  | LayerNorm         | 1 K   \n",
      "155 | model.encoder.layer.8.attention.output.dropout    | Dropout           | 0     \n",
      "156 | model.encoder.layer.8.intermediate                | BertIntermediate  | 2 M   \n",
      "157 | model.encoder.layer.8.intermediate.dense          | Linear            | 2 M   \n",
      "158 | model.encoder.layer.8.output                      | BertOutput        | 2 M   \n",
      "159 | model.encoder.layer.8.output.dense                | Linear            | 2 M   \n",
      "160 | model.encoder.layer.8.output.LayerNorm            | LayerNorm         | 1 K   \n",
      "161 | model.encoder.layer.8.output.dropout              | Dropout           | 0     \n",
      "162 | model.encoder.layer.9                             | BertLayer         | 7 M   \n",
      "163 | model.encoder.layer.9.attention                   | BertAttention     | 2 M   \n",
      "164 | model.encoder.layer.9.attention.self              | BertSelfAttention | 1 M   \n",
      "165 | model.encoder.layer.9.attention.self.query        | Linear            | 590 K \n",
      "166 | model.encoder.layer.9.attention.self.key          | Linear            | 590 K \n",
      "167 | model.encoder.layer.9.attention.self.value        | Linear            | 590 K \n",
      "168 | model.encoder.layer.9.attention.self.dropout      | Dropout           | 0     \n",
      "169 | model.encoder.layer.9.attention.output            | BertSelfOutput    | 592 K \n",
      "170 | model.encoder.layer.9.attention.output.dense      | Linear            | 590 K \n",
      "171 | model.encoder.layer.9.attention.output.LayerNorm  | LayerNorm         | 1 K   \n",
      "172 | model.encoder.layer.9.attention.output.dropout    | Dropout           | 0     \n",
      "173 | model.encoder.layer.9.intermediate                | BertIntermediate  | 2 M   \n",
      "174 | model.encoder.layer.9.intermediate.dense          | Linear            | 2 M   \n",
      "175 | model.encoder.layer.9.output                      | BertOutput        | 2 M   \n",
      "176 | model.encoder.layer.9.output.dense                | Linear            | 2 M   \n",
      "177 | model.encoder.layer.9.output.LayerNorm            | LayerNorm         | 1 K   \n",
      "178 | model.encoder.layer.9.output.dropout              | Dropout           | 0     \n",
      "179 | model.encoder.layer.10                            | BertLayer         | 7 M   \n",
      "180 | model.encoder.layer.10.attention                  | BertAttention     | 2 M   \n",
      "181 | model.encoder.layer.10.attention.self             | BertSelfAttention | 1 M   \n",
      "182 | model.encoder.layer.10.attention.self.query       | Linear            | 590 K \n",
      "183 | model.encoder.layer.10.attention.self.key         | Linear            | 590 K \n",
      "184 | model.encoder.layer.10.attention.self.value       | Linear            | 590 K \n",
      "185 | model.encoder.layer.10.attention.self.dropout     | Dropout           | 0     \n",
      "186 | model.encoder.layer.10.attention.output           | BertSelfOutput    | 592 K \n",
      "187 | model.encoder.layer.10.attention.output.dense     | Linear            | 590 K \n",
      "188 | model.encoder.layer.10.attention.output.LayerNorm | LayerNorm         | 1 K   \n",
      "189 | model.encoder.layer.10.attention.output.dropout   | Dropout           | 0     \n",
      "190 | model.encoder.layer.10.intermediate               | BertIntermediate  | 2 M   \n",
      "191 | model.encoder.layer.10.intermediate.dense         | Linear            | 2 M   \n",
      "192 | model.encoder.layer.10.output                     | BertOutput        | 2 M   \n",
      "193 | model.encoder.layer.10.output.dense               | Linear            | 2 M   \n",
      "194 | model.encoder.layer.10.output.LayerNorm           | LayerNorm         | 1 K   \n",
      "195 | model.encoder.layer.10.output.dropout             | Dropout           | 0     \n",
      "196 | model.encoder.layer.11                            | BertLayer         | 7 M   \n",
      "197 | model.encoder.layer.11.attention                  | BertAttention     | 2 M   \n",
      "198 | model.encoder.layer.11.attention.self             | BertSelfAttention | 1 M   \n",
      "199 | model.encoder.layer.11.attention.self.query       | Linear            | 590 K \n",
      "200 | model.encoder.layer.11.attention.self.key         | Linear            | 590 K \n",
      "201 | model.encoder.layer.11.attention.self.value       | Linear            | 590 K \n",
      "202 | model.encoder.layer.11.attention.self.dropout     | Dropout           | 0     \n",
      "203 | model.encoder.layer.11.attention.output           | BertSelfOutput    | 592 K \n",
      "204 | model.encoder.layer.11.attention.output.dense     | Linear            | 590 K \n",
      "205 | model.encoder.layer.11.attention.output.LayerNorm | LayerNorm         | 1 K   \n",
      "206 | model.encoder.layer.11.attention.output.dropout   | Dropout           | 0     \n",
      "207 | model.encoder.layer.11.intermediate               | BertIntermediate  | 2 M   \n",
      "208 | model.encoder.layer.11.intermediate.dense         | Linear            | 2 M   \n",
      "209 | model.encoder.layer.11.output                     | BertOutput        | 2 M   \n",
      "210 | model.encoder.layer.11.output.dense               | Linear            | 2 M   \n",
      "211 | model.encoder.layer.11.output.LayerNorm           | LayerNorm         | 1 K   \n",
      "212 | model.encoder.layer.11.output.dropout             | Dropout           | 0     \n",
      "213 | model.pooler                                      | BertPooler        | 590 K \n",
      "214 | model.pooler.dense                                | Linear            | 590 K \n",
      "215 | model.pooler.activation                           | Tanh              | 0     \n",
      "216 | linear_arg1_1                                     | Linear            | 49 K  \n",
      "217 | linear_arg2_1                                     | Linear            | 49 K  \n",
      "218 | linear_arg1_2                                     | Linear            | 49 K  \n",
      "219 | linear_arg2_2                                     | Linear            | 49 K  \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/shauli/miniconda3/envs/py3/lib/python3.7/site-packages/pytorch_lightning/utilities/distributed.py:23: UserWarning: The dataloader, val dataloader 0, does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` in the `DataLoader` init to improve performance.\n",
      "  warnings.warn(*args, **kwargs)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=1.0, bar_style='info', description='Validation sanity check', layout=Layout"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss is 1.4584121704101562\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/shauli/miniconda3/envs/py3/lib/python3.7/site-packages/pytorch_lightning/utilities/distributed.py:23: UserWarning: The dataloader, train dataloader, does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` in the `DataLoader` init to improve performance.\n",
      "  warnings.warn(*args, **kwargs)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f12945710e4241b6897e36de5ae0475c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=1.0, bar_style='info', description='Training', layout=Layout(flex='2'), max"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "count 0.223\n",
      "count 0.2995\n",
      "count 0.3576666666666667\n",
      "count 0.3965\n",
      "count 0.4228\n",
      "count 0.44516666666666665\n",
      "count 0.4655714285714286\n",
      "count 0.482875\n",
      "count 0.49477777777777776\n",
      "count 0.5094\n",
      "count 0.5213636363636364\n",
      "count 0.5295833333333333\n",
      "count 0.5386923076923077\n",
      "count 0.5494285714285714\n",
      "count 0.5562666666666667\n",
      "count 0.5635625\n",
      "count 0.57\n",
      "count 0.5761111111111111\n",
      "count 0.5816842105263158\n",
      "count 0.5877\n",
      "count 0.5935714285714285\n",
      "count 0.5980909090909091\n",
      "count 0.6020869565217392\n",
      "count 0.6075\n",
      "count 0.61212\n",
      "count 0.6161153846153846\n",
      "count 0.620037037037037\n",
      "count 0.6241428571428571\n",
      "count 0.628551724137931\n",
      "count 0.6324333333333333\n",
      "count 0.6359354838709678\n",
      "count 0.63884375\n",
      "count 0.642090909090909\n",
      "count 0.646\n",
      "count 0.6491142857142858\n",
      "count 0.6521111111111111\n",
      "count 0.655027027027027\n",
      "count 0.6571842105263158\n",
      "count 0.6599487179487179\n",
      "count 0.662325\n",
      "count 0.6653414634146342\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=1.0, bar_style='info', description='Validating', layout=Layout(flex='2'), m"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss is 0.25506293773651123\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/shauli/miniconda3/envs/py3/lib/python3.7/site-packages/pytorch_lightning/utilities/distributed.py:23: RuntimeWarning: Can save best model only with val_loss available, skipping.\n",
      "  warnings.warn(*args, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "count 0.6698163265306123\n",
      "count 0.67232\n",
      "count 0.6744705882352942\n",
      "count 0.675923076923077\n",
      "count 0.6779622641509434\n",
      "count 0.6801481481481482\n",
      "count 0.6820727272727273\n",
      "count 0.68425\n",
      "count 0.6863508771929825\n",
      "count 0.6886034482758621\n",
      "count 0.6903559322033899\n",
      "count 0.6924833333333333\n",
      "count 0.693983606557377\n",
      "count 0.6961129032258064\n",
      "count 0.6977936507936507\n",
      "count 0.699609375\n",
      "count 0.7013230769230769\n",
      "count 0.7028030303030303\n",
      "count 0.7041791044776119\n",
      "count 0.7055588235294118\n",
      "count 0.7069565217391305\n",
      "count 0.7081571428571428\n",
      "count 0.7095774647887324\n",
      "count 0.7110555555555556\n",
      "count 0.7126301369863014\n",
      "count 0.7138648648648649\n",
      "count 0.71508\n",
      "count 0.7167105263157895\n",
      "count 0.718025974025974\n",
      "count 0.7193205128205128\n",
      "count 0.7204556962025317\n",
      "count 0.72155\n",
      "count 0.7229876543209877\n",
      "count 0.7241951219512195\n",
      "count 0.7253734939759036\n",
      "count 0.7267619047619047\n",
      "count 0.7279411764705882\n",
      "count 0.7291744186046512\n",
      "count 0.7304942528735632\n",
      "count 0.7318295454545455\n",
      "count 0.7330561797752809\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=1.0, bar_style='info', description='Validating', layout=Layout(flex='2'), m"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss is 0.2434513419866562\n",
      "count 0.7325714285714285\n",
      "count 0.7337272727272727\n",
      "count 0.73475\n",
      "count 0.7358613861386138\n",
      "count 0.7369705882352942\n",
      "count 0.7380194174757282\n",
      "count 0.7388942307692308\n",
      "count 0.7398571428571429\n",
      "count 0.7409622641509434\n",
      "count 0.7420560747663552\n",
      "count 0.7430555555555556\n",
      "count 0.7439082568807339\n",
      "count 0.7449090909090909\n",
      "count 0.7458108108108108\n",
      "count 0.7468125\n",
      "count 0.7479203539823008\n",
      "count 0.7489385964912281\n",
      "count 0.7498\n",
      "count 0.7505689655172414\n",
      "count 0.7516153846153846\n",
      "count 0.7522881355932204\n",
      "count 0.7532100840336134\n",
      "count 0.7539666666666667\n",
      "count 0.7548512396694215\n",
      "count 0.7557049180327868\n",
      "count 0.7564634146341463\n",
      "count 0.75725\n",
      "count 0.757992\n",
      "count 0.7586031746031746\n",
      "count 0.7594094488188976\n",
      "count 0.7601953125\n",
      "count 0.760953488372093\n",
      "count 0.7617769230769231\n",
      "count 0.7626030534351145\n",
      "count 0.76325\n",
      "count 0.7639097744360902\n",
      "count 0.764731343283582\n",
      "count 0.7654814814814814\n",
      "count 0.766264705882353\n",
      "count 0.7668467153284672\n",
      "count 0.7675\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=1.0, bar_style='info', description='Validating', layout=Layout(flex='2'), m"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss is 0.24997368454933167\n",
      "count 0.7652789115646258\n",
      "count 0.7659324324324325\n",
      "count 0.7666778523489933\n",
      "count 0.7674733333333333\n",
      "count 0.7680662251655629\n",
      "count 0.7687039473684211\n",
      "count 0.7693921568627451\n",
      "count 0.7699805194805195\n",
      "count 0.7705870967741936\n",
      "count 0.7713269230769231\n",
      "count 0.7719235668789809\n",
      "count 0.772620253164557\n",
      "count 0.7733207547169811\n",
      "count 0.77395625\n",
      "count 0.774527950310559\n",
      "count 0.7751666666666667\n",
      "count 0.7756871165644171\n",
      "count 0.7762256097560976\n",
      "count 0.776860606060606\n",
      "count 0.7774036144578313\n",
      "count 0.7778562874251497\n",
      "count 0.7783452380952381\n",
      "count 0.7789289940828402\n",
      "count 0.779464705882353\n",
      "count 0.7799883040935672\n",
      "count 0.7806279069767442\n",
      "count 0.781242774566474\n",
      "count 0.7818505747126436\n",
      "count 0.7824\n",
      "count 0.7829375\n",
      "count 0.7834011299435029\n",
      "count 0.7839887640449438\n",
      "count 0.7844748603351955\n",
      "count 0.7849722222222222\n",
      "count 0.7855580110497238\n",
      "count 0.7860054945054945\n",
      "count 0.7865355191256831\n",
      "count 0.7870489130434782\n",
      "count 0.787627027027027\n",
      "count 0.7881774193548388\n",
      "count 0.7887326203208556\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=1.0, bar_style='info', description='Validating', layout=Layout(flex='2'), m"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss is 0.2426980435848236\n",
      "count 0.7858923076923077\n",
      "count 0.7864030612244898\n",
      "count 0.7869238578680203\n",
      "count 0.7875252525252525\n",
      "count 0.7879547738693468\n",
      "count 0.78844\n",
      "count 0.788955223880597\n",
      "count 0.7893861386138614\n",
      "count 0.7898374384236453\n",
      "count 0.7903725490196079\n",
      "count 0.790829268292683\n",
      "count 0.7912815533980583\n",
      "count 0.7917391304347826\n",
      "count 0.7923076923076923\n",
      "count 0.7927416267942584\n",
      "count 0.7931857142857143\n",
      "count 0.7936777251184834\n",
      "count 0.7941745283018868\n",
      "count 0.7945774647887324\n",
      "count 0.7950093457943925\n",
      "count 0.7954325581395348\n",
      "count 0.7959259259259259\n",
      "count 0.7963640552995391\n",
      "count 0.7967935779816514\n",
      "count 0.7972694063926941\n",
      "count 0.7977181818181818\n",
      "count 0.798131221719457\n",
      "count 0.7985405405405406\n",
      "count 0.7989372197309417\n",
      "count 0.7993928571428571\n",
      "count 0.7997688888888889\n",
      "count 0.8001637168141593\n",
      "count 0.8006299559471366\n",
      "count 0.8010701754385965\n",
      "count 0.8015065502183406\n",
      "count 0.8018826086956522\n",
      "count 0.8022943722943723\n",
      "count 0.8026163793103448\n",
      "count 0.8030128755364807\n",
      "count 0.8034102564102564\n",
      "count 0.8037148936170213\n",
      "count 0.8040847457627118\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=1.0, bar_style='info', description='Validating', layout=Layout(flex='2'), m"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss is 0.2367767095565796\n",
      "count 0.8012622950819672\n",
      "count 0.8016489795918368\n",
      "count 0.8019878048780488\n",
      "count 0.8023279352226721\n",
      "count 0.8026814516129033\n",
      "count 0.8030963855421687\n",
      "count 0.803448\n",
      "count 0.8038446215139442\n",
      "count 0.804234126984127\n",
      "count 0.8045889328063242\n",
      "count 0.8049566929133858\n",
      "count 0.8053725490196079\n",
      "count 0.80576171875\n",
      "count 0.80615953307393\n",
      "count 0.8066046511627907\n",
      "count 0.8069073359073359\n",
      "count 0.8072038461538461\n",
      "count 0.8075785440613027\n",
      "count 0.8079885496183206\n",
      "count 0.8083422053231939\n",
      "count 0.8087462121212121\n",
      "count 0.8091433962264151\n",
      "count 0.8094398496240601\n",
      "count 0.8097865168539325\n",
      "count 0.8101231343283583\n",
      "count 0.8104163568773234\n",
      "count 0.8107222222222222\n",
      "count 0.8110922509225093\n",
      "count 0.8114117647058824\n",
      "count 0.8117582417582417\n",
      "count 0.8120839416058394\n",
      "count 0.8123345454545454\n",
      "count 0.812695652173913\n",
      "count 0.813014440433213\n",
      "count 0.8133021582733813\n",
      "count 0.8136236559139784\n",
      "count 0.8139535714285714\n",
      "count 0.8142562277580071\n",
      "count 0.8145780141843971\n",
      "count 0.8149858657243816\n",
      "count 0.8152852112676057\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=1.0, bar_style='info', description='Validating', layout=Layout(flex='2'), m"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss is 0.24430200457572937\n",
      "count 0.8131535836177475\n",
      "count 0.8134489795918367\n",
      "count 0.8138033898305085\n",
      "count 0.8140675675675676\n",
      "count 0.8144040404040404\n",
      "count 0.8147114093959732\n",
      "count 0.8150334448160536\n",
      "count 0.8153066666666666\n",
      "count 0.8156378737541529\n",
      "count 0.8159039735099338\n",
      "count 0.8162145214521452\n",
      "count 0.8164835526315789\n",
      "count 0.8167344262295082\n",
      "count 0.8170130718954248\n",
      "count 0.8172964169381107\n",
      "count 0.8176168831168831\n",
      "count 0.8179288025889968\n",
      "count 0.8182193548387097\n",
      "count 0.8185434083601286\n",
      "count 0.8188141025641026\n"
     ]
    }
   ],
   "source": [
    "trainer = Trainer(max_nb_epochs=50,min_nb_epochs=1, gpus = 1)\n",
    "trainer.fit(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# #model.to(\"cpu\")\n",
    "# #model.device = \"cpu\"\n",
    "# while True:\n",
    "#     try:\n",
    "#         trainer = Trainer(max_nb_epochs=50,min_nb_epochs=1, gpus = 1)\n",
    "#         trainer.fit(model)\n",
    "#     except Exception as e:\n",
    "#         continue"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.model.save_pretrained(\"finetuned_model/model.softmax.k=5.count=0.652.layers=12\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## model.model.layers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "preds = evaluate_model(dev_dataset, model, max_ngrams = 5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "preds[0].keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "def pretty_print(sent, idx_arg1, idx_arg2):\n",
    "    \n",
    "    sent_lst = sent.split(\" \")\n",
    "    sent = \" \".join(sent_lst[:idx_arg1[0]]) + \" \" + colored(\" \".join(sent_lst[idx_arg1[0]:idx_arg1[1]]), \"red\") + \" \" + \" \".join(sent_lst[idx_arg1[1]:])\n",
    "    sent_lst = sent.split(\" \")\n",
    "    sent = \" \".join(sent_lst[:idx_arg2[0]]) + \" \" + colored(\" \".join(sent_lst[idx_arg2[0]:idx_arg2[1]]), \"blue\") + \" \" + \" \".join(sent_lst[idx_arg2[1]:])\n",
    "    return sent\n",
    "\n",
    "for p in preds:\n",
    "    sent = p[\"sent\"]\n",
    "    tokens = p[\"tokens\"]\n",
    "    range_arg1, range_arg2 = p[\"gold_arg1_range_tokens\"], p[\"gold_arg2_range_tokens\"]\n",
    "    \n",
    "    \n",
    "    print(\"Gold arg1: {}; Gold arg2: {}\".format(\" \".join(tokens[range_arg1[0]:range_arg1[1]]), \" \".join(tokens[range_arg2[0]:range_arg2[1]])))\n",
    "    pred_arg1, pred_arg2 = p[\"preds_arg1_tokens\"], p[\"preds_arg2_tokens\"]\n",
    "    ngram_pred_arg1_idx, ngram_pred_arg2_idx = p[\"all_ngrams\"][pred_arg1[0]], p[\"all_ngrams\"][pred_arg2[0]]\n",
    "    print(\"Pred arg1: {}; Pred arg2: {}\".format(\" \".join(tokens[ngram_pred_arg1_idx[0]:ngram_pred_arg1_idx[1]]),\n",
    "         \" \".join(tokens[ngram_pred_arg2_idx[0]:ngram_pred_arg2_idx[1]])))\n",
    "    \n",
    "    arg1_start = p[\"tok2orig\"][ngram_pred_arg1_idx[0]]\n",
    "    arg1_end = p[\"tok2orig\"][ngram_pred_arg1_idx[1]]\n",
    "    arg2_start = p[\"tok2orig\"][ngram_pred_arg2_idx[0]]\n",
    "    arg2_end = p[\"tok2orig\"][ngram_pred_arg2_idx[1]]\n",
    "    #print(p[\"preds_arg1_tokens\"][:] == p[\"preds_arg2_tokens\"][:])\n",
    "    print(pretty_print(sent, [arg1_start, arg1_end], [arg2_start, arg2_end]))\n",
    "    print(\"=================================================================\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "k = random.choice(range(100))\n",
    "\n",
    "sent1 = \"The use of 5 % <<ARG1:dextrose>> and sodium bicarbonate is an effective initial treatment for <<ARG2:hyperkalemia>> .\"\n",
    "sent2 = \"Cyclosporine is an immunosuppressant and is used to avoid organ transplant rejection .\"\n",
    "\n",
    "with torch.no_grad():\n",
    "    print(sent1)\n",
    "    print(\"-------------------------------\")\n",
    "    print(sent2)\n",
    "    print(\"-------------------------------\")\n",
    "    get_prediction(sent1, sent2, model.eval())\n",
    "\n",
    "print(\"===================================================\")\n",
    "    \n",
    "    \n",
    "sent1 = \"Suppose that a fraction <<ARG1:Q>> of all infected individuals is completely isolated and does not transmit the disease to <<ARG2:anyone>> .\"\n",
    "sent2 = \"Although the J class is isolated to a negative-pressure room , a few of its members could transmit the virus , by accident , to other people such as healthcare workers .\"\n",
    "\n",
    "with torch.no_grad():\n",
    "    print(sent1)\n",
    "    print(\"-------------------------------\")\n",
    "    print(sent2)\n",
    "    print(\"-------------------------------\")\n",
    "    get_prediction(sent1, sent2, model.eval())\n",
    "    \n",
    "    \n",
    "print(\"===================================================\")\n",
    "    \n",
    "    \n",
    "sent1 = \"Moreover , the <<ARG1:pathogen>> also spreads to humans through direct <<ARG2:contact with infected poultry>> and contaminated surfaces [ 5 ] .\"\n",
    "sent2 = \"The COVID-19 disease can spread in a population through infected symptomatic/asymptomatic individuals who come in contact directly/indirectly [ 4 ] .\"\n",
    "\n",
    "with torch.no_grad():\n",
    "    print(sent1)\n",
    "    print(\"-------------------------------\")\n",
    "    print(sent2)\n",
    "    print(\"-------------------------------\")\n",
    "    get_prediction(sent1, sent2, model.eval())\n",
    "    \n",
    "    \n",
    "print(\"===================================================\")\n",
    "    \n",
    "    \n",
    "sent1 = \"The low second trimester plasma MBL <<ARG1:level>> is not a risk factor for the development of <<ARG2:preterm birth>> .\"\n",
    "sent2 = \"Nevertheless , even 5 - 10 years intervals from the previous gestation do not increase the risk for PE .\"\n",
    "\n",
    "with torch.no_grad():\n",
    "    print(sent1)\n",
    "    print(\"-------------------------------\")\n",
    "    print(sent2)\n",
    "    print(\"-------------------------------\")\n",
    "    get_prediction(sent1, sent2, model.eval())\n",
    "    \n",
    "    \n",
    "print(\"===================================================\")\n",
    "    \n",
    "    \n",
    "sent1 = \"However , <<ARG1:glucose blood levels>> were reduced and insulin sensitivity was increased in <<ARG2:MTX2>> and MTX4 .\"\n",
    "sent2 = \"Both blood glucose and lipid profiles were reduced in the allogenic group [ 9 ] .\"\n",
    "\n",
    "with torch.no_grad():\n",
    "    print(sent1)\n",
    "    print(\"-------------------------------\")\n",
    "    print(sent2)\n",
    "    print(\"-------------------------------\")\n",
    "    get_prediction(sent1, sent2, model.eval())\n",
    "    \n",
    "    \n",
    "print(\"===================================================\")\n",
    "    \n",
    "    \n",
    "sent1 = \"It seems likely that the prevention and treatment of <<ARG1:AEx of IPF>> must focus on both <<ARG2:disease-specific>> ( e.g. , anti-fi brotic therapies ) and non-disease-specific ( e.g. , vaccination , prevention of stress ) areas .\"\n",
    "sent2 = \"Thus , the clinical management of SARS should consider not only antiviral but anti-inflammatory strategies as well .\"\n",
    "\n",
    "with torch.no_grad():\n",
    "    print(sent1)\n",
    "    print(\"-------------------------------\")\n",
    "    print(sent2)\n",
    "    print(\"-------------------------------\")\n",
    "    get_prediction(sent1, sent2, model.eval())\n",
    "    \n",
    "    \n",
    "    \n",
    "print(\"===================================================\")\n",
    "    \n",
    "    \n",
    "sent1 = \"The results indicate that supplementation of fish with <<ARG1:rosemary>> could improve the haematological and immunological properties and increase the survival rate after challenge with <<ARG2:S. iniae>> .\"\n",
    "sent2 = \"Recent studies have demonstrated that prolonged treatment with EP can ameliorate experimental ulcerative colitis and slow multiple tumor growth .\"\n",
    "\n",
    "with torch.no_grad():\n",
    "    print(sent1)\n",
    "    print(\"-------------------------------\")\n",
    "    print(sent2)\n",
    "    print(\"-------------------------------\")\n",
    "    get_prediction(sent1, sent2, model.eval())\n",
    "    \n",
    "    \n",
    "print(\"===================================================\")\n",
    "    \n",
    "    \n",
    "sent1 = \"In 2013 , an outbreak of <<ARG1:MERS-CoV>> occurred in the <<ARG2:Middle East>> , including Jordan ( 10 , 11 ) .\"\n",
    "sent2 = \"An outbreak of severe acute respiratory syndrome ( SARS ) was detected in Singapore at the beginning of March 2003 .\"\n",
    "\n",
    "with torch.no_grad():\n",
    "    print(sent1)\n",
    "    print(\"-------------------------------\")\n",
    "    print(sent2)\n",
    "    print(\"-------------------------------\")\n",
    "    get_prediction(sent1, sent2, model.eval())\n",
    "    \n",
    "    \n",
    "print(\"===================================================\")\n",
    "    \n",
    "\n",
    "for i in range(25):\n",
    "\n",
    "    sent1 = data[i][\"first\"]\n",
    "    sent2 = data[i][\"second\"].replace(\"ARG1:\", \"\").replace(\"ARG2:\",\"\")\n",
    "    with torch.no_grad():\n",
    "        print(sent1)\n",
    "        print(\"-------------------------------\")\n",
    "        print(data[i][\"second_with_arguments\"])\n",
    "        print(\"-------------------------------\")\n",
    "        get_prediction(sent1, sent2, model.eval())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#del model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.randn(1)*0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "sent = train_dataset[0][0]\n",
    "bert_tokens, orig_to_tok_map, tok_to_orig_map, tokens_tensor = model.tokenize(sent.split(\" \"))\n",
    "indexed_tokens = model.tokenizer.convert_tokens_to_ids(bert_tokens)\n",
    "tokens_tensor = torch.tensor([indexed_tokens])\n",
    "\n",
    "for d in train_dataset:\n",
    "    sent = d[0]\n",
    "    bert_tokens, orig_to_tok_map, tok_to_orig_map, tokens_tensor = model.tokenize(sent.split(\" \"))\n",
    "    print(len(bert_tokens))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataset[0][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(sent)\n",
    "print(bert_tokens)\n",
    "print(get_entity_range((1,3), orig_to_tok_map))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk import ngrams\n",
    "list(ngrams(range(10), 3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "q = get_all_ngrams_spans(10, [(3,5)], start_ind = 0, n_max=2)\n",
    "q"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "q[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "states = torch.randn(500,300)\n",
    "ngrams = get_all_ngrams_spans(len(states), [[0,4], [13, 16]], start_ind = 50)\n",
    "negatives = [states[ngram[0]:ngram[1]].mean(dim=0) for ngram in ngrams]\n",
    "negatives = torch.stack(negatives)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "negatives.shape, len(ngrams)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "list(range(2,2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.training_step([train_dataset[0]],0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataset[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "type(torch.zeros(1).item())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.linear_adrg1_1.bias[0:1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "s,idx,l,_ = train_dataset[1]\n",
    "idx = idx.detach().cpu().numpy()\n",
    "s.split(\" \")[idx[1][0][0]:idx[1][0][1]+1]\n",
    "print(s.split(\" \")[26:])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bert_tokens, orig_to_tok_map, tok_to_orig_map, tokens_tensor = model.tokenize(s.split(\" \"))\n",
    "sent1_range_arg1 = get_entity_range_multiword_expression(idx[0][0], orig_to_tok_map)\n",
    "sent1_range_arg2 = get_entity_range_multiword_expression(idx[0][1], orig_to_tok_map)\n",
    "sent2_range_arg1 = get_entity_range_multiword_expression(idx[1][0], orig_to_tok_map)\n",
    "sent2_range_arg2 = get_entity_range_multiword_expression(idx[1][1], orig_to_tok_map)\n",
    "l_tokens = orig_to_tok_map[l]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sent2_range_arg1\n",
    "bert_tokens_2 = bert_tokens[l_tokens:]\n",
    "bert_tokens_2[sent2_range_arg1[0]-l_tokens:sent2_range_arg1[1]-l_tokens]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "l_tokens"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "+"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
