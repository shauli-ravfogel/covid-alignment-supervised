{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The autoreload extension is already loaded. To reload it, use:\n",
      "  %reload_ext autoreload\n"
     ]
    }
   ],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "import spike_queries\n",
    "import pandas as pd\n",
    "import tqdm\n",
    "import pickle\n",
    "import random\n",
    "import itertools\n",
    "\n",
    "import torch\n",
    "from transformers import BertTokenizer\n",
    "from torch.utils.data import TensorDataset, DataLoader, RandomSampler, SequentialSampler\n",
    "from transformers import AutoTokenizer, AutoModel, AutoConfig\n",
    "from transformers import BertForSequenceClassification, AdamW, BertConfig, BertModel, AutoTokenizer, AutoModel, PreTrainedTokenizerFast\n",
    "import numpy as np\n",
    "from typing import List\n",
    "from torch import nn\n",
    "import pytorch_lightning as pl\n",
    "from pytorch_lightning import Trainer\n",
    "from torch.utils.data import DataLoader\n",
    "from torch.utils.data import Dataset\n",
    "from typing import Dict, Tuple\n",
    "from scipy.spatial.distance import cosine as cosine_distance\n",
    "from collections import defaultdict\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"queries2.txt\", \"r\") as f:\n",
    "    queries = f.readlines()\n",
    "    queries = [l.strip() for l in queries]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [],
   "source": [
    "queries = queries[:220]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i,q in enumerate(queries):\n",
    "    a = q.count(\"arg1:\") == q.count(\"arg2:\") == 1\n",
    "    if not a:\n",
    "        print(i,q)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [],
   "source": [
    "queries2results = defaultdict(list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  1%|          | 2/220 [00:24<44:02, 12.12s/it]\n"
     ]
    },
    {
     "ename": "HTTPError",
     "evalue": "HTTP Error 503: Service Temporarily Unavailable",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mHTTPError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-102-b3ac25d79914>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      6\u001b[0m     \u001b[0mq\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mid\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mq_and_id\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msplit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"\\t\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m     \u001b[0mid\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mid\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 8\u001b[0;31m     \u001b[0mdf\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mspike_queries\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mperform_query\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mq\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdataset_name\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnum_results\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mquery_type\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;31m#previously: word=Hawaii\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      9\u001b[0m     \u001b[0mqueries2results\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mid\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdf\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Desktop/spike_queries/query-example/spike_queries.py\u001b[0m in \u001b[0;36mperform_query\u001b[0;34m(query, dataset_name, num_results, query_type, remove_duplicates, lucene_query)\u001b[0m\n\u001b[1;32m     42\u001b[0m    \u001b[0mtsv_url\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mget_tsv_url\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mresponse\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mresults_limit\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnum_results\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbase_url\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mbase_url\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     43\u001b[0m    \u001b[0;31m#print(tsv_url)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 44\u001b[0;31m    \u001b[0mdf\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread_csv\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtsv_url\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msep\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m\"\\t\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     45\u001b[0m    \u001b[0;31m#if remove_duplicates:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     46\u001b[0m    \u001b[0;31m#     df = df.drop_duplicates(\"sentence_text\")\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/envs/py3/lib/python3.7/site-packages/pandas/io/parsers.py\u001b[0m in \u001b[0;36mparser_f\u001b[0;34m(filepath_or_buffer, sep, delimiter, header, names, index_col, usecols, squeeze, prefix, mangle_dupe_cols, dtype, engine, converters, true_values, false_values, skipinitialspace, skiprows, skipfooter, nrows, na_values, keep_default_na, na_filter, verbose, skip_blank_lines, parse_dates, infer_datetime_format, keep_date_col, date_parser, dayfirst, cache_dates, iterator, chunksize, compression, thousands, decimal, lineterminator, quotechar, quoting, doublequote, escapechar, comment, encoding, dialect, error_bad_lines, warn_bad_lines, delim_whitespace, low_memory, memory_map, float_precision)\u001b[0m\n\u001b[1;32m    683\u001b[0m         )\n\u001b[1;32m    684\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 685\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0m_read\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilepath_or_buffer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    686\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    687\u001b[0m     \u001b[0mparser_f\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__name__\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/envs/py3/lib/python3.7/site-packages/pandas/io/parsers.py\u001b[0m in \u001b[0;36m_read\u001b[0;34m(filepath_or_buffer, kwds)\u001b[0m\n\u001b[1;32m    438\u001b[0m     \u001b[0;31m# See https://github.com/python/mypy/issues/1297\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    439\u001b[0m     fp_or_buf, _, compression, should_close = get_filepath_or_buffer(\n\u001b[0;32m--> 440\u001b[0;31m         \u001b[0mfilepath_or_buffer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mencoding\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcompression\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    441\u001b[0m     )\n\u001b[1;32m    442\u001b[0m     \u001b[0mkwds\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"compression\"\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcompression\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/envs/py3/lib/python3.7/site-packages/pandas/io/common.py\u001b[0m in \u001b[0;36mget_filepath_or_buffer\u001b[0;34m(filepath_or_buffer, encoding, compression, mode)\u001b[0m\n\u001b[1;32m    194\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    195\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0m_is_url\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilepath_or_buffer\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 196\u001b[0;31m         \u001b[0mreq\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0murlopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilepath_or_buffer\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    197\u001b[0m         \u001b[0mcontent_encoding\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mreq\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mheaders\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Content-Encoding\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    198\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mcontent_encoding\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m\"gzip\"\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/envs/py3/lib/python3.7/urllib/request.py\u001b[0m in \u001b[0;36murlopen\u001b[0;34m(url, data, timeout, cafile, capath, cadefault, context)\u001b[0m\n\u001b[1;32m    220\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    221\u001b[0m         \u001b[0mopener\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_opener\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 222\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mopener\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0murl\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtimeout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    223\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    224\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0minstall_opener\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mopener\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/envs/py3/lib/python3.7/urllib/request.py\u001b[0m in \u001b[0;36mopen\u001b[0;34m(self, fullurl, data, timeout)\u001b[0m\n\u001b[1;32m    529\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mprocessor\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mprocess_response\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mprotocol\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    530\u001b[0m             \u001b[0mmeth\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mgetattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mprocessor\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmeth_name\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 531\u001b[0;31m             \u001b[0mresponse\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmeth\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mreq\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mresponse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    532\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    533\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mresponse\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/envs/py3/lib/python3.7/urllib/request.py\u001b[0m in \u001b[0;36mhttp_response\u001b[0;34m(self, request, response)\u001b[0m\n\u001b[1;32m    639\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0;36m200\u001b[0m \u001b[0;34m<=\u001b[0m \u001b[0mcode\u001b[0m \u001b[0;34m<\u001b[0m \u001b[0;36m300\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    640\u001b[0m             response = self.parent.error(\n\u001b[0;32m--> 641\u001b[0;31m                 'http', request, response, code, msg, hdrs)\n\u001b[0m\u001b[1;32m    642\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    643\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mresponse\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/envs/py3/lib/python3.7/urllib/request.py\u001b[0m in \u001b[0;36merror\u001b[0;34m(self, proto, *args)\u001b[0m\n\u001b[1;32m    567\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mhttp_err\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    568\u001b[0m             \u001b[0margs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mdict\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'default'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'http_error_default'\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0morig_args\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 569\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call_chain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    570\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    571\u001b[0m \u001b[0;31m# XXX probably also want an abstract factory that knows when it makes\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/envs/py3/lib/python3.7/urllib/request.py\u001b[0m in \u001b[0;36m_call_chain\u001b[0;34m(self, chain, kind, meth_name, *args)\u001b[0m\n\u001b[1;32m    501\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mhandler\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mhandlers\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    502\u001b[0m             \u001b[0mfunc\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mgetattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mhandler\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmeth_name\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 503\u001b[0;31m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    504\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mresult\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    505\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/envs/py3/lib/python3.7/urllib/request.py\u001b[0m in \u001b[0;36mhttp_error_default\u001b[0;34m(self, req, fp, code, msg, hdrs)\u001b[0m\n\u001b[1;32m    647\u001b[0m \u001b[0;32mclass\u001b[0m \u001b[0mHTTPDefaultErrorHandler\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mBaseHandler\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    648\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mhttp_error_default\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mreq\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfp\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcode\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmsg\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhdrs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 649\u001b[0;31m         \u001b[0;32mraise\u001b[0m \u001b[0mHTTPError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mreq\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfull_url\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcode\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmsg\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhdrs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfp\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    650\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    651\u001b[0m \u001b[0;32mclass\u001b[0m \u001b[0mHTTPRedirectHandler\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mBaseHandler\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mHTTPError\u001b[0m: HTTP Error 503: Service Temporarily Unavailable"
     ]
    }
   ],
   "source": [
    "dataset_name = \"covid19\"\n",
    "num_results = 100\n",
    "query_type = \"syntactic\"\n",
    "\n",
    "for q_and_id in tqdm.tqdm(queries, total = len(queries)):\n",
    "    q, id = q_and_id.split(\"\\t\")\n",
    "    id = int(id)\n",
    "    df = spike_queries.perform_query(q, dataset_name, num_results, query_type) #previously: word=Hawaii\n",
    "    queries2results[id].append(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "queries2results[1][0].head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"queries2results.pickle\", \"wb\") as f:\n",
    "     pickle.dump(queries2results, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"queries2results.pickle\", \"rb\") as f:\n",
    "    queries2results = pickle.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict_keys([1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 0])"
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "queries2results.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/shauli/miniconda3/envs/py3/lib/python3.7/site-packages/ipykernel_launcher.py:4: FutureWarning: Sorting because non-concatenation axis is not aligned. A future version\n",
      "of pandas will change to not sort by default.\n",
      "\n",
      "To accept the future behavior, pass 'sort=False'.\n",
      "\n",
      "To retain the current behavior and silence the warning, pass 'sort=True'.\n",
      "\n",
      "  after removing the cwd from sys.path.\n"
     ]
    }
   ],
   "source": [
    "queries2results_new = dict()\n",
    "for k,dfs in queries2results.items():\n",
    "    if k == 0: continue\n",
    "    queries2results_new[k] = pd.concat(dfs, axis=0)\n",
    "    \n",
    "queries2results = queries2results_new"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [],
   "source": [
    "ids = set([int(l.split(\"\\t\")[-1]) for l in queries])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1 136161\n",
      "2 54289\n",
      "3 90000\n",
      "4 234256\n",
      "5 370881\n",
      "6 93636\n",
      "7 63504\n",
      "8 4\n",
      "9 130321\n",
      "10 158404\n",
      "11 111556\n",
      "12 7921\n",
      "13 50625\n",
      "14 134689\n",
      "15 41616\n"
     ]
    }
   ],
   "source": [
    "data = []\n",
    "for id in ids:\n",
    "    results = queries2results[id]\n",
    "    sents, arg1_first, arg2_first = results[\"sentence_text\"].tolist(), results[\"arg1_first_index\"].tolist(), results[\"arg2_first_index\"].tolist()\n",
    "    arg1_last, arg2_last = results[\"arg1_last_index\"].tolist(), results[\"arg2_last_index\"].tolist()\n",
    "    \n",
    "    sents_with_args = []\n",
    "    for s,arg1_ind,arg2_ind, arg1_ind_last, arg2_ind_last in zip(sents,arg1_first,arg2_first, arg1_last, arg2_last):\n",
    "        s_lst = s.split(\" \")\n",
    "        if arg1_ind > arg2_ind:\n",
    "            arg1_ind, arg2_ind = arg2_ind, arg1_ind\n",
    "            arg1_ind_last, arg2_ind_last = arg2_ind_last, arg1_ind_last\n",
    "            arg1_str, arg2_str = \"ARG2:\", \"ARG1:\"\n",
    "        else:\n",
    "            arg1_str, arg2_str = \"ARG1:\", \"ARG2:\"\n",
    "        s_with_args = s_lst[:arg1_ind] + [arg1_str+s_lst[arg1_ind]] + s_lst[arg1_ind+1:arg2_ind] + [arg2_str+s_lst[arg2_ind]] + s_lst[arg2_ind+1:]\n",
    "        s_with_args = \" \".join(s_with_args)\n",
    "        sents_with_args.append({\"sent\": s_with_args, \"start_1\": arg1_ind, \"start_2\": arg2_ind, \"end_1\": arg1_ind_last,\n",
    "                               \"end_2\": arg2_ind_last})\n",
    "    \n",
    "    max_number_of_pairs = 450\n",
    "    pairs = list(itertools.product(sents_with_args, repeat=2))\n",
    "    print(id, len(pairs))\n",
    "    random.shuffle(pairs)\n",
    "    for pair in pairs[:max_number_of_pairs]:\n",
    "        data.append({\"first\": pair[0][\"sent\"], \"second\": pair[1][\"sent\"], \"query\": q, \"first_arg1\": (pair[0][\"start_1\"], pair[0][\"end_1\"]),\n",
    "                    \"first_arg2\": (pair[0][\"start_2\"], pair[0][\"end_2\"]), \"second_arg1\": (pair[1][\"start_1\"], pair[1][\"end_1\"]),\n",
    "                   \"second_arg2\": (pair[1][\"start_2\"], pair[1][\"end_2\"])})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "6304"
      ]
     },
     "execution_count": 72,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [],
   "source": [
    "random.shuffle(data)\n",
    "data[0]\n",
    "\n",
    "with open(\"data.pickle\", \"wb\") as f:\n",
    "    pickle.dump(data, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "with open(\"data.pickle\", \"rb\") as f:\n",
    "    data = pickle.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "\n",
    "with open(\"data.txt\", \"w\") as f:\n",
    "    for d in data:\n",
    "        first, second = d[\"first\"], d[\"second\"]\n",
    "        first_arg1 = d[\"first_arg1\"]\n",
    "        first_arg2 = d[\"first_arg2\"]\n",
    "        second_arg1 = d[\"second_arg1\"]\n",
    "        second_arg2 = d[\"second_arg2\"]\n",
    "        \n",
    "        elems = [first, second, first_arg1, first_arg2, second_arg1, second_arg2]\n",
    "        keys = [\"first\", \"second\", \"first_arg1\", \"first_arg2\"]\n",
    "        \n",
    "        f.write(json.dumps(d) + \"\\n\")\n",
    "        #f.write(d[\"first\"] + \"\\t\" + d[\"second\"] + \"\\t\" + d[\"query\"] + \"\\t\" + \"-\".join(d[\"first_arg1\"])+ \"\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'first': 'The ultimate treatment would be liver transplant , but ARG1:this is contraindicated in ARG2:patient with such short sobriety .',\n",
       " 'second': 'This could leave us with only 1 antiviral class of drugs ( ie , neuraminidase inhibitors ) and no treatment option for infants , because ARG1:oseltamivir is contraindicated in ARG2:children less than 1 year of age based on a study , done by the manufacturer , showing increased central nervous system drug concentrations in a juvenile animal model .',\n",
       " 'query': '<>arg1:SCD $[l]polymorphism is a $risk factor for <>arg2:something',\n",
       " 'first_arg1': (9, 9),\n",
       " 'first_arg2': (13, 13),\n",
       " 'second_arg1': (25, 25),\n",
       " 'second_arg2': (29, 29)}"
      ]
     },
     "execution_count": 76,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "random.shuffle(data)\n",
    "data[9]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [],
   "source": [
    "global count\n",
    "count = 0\n",
    "global total\n",
    "total = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [],
   "source": [
    "class BertModel(pl.LightningModule):\n",
    "\n",
    "    def __init__(self, train_dataset: Dataset, dev_dataset: Dataset, batch_size, device: str, mode: str = \"eval\"):\n",
    "        \n",
    "        super().__init__()\n",
    "        \n",
    "        self.device = device\n",
    "        config = AutoConfig.from_pretrained('allenai/scibert_scivocab_uncased', output_hidden_states=True)\n",
    "        self.tokenizer = AutoTokenizer.from_pretrained('allenai/scibert_scivocab_uncased')\n",
    "        self.model = AutoModel.from_pretrained('allenai/scibert_scivocab_uncased', config=config)    \n",
    "        self.train_dataset = train_dataset\n",
    "        self.dev_dataset = dev_dataset\n",
    "        self.linear_arg1_1 = torch.nn.Linear(768, 128)\n",
    "        self.linear_arg2_1 = torch.nn.Linear(768, 128)\n",
    "        self.linear_arg1_2 = self.linear_arg1_1 #torch.nn.Linear(768, 256)\n",
    "        self.linear_arg2_2 = self.linear_arg2_1 #torch.nn.Linear(768, 256)\n",
    "        \n",
    "        if mode == \"eval\":\n",
    "            \n",
    "            self.model.eval()\n",
    "        else:\n",
    "            self.model.train()\n",
    "        \n",
    "        for p in self.model.parameters():\n",
    "            p.requires_grad = False\n",
    "        for p in self.model.encoder.layer[-1].parameters():\n",
    "            p.requires_grad = True\n",
    "        for p in self.model.encoder.layer[-2].parameters():\n",
    "            p.requires_grad = False       \n",
    "\n",
    "        for p in self.model.embeddings.parameters():\n",
    "            p.requires_grad = False\n",
    "            \n",
    "        self.linear_arg1_1.requires_grad = True\n",
    "        self.linear_arg2_1.requires_grad = True\n",
    "        self.linear_arg1_2.requires_grad = True\n",
    "        self.linear_arg2_2.requires_grad = True\n",
    "        \n",
    "    \n",
    "        self.train_gen = torch.utils.data.DataLoader(self.train_dataset, batch_size=batch_size, drop_last=False, shuffle=True)\n",
    "        self.dev_gen = torch.utils.data.DataLoader(self.dev_dataset, batch_size=batch_size, drop_last=False, shuffle=False)\n",
    "        self.acc = None\n",
    "\n",
    "        \n",
    "    def tokenize(self, original_sentence: List[str]) -> Tuple[List[str], Dict[int, int]]:\n",
    "\n",
    "        \"\"\"\n",
    "        Parameters\n",
    "        ----------\n",
    "        Returns\n",
    "        -------\n",
    "        bert_tokens: The sentence, tokenized by BERT tokenizer.\n",
    "        orig_to_tok_map: An output dictionary consisting of a mapping (alignment) between indices in the original tokenized sentence, and indices in the sentence tokenized by the BERT tokenizer. See https://github.com/google-research/bert\n",
    "        \"\"\"\n",
    "\n",
    "        bert_tokens = [\"[CLS]\"]\n",
    "        orig_to_tok_map = {}\n",
    "        tok_to_orig_map = {}\n",
    "        has_subwords = False\n",
    "        is_subword = []\n",
    "\n",
    "        for i, w in enumerate(original_sentence):\n",
    "            tokenized_w = self.tokenizer.tokenize(w)\n",
    "            has_subwords = len(tokenized_w) > 1\n",
    "            is_subword.append(has_subwords)\n",
    "            bert_tokens.extend(tokenized_w)\n",
    "\n",
    "            orig_to_tok_map[i] = len(bert_tokens) - 1\n",
    "\n",
    "        tok_to_orig_map = {}\n",
    "\n",
    "        bert_tokens.append(\"[SEP]\")\n",
    "        tok_to_orig_map = get_tok_to_orig_map(orig_to_tok_map, len(original_sentence), len(bert_tokens))        \n",
    "        indexed_tokens = self.tokenizer.convert_tokens_to_ids(bert_tokens)\n",
    "        tokens_tensor = torch.tensor([indexed_tokens]).to(self.device)\n",
    "\n",
    "        return (bert_tokens, orig_to_tok_map, tok_to_orig_map, tokens_tensor)\n",
    "    \n",
    "    \n",
    "    def forward(self, x):\n",
    "        \n",
    "        outputs = self.model(x)\n",
    "        states = outputs[0][0] #[seq_len, 768]\n",
    "        return states\n",
    "    \n",
    "    def forward_with_loss_calculation2(self, bert_tokens, x, range_sent1, range_sent2, orig_to_tok_map, l, l_tokens):\n",
    "        \n",
    "        outputs = self.model(x)\n",
    "        states = outputs[0][0] #[seq_len, 768]\n",
    "        states = states / (torch.norm(states, dim = 1, keepdim = True)+1e-7)\n",
    "        \n",
    "        arg1_sent1, arg2_sent1 = range_sent1\n",
    "        arg1_sent2, arg2_sent2 = range_sent2\n",
    "        \n",
    "        #print(range_sent1)\n",
    "        #print(arg1_sent1, arg2_sent1)\n",
    "        #print(range_sent2)\n",
    "        #print(arg1_sent2, arg2_sent2)\n",
    "        #print(states[arg1_sent1[0]:arg1_sent1[1]].shape)\n",
    "        #print(\"sent1 args (gold):\", bert_tokens[arg1_sent1[0]+3:arg1_sent1[1]], bert_tokens[arg2_sent1[0]+3:arg2_sent1[1]])\n",
    "        #print(\"sent2 args (gold):\", bert_tokens[arg1_sent2[0]:arg1_sent2[1]], bert_tokens[arg2_sent2[0]:arg2_sent2[1]])\n",
    "        #print(\"------------------------------------------------\")\n",
    "        \n",
    "        sent1_arg1_vec, sent1_arg2_vec = states[arg1_sent1[0]+3:arg1_sent1[1]].mean(dim=0), states[arg2_sent1[0]+3:arg2_sent1[1]].mean(dim=0)\n",
    "        sent2_arg1_vec, sent2_arg2_vec = states[arg1_sent2[0]:arg1_sent2[1]].mean(dim=0), states[arg2_sent2[0]:arg2_sent2[1]].mean(dim=0)\n",
    "        #sent1_arg1_vec, sent1_arg2_vec = states[arg1_sent1[0]:arg1_sent1[1]].mean(dim=0), states[arg2_sent1[0]:arg2_sent1[1]].mean(dim=0)\n",
    "        #sent2_arg1_vec, sent2_arg2_vec = states[arg1_sent2[0]:arg1_sent2[1]].mean(dim=0), states[arg2_sent2[0]:arg2_sent2[1]].mean(dim=0)\n",
    "\n",
    "        \n",
    "        dists_arg1 = ((self.linear_arg1_1(states)-self.linear_arg1_2(sent1_arg1_vec))**2).sum(dim = 1).detach().cpu().numpy()\n",
    "        dists_arg2 = ((self.linear_arg2_1(states)-self.linear_arg2_2(sent1_arg2_vec)**2)).sum(dim = 1).detach().cpu().numpy()       \n",
    "        #states_projected = self.linear_arg1_1(states)\n",
    "        #arg1_sent1_projected = self.linear_arg1_2(sent1_arg1_vec)\n",
    "        #arg2_sent1_projected = self.linear_arg2_2(sent1_arg2_vec)\n",
    "        #dists_arg1 = cosine_distance(arg1_sent1_projected, states_projected)\n",
    "        #dists_arg2 = cosine_distance(arg2_sent1_projected, states_projected)\n",
    "        \n",
    "        \n",
    "        mask_gold_arg1 = np.zeros_like(dists_arg1)\n",
    "        mask_gold_arg2 = np.zeros_like(dists_arg2)\n",
    "        mask_gold_arg1[arg1_sent1[0]:arg1_sent1[1]] = 1e6\n",
    "        mask_gold_arg1[arg1_sent2[0]:arg1_sent2[1]] = 1e6\n",
    "        mask_gold_arg2[arg2_sent1[0]:arg2_sent1[1]] = 1e6\n",
    "        mask_gold_arg2[arg2_sent2[0]:arg2_sent2[1]] = 1e6\n",
    "        mask_gold_arg2[:l_tokens] = 1e6\n",
    "        mask_gold_arg1[:l_tokens] = 1e6\n",
    "\n",
    "        \n",
    "        idx_arg1 = np.argsort(dists_arg1+mask_gold_arg1)\n",
    "        idx_arg2 = np.argsort(dists_arg2+mask_gold_arg2)\n",
    "        k = 0# if np.random.random() < 0.5 else random.choice(range(10))\n",
    "        \n",
    "        alpha = 1\n",
    "        dist_arg1_argmax = alpha*(self.linear_arg1_2(sent1_arg1_vec) - self.linear_arg1_1(states[idx_arg1[k]])).norm()#**2\n",
    "        dist_arg2_argmax = alpha*(self.linear_arg2_2(sent1_arg2_vec) - self.linear_arg2_1(states[idx_arg2[k]])).norm()#**2\n",
    "        dist_arg1_gold = alpha*(self.linear_arg1_2(sent1_arg1_vec) - self.linear_arg1_1(sent2_arg1_vec)).norm()#**2\n",
    "        dist_arg2_gold = alpha*(self.linear_arg2_2(sent1_arg2_vec) - self.linear_arg2_1(sent2_arg2_vec)).norm()#**2\n",
    "        \n",
    "        #print(\"arg1-argmax, arg1-gold: {}, {}\".format(dist_arg1_argmax, dist_arg1_gold))\n",
    "        #print(\"arg2-argmax, arg2-gold: {}, {}\".format(dist_arg2_argmax, dist_arg2_gold))\n",
    "        \n",
    "        # softmax triplet\n",
    "        \n",
    "        z = torch.max(dist_arg1_argmax, dist_arg1_gold)\n",
    "        temp = 2\n",
    "        pos_arg1 = torch.exp((dist_arg1_gold - z)/temp)\n",
    "        neg_arg1 = torch.exp((dist_arg1_argmax - z)/temp)\n",
    "        loss_arg1 = (pos_arg1 / (pos_arg1 + neg_arg1))**2\n",
    "\n",
    "        z = torch.max(dist_arg2_argmax, dist_arg2_gold)\n",
    "        pos_arg2 = torch.exp((dist_arg2_gold - z)/temp)\n",
    "        neg_arg2 = torch.exp((dist_arg2_argmax - z)/temp)\n",
    "        loss_arg2 = (pos_arg2 / (pos_arg2 + neg_arg2))**2\n",
    "\n",
    "        alpha = 0.005\n",
    "        loss_arg1 = torch.max(torch.zeros(1).to(self.device), dist_arg1_gold - dist_arg1_argmax + alpha)\n",
    "        loss_arg2 = torch.max(torch.zeros(1).to(self.device), dist_arg2_gold - dist_arg2_argmax + alpha)\n",
    "        #print(dist_arg1_gold.detach().cpu().numpy().item(), dist_arg1_argmax.detach().cpu().numpy().item(), dist_arg2_gold.detach().cpu().numpy().item(), dist_arg2_argmax.detach().cpu().numpy().item())\n",
    "        global count\n",
    "        global total\n",
    "        if pos_arg1 < neg_arg1 and pos_arg2 < neg_arg2:\n",
    "            count += 1\n",
    "        total += 1                                                      \n",
    "        # check\n",
    "        \n",
    "        if (not np.isnan(loss_arg2.detach().cpu().numpy().item())) and (not np.isnan(loss_arg1.detach().cpu().numpy().item())):\n",
    "            \n",
    "            loss = loss_arg1 + loss_arg2\n",
    "        else:\n",
    "            \n",
    "            if not np.isnan(loss_arg2.detach().cpu().numpy().item()):\n",
    "                loss = loss_arg2\n",
    "            else:\n",
    "                loss = loss_arg1\n",
    "            \n",
    "        if loss.detach().cpu().numpy().item() > 1e4:\n",
    "            print(\"EEEEE\")\n",
    "            print(dist_arg1_gold, dist_arg1_argmax, dist_arg2_gold, dist_arg2_argmax)\n",
    "            print(\"================================\")\n",
    "            print(dists_arg1)\n",
    "            print(\"--------------\")\n",
    "            print(dists_arg2)\n",
    "            return\n",
    "        return loss, np.argsort(dists_arg1+mask_gold_arg1)\n",
    "    \n",
    "    def forward_with_loss_calculation(self, x, sent1_idx, sent2_idx, orig_to_tok_map, tok_to_orig_map, l, l_tokens):\n",
    "        \n",
    "        outputs = self.model(x)\n",
    "        states = outputs[0][0] #[seq_len, 768]\n",
    "        #states = states/torch.norm(states, dim = 1, keepdim = True)\n",
    "        \n",
    "        sent1_idx_arg1 = sent1_idx[0].detach().cpu().numpy().item()\n",
    "        sent1_idx_arg2 = sent1_idx[1].detach().cpu().numpy().item()\n",
    "        gold_arg1_sent1 = orig_to_tok_map[sent1_idx_arg1]\n",
    "        gold_arg2_sent1 = orig_to_tok_map[sent1_idx_arg2]\n",
    "        \n",
    "        sent1_arg1_vec, sent1_arg2_vec = states[gold_arg1_sent1], states[gold_arg2_sent1]\n",
    "        \n",
    "        states_sent2 = states[orig_to_tok_map[l.detach().cpu().numpy().item()]:]  \n",
    "        \n",
    "        sims_arg1 = sent1_arg1_vec @ states.T\n",
    "        sims_arg2 = sent1_arg2_vec @ states.T\n",
    "        \n",
    "        sent2_idx_arg1 = sent2_idx[0].detach().cpu().numpy().item()\n",
    "        sent2_idx_arg2 = sent2_idx[1].detach().cpu().numpy().item()\n",
    "        gold_arg1_sent2, gold_arg2_sent2 = orig_to_tok_map[sent2_idx_arg1], orig_to_tok_map[sent2_idx_arg2]\n",
    "\n",
    "        dists_arg1 = ((self.linear_arg1(states-sent1_arg1_vec))**2).sum(dim = 1).detach().cpu().numpy()\n",
    "        dists_arg2 = ((self.linear_arg2(states-sent1_arg2_vec)**2)).sum(dim = 1).detach().cpu().numpy()\n",
    "               \n",
    "        mask_gold_arg1 = np.zeros_like(dists_arg1)\n",
    "        mask_gold_arg2 = np.zeros_like(dists_arg2)\n",
    "        mask_gold_arg1[gold_arg1_sent2] = 1e6\n",
    "        mask_gold_arg2[gold_arg2_sent2] = 1e6\n",
    "        mask_gold_arg2[:l_tokens] = 1e6\n",
    "        mask_gold_arg1[:l_tokens] = 1e6\n",
    "        \n",
    "        if np.random.random() < 0.0*1e-1:\n",
    "            print(dists_arg1+mask_gold_arg2)\n",
    "            print(\"=========================\")\n",
    "        \n",
    "        idx_arg1 = np.argsort(dists_arg1+mask_gold_arg1)\n",
    "        idx_arg2 = np.argsort(dists_arg2+mask_gold_arg2)\n",
    "        \n",
    "        k = 0 #random.choice(range(0,7))\n",
    "        #idx_arg1 = [orig_to_tok_map[i] for i in orig_to_tok_map.keys() if i != sent2_idx_arg1 and i > l]\n",
    "        #idx_arg2 = [orig_to_tok_map[i] for i in orig_to_tok_map.keys() if i != sent2_idx_arg2 and i > l]\n",
    "        #random.shuffle(idx_arg1)\n",
    "        #random.shuffle(idx_arg2)\n",
    "        \n",
    "        dist_arg1_argmax = (self.linear_arg1(sent1_arg1_vec - states[idx_arg1[k]])).norm()#**2\n",
    "        dist_arg2_argmax = (self.linear_arg2(sent1_arg2_vec - states[idx_arg2[k]])).norm()#**2\n",
    "        dist_arg1_gold = (self.linear_arg1(sent1_arg1_vec - states[gold_arg1_sent2])).norm()#**2\n",
    "        dist_arg2_gold = (self.linear_arg2(sent1_arg2_vec - states[gold_arg2_sent2])).norm()#**2\n",
    "        \n",
    "        \n",
    "        #alpha = 0.01\n",
    "        #loss_arg1 = torch.max(torch.zeros(1).to(self.device), -sim_arg1_gold + most_sim_arg1 + alpha)\n",
    "        #loss_arg2 = torch.max(torch.zeros(1).to(self.device), -sim_arg2_gold + most_sim_arg2 + alpha)\n",
    "        alpha = 0.05\n",
    "        loss_arg1 = torch.max(torch.zeros(1).to(self.device), dist_arg1_gold - dist_arg1_argmax + alpha)\n",
    "        loss_arg2 = torch.max(torch.zeros(1).to(self.device), dist_arg2_gold - dist_arg2_argmax + alpha)\n",
    "\n",
    "        # softmax triplet\n",
    "        \n",
    "        z = torch.max(dist_arg1_argmax, dist_arg1_gold)\n",
    "        temp = 1\n",
    "        pos_arg1 = torch.exp((dist_arg1_gold - z)/temp)\n",
    "        neg_arg1 = torch.exp((dist_arg1_argmax - z)/temp)\n",
    "        loss_arg1 = (pos_arg1 / (pos_arg1 + neg_arg1))**2\n",
    "\n",
    "        z = torch.max(dist_arg2_argmax, dist_arg2_gold)\n",
    "        pos_arg2 = torch.exp((dist_arg2_gold - z)/temp)\n",
    "        neg_arg2 = torch.exp((dist_arg2_argmax - z)/temp)\n",
    "        loss_arg2 = (pos_arg2 / (pos_arg2 + neg_arg2))**2\n",
    "                                                               \n",
    "        # check\n",
    "        global count\n",
    "        \n",
    "        if tok_to_orig_map[idx_arg1[0]] == sent2_idx_arg1:\n",
    "            print(\"yay\",)\n",
    "            count += 1\n",
    "            loss_arg1 = torch.zeros(1).to(self.device).squeeze()\n",
    "            \n",
    "        if tok_to_orig_map[idx_arg2[0]] == sent2_idx_arg2:\n",
    "            print(\"yay2\")\n",
    "            count += 1\n",
    "            loss_arg2 = torch.zeros(1).to(self.device).squeeze()                                                      \n",
    "            \n",
    "        loss = loss_arg1 + loss_arg2\n",
    "        return loss, np.argsort(dists_arg1+mask_gold_arg1)\n",
    "    \n",
    "    def training_step(self, batch, batch_nb):\n",
    "        \n",
    "        sents_concat, sent1_idx, sent2_idx, l = batch\n",
    "        sent1_idx = [x.detach().cpu().numpy().item() for x in sent1_idx]\n",
    "        sent2_idx = [x.detach().cpu().numpy().item() for x in sent2_idx]\n",
    "        \n",
    "        #print(sents_concat)\n",
    "        #print(\"---------------------------------------------\")\n",
    "        bert_tokens, orig_to_tok_map, tok_to_orig_map, tokens_tensor = self.tokenize(sents_concat[0].split(\" \"))        \n",
    "        l_tokens = len(bert_tokens[:orig_to_tok_map[l.detach().cpu().numpy().item()-1]]) \n",
    "        sent1_range_arg1 = get_entity_range(sent1_idx[0], orig_to_tok_map)\n",
    "        sent1_range_arg2 = get_entity_range(sent1_idx[1], orig_to_tok_map)\n",
    "        sent2_range_arg1 = get_entity_range(sent2_idx[0], orig_to_tok_map)\n",
    "        sent2_range_arg2 = get_entity_range(sent2_idx[1], orig_to_tok_map)\n",
    "        range_sent1 = (sent1_range_arg1,sent1_range_arg2)\n",
    "        range_sent2 = (sent2_range_arg1,sent2_range_arg2)\n",
    "        \n",
    "        loss, argsort = self.forward_with_loss_calculation2(bert_tokens, tokens_tensor, range_sent1, range_sent2, orig_to_tok_map, l, l_tokens)\n",
    "        \n",
    "        if np.isnan(loss.detach().cpu().numpy().item()) or loss.detach().cpu().numpy().item() > 1e4:\n",
    "            print(\"ERRROR!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!\")\n",
    "            print(sents_concat, range_sent1, range_sent2, sent1_idx, sent2_idx)\n",
    "            return {\"loss\": loss*0}\n",
    "        #loss, argsort = self.forward_with_loss_calculation(tokens_tensor, sent1_idx, sent2_idx, orig_to_tok_map,tok_to_orig_map, l, l_tokens)\n",
    "        #print(sents_concat)\n",
    "        #print(argsort[:5])\n",
    "        #print(\"preds\", bert_tokens[argsort[0]], bert_tokens[argsort[1]], bert_tokens[argsort[2]])\n",
    "        #print(\"gold\", bert_tokens[orig_to_tok_map[sent2_idx[0]]])\n",
    "        #if np.random.random() < 1e-3:\n",
    "        if total%1000 == 0:\n",
    "            print(\"count\", count/total)\n",
    "        #print(\"==================================\")\n",
    "        return {'loss': loss}\n",
    "    \n",
    "    def validation_step(self, batch, batch_nb):\n",
    "\n",
    "        sents_concat, sent1_idx, sent2_idx, l = batch\n",
    "        #print(sent1_idx, type(sent1_idx))\n",
    "        \n",
    "        sent1_idx = [x.detach().cpu().numpy().item() for x in sent1_idx]\n",
    "        sent2_idx = [x.detach().cpu().numpy().item() for x in sent2_idx]\n",
    "        \n",
    "        bert_tokens, orig_to_tok_map, tok_to_orig_map, tokens_tensor = self.tokenize(sents_concat[0].split(\" \"))\n",
    "        l_tokens = len(bert_tokens[:orig_to_tok_map[l.detach().cpu().numpy().item()-1]]) \n",
    "        sent1_range_arg1 = get_entity_range(sent1_idx[0], orig_to_tok_map)\n",
    "        sent1_range_arg2 = get_entity_range(sent1_idx[1], orig_to_tok_map)\n",
    "        sent2_range_arg1 = get_entity_range(sent2_idx[0], orig_to_tok_map)\n",
    "        sent2_range_arg2 = get_entity_range(sent2_idx[1], orig_to_tok_map)\n",
    "        range_sent1 = (sent1_range_arg1,sent1_range_arg2)\n",
    "        range_sent2 = (sent2_range_arg1,sent2_range_arg2)\n",
    "        loss, argsort = self.forward_with_loss_calculation2(bert_tokens, tokens_tensor, range_sent1, range_sent2, orig_to_tok_map, l, l_tokens)\n",
    "        #loss, argsort = self.forward_with_loss_calculation(tokens_tensor, sent1_idx, sent2_idx, orig_to_tok_map, tok_to_orig_map, l, l_tokens)\n",
    "\n",
    "        return {'val_loss': loss}\n",
    "    \n",
    "    def validation_end(self, outputs):\n",
    "        avg_loss = torch.stack([x['val_loss'] for x in outputs]).mean()\n",
    "        print(\"Loss is {}\".format(avg_loss))\n",
    "        return {'avg_val_loss': avg_loss}\n",
    "    \n",
    "    def configure_optimizers(self):\n",
    "        #return torch.optim.RMSprop(self.parameters())\n",
    "        #return torch.optim.ASGD(self.parameters())\n",
    "        return torch.optim.SGD(self.parameters(), lr=0.01, momentum=0.75)\n",
    "        #return torch.optim.Adam(self.parameters())\n",
    "    \n",
    "    @pl.data_loader\n",
    "    def train_dataloader(self):\n",
    "        return self.train_gen\n",
    "\n",
    "    @pl.data_loader\n",
    "    def val_dataloader(self):\n",
    "        # OPTIONAL\n",
    "        # can also return a list of val dataloaders\n",
    "        return self.dev_gen\n",
    "    \n",
    "\n",
    "def get_entity_range(index_orig, orig_to_tok_map):\n",
    "    \n",
    "    m = min(orig_to_tok_map.keys())\n",
    "    if orig_to_tok_map[index_orig] == 1: return (1,2)\n",
    "    if index_orig == 0: return (1, orig_to_tok_map[index_orig] + 1)\n",
    "    \n",
    "    before = index_orig - 1\n",
    "    tok_range = (orig_to_tok_map[before] + 1, orig_to_tok_map[index_orig] + 1)\n",
    "    return tok_range\n",
    "\n",
    "\n",
    "def get_tok_to_orig_map(orig_to_tok_map, num_words, num_tokens):\n",
    "    \n",
    "    ranges = [get_entity_range(i, orig_to_tok_map) for i in range(num_words)]\n",
    "    tok_to_orig_map = {}\n",
    "    for i in range(num_words):\n",
    "        min,max = ranges[i]\n",
    "        for tok in range(min,max):\n",
    "            tok_to_orig_map[tok] = i\n",
    "    \n",
    "    for tok in range(num_tokens):\n",
    "        if tok not in tok_to_orig_map:\n",
    "            tok_to_orig_map[tok] = num_words -1\n",
    "    \n",
    "    return tok_to_orig_map\n",
    "        \n",
    "\n",
    "def get_prediction(sent1, sent2, model):\n",
    "    \n",
    "    l = len(sent1.split(\" \")) + 1 \n",
    "    sent2 = sent2.replace(\"ARG1:\", \"\").replace(\"ARG2:\", \"\")\n",
    "    \n",
    "    sents_concat = sent1 + \" ***** \" + sent2\n",
    "    sent1_arg1 = [i for i,w in enumerate(sent1.split(\" \")) if \"ARG1:\" in w][0]\n",
    "    sent1_arg2 = [i for i,w in enumerate(sent1.split(\" \")) if \"ARG2:\" in w][0]\n",
    "    words = sents_concat.split(\" \")\n",
    "    \n",
    "    bert_tokens, orig_to_tok_map, tok_to_orig_map, tokens_tensor = model.tokenize(sents_concat.split(\" \"))\n",
    "    range_arg1 = get_entity_range(sent1_arg1, orig_to_tok_map)\n",
    "    range_arg2 = get_entity_range(sent1_arg2, orig_to_tok_map)\n",
    "    \n",
    "    l_tokens = len(bert_tokens[:orig_to_tok_map[l-1]])    \n",
    "    outputs = model.model(tokens_tensor)\n",
    "    states = outputs[0][0] #[seq_len, 768]\n",
    "\n",
    "    states = states/torch.norm(states, dim = 1, keepdim = True)\n",
    "    \n",
    "    sent1_arg1_vec, sent1_arg2_vec = states[range_arg1[0]:range_arg1[1]].mean(dim=0), states[range_arg2[0]:range_arg2[1]].mean(dim=0)\n",
    "    \n",
    "    print(\"GOLD ARG1, ARG2:\", bert_tokens[orig_to_tok_map[sent1_arg1]], bert_tokens[orig_to_tok_map[sent1_arg2]])\n",
    "    sims_arg1 = (model.linear_arg1_1(states)-model.linear_arg1_2(sent1_arg1_vec)).norm(dim=1)\n",
    "    sims_arg2 = (model.linear_arg2_1(states)-model.linear_arg2_2(sent1_arg2_vec)).norm(dim=1)\n",
    "\n",
    "    mask_gold_arg1 = torch.zeros_like(sims_arg1).to(model.device)\n",
    "    mask_gold_arg2 = torch.zeros_like(sims_arg2).to(model.device)\n",
    "    #mask_gold_arg1[range_arg1[0]:range_arg1[1]] = 1e6\n",
    "    #mask_gold_arg2[range_arg2[0]:range_arg2[1]] = 1e6\n",
    "    mask_gold_arg2[:l_tokens] = 1e6\n",
    "    mask_gold_arg1[:l_tokens] = 1e6\n",
    "        \n",
    "    idx_arg1 = torch.argsort(sims_arg1+mask_gold_arg1).detach().cpu().numpy()\n",
    "    idx_arg2 = torch.argsort(sims_arg2+mask_gold_arg2).detach().cpu().numpy()\n",
    "    \n",
    "    print(\"all arg1 preds\", [words[tok_to_orig_map[idx_arg1[i]]] for i in range(len(idx_arg1))][:7])\n",
    "    print(\"---------------------------------------------------\")\n",
    "    print(\"all arg2 preds\", [words[tok_to_orig_map[idx_arg2[i]]] for i in range(len(idx_arg2))][:7])\n",
    "    print(\"---------------------------------------------------\")\n",
    "    \n",
    "    #print(bert_tokens[idx_arg1[-4]], bert_tokens[idx_arg2[-4]])\n",
    "    \n",
    "    return\n",
    "    \n",
    "    most_sim_arg1, most_sim_arg2 = sims_arg1[idx_arg1[-2]], sims_arg2[idx_arg2[-2]]\n",
    "    ind_arg1, ind_arg2 = idx_arg1[-2].detach().cpu().numpy().item(), idx_arg2[-2].detach().cpu().numpy().item()\n",
    "    ind_arg1, ind_arg2 = ind_arg1 + l_tokens, ind_arg2 + l_tokens\n",
    "    \n",
    "    return sents_concat, tok_to_orig_map[ind_arg1], tok_to_orig_map[ind_arg2], bert_tokens[ind_arg1], bert_tokens[ind_arg2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Dataset(torch.utils.data.Dataset):\n",
    "    \"\"\"Simple torch dataset class\"\"\"\n",
    "\n",
    "    def __init__(self, data: List[Dict], device = \"cpu\"):\n",
    "\n",
    "        self.data = data\n",
    "        self.device = device\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.data)\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "        with torch.no_grad():\n",
    "            \n",
    "            d = self.data[index]\n",
    "            sent1, sent2 = d[\"first\"], d[\"second\"]\n",
    "            sent1_arg1, sent1_arg2 = d[\"first_arg1\"][0], d[\"first_arg2\"][0]\n",
    "            sent2_arg1, sent2_arg2 = d[\"second_arg1\"][0], d[\"second_arg2\"][0]\n",
    "            \n",
    "            l = len(sent1.split(\" \")) + 1 \n",
    "            sent2_arg1, sent2_arg2 = sent2_arg1 + l, sent2_arg2 + l\n",
    "\n",
    "            sent2 = sent2.replace(\"ARG1:\", \"\").replace(\"ARG2:\", \"\")\n",
    "            sents_concat = sent1 + \" ***** \" + sent2 #sents_concat.split(\" \")[l] is the first token in the 2nd sent\n",
    "            \n",
    "            return sents_concat, (sent1_arg1, sent1_arg2), (sent2_arg1, sent2_arg2), l"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [],
   "source": [
    "l = int(0.8 * len(data))\n",
    "train_dataset, dev_dataset = Dataset(data[:l], \"cpu\"), Dataset(data[l:], \"cpu\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "sents_concat, (sent1_arg1, sent1_arg2), (sent2_arg1, sent2_arg2), l = train_dataset[5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [],
   "source": [
    "del model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = BertModel(train_dataset, dev_dataset, 1, \"cuda\", \"train\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sent = \"it is very important.\"\n",
    "bert_tokens, orig_to_tok_map, tok_to_orig_map, tokens_tensor = model.tokenize(sent.split(\" \"))\n",
    "indexed_tokens = model.tokenizer.convert_tokens_to_ids(bert_tokens)\n",
    "tokens_tensor = torch.tensor([indexed_tokens])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bert_tokens"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "orig_to_tok_map"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tok_to_orig_map"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2020-11-01 11:57:02.033 INFO    lightning: GPU available: True, used: True\n",
      "2020-11-01 11:57:02.034 INFO    lightning: CUDA_VISIBLE_DEVICES: [0]\n",
      "2020-11-01 11:57:02.140 INFO    lightning: \n",
      "    | Name                                              | Type              | Params\n",
      "------------------------------------------------------------------------------------\n",
      "0   | model                                             | BertModel         | 109 M \n",
      "1   | model.embeddings                                  | BertEmbeddings    | 24 M  \n",
      "2   | model.embeddings.word_embeddings                  | Embedding         | 23 M  \n",
      "3   | model.embeddings.position_embeddings              | Embedding         | 393 K \n",
      "4   | model.embeddings.token_type_embeddings            | Embedding         | 1 K   \n",
      "5   | model.embeddings.LayerNorm                        | LayerNorm         | 1 K   \n",
      "6   | model.embeddings.dropout                          | Dropout           | 0     \n",
      "7   | model.encoder                                     | BertEncoder       | 85 M  \n",
      "8   | model.encoder.layer                               | ModuleList        | 85 M  \n",
      "9   | model.encoder.layer.0                             | BertLayer         | 7 M   \n",
      "10  | model.encoder.layer.0.attention                   | BertAttention     | 2 M   \n",
      "11  | model.encoder.layer.0.attention.self              | BertSelfAttention | 1 M   \n",
      "12  | model.encoder.layer.0.attention.self.query        | Linear            | 590 K \n",
      "13  | model.encoder.layer.0.attention.self.key          | Linear            | 590 K \n",
      "14  | model.encoder.layer.0.attention.self.value        | Linear            | 590 K \n",
      "15  | model.encoder.layer.0.attention.self.dropout      | Dropout           | 0     \n",
      "16  | model.encoder.layer.0.attention.output            | BertSelfOutput    | 592 K \n",
      "17  | model.encoder.layer.0.attention.output.dense      | Linear            | 590 K \n",
      "18  | model.encoder.layer.0.attention.output.LayerNorm  | LayerNorm         | 1 K   \n",
      "19  | model.encoder.layer.0.attention.output.dropout    | Dropout           | 0     \n",
      "20  | model.encoder.layer.0.intermediate                | BertIntermediate  | 2 M   \n",
      "21  | model.encoder.layer.0.intermediate.dense          | Linear            | 2 M   \n",
      "22  | model.encoder.layer.0.output                      | BertOutput        | 2 M   \n",
      "23  | model.encoder.layer.0.output.dense                | Linear            | 2 M   \n",
      "24  | model.encoder.layer.0.output.LayerNorm            | LayerNorm         | 1 K   \n",
      "25  | model.encoder.layer.0.output.dropout              | Dropout           | 0     \n",
      "26  | model.encoder.layer.1                             | BertLayer         | 7 M   \n",
      "27  | model.encoder.layer.1.attention                   | BertAttention     | 2 M   \n",
      "28  | model.encoder.layer.1.attention.self              | BertSelfAttention | 1 M   \n",
      "29  | model.encoder.layer.1.attention.self.query        | Linear            | 590 K \n",
      "30  | model.encoder.layer.1.attention.self.key          | Linear            | 590 K \n",
      "31  | model.encoder.layer.1.attention.self.value        | Linear            | 590 K \n",
      "32  | model.encoder.layer.1.attention.self.dropout      | Dropout           | 0     \n",
      "33  | model.encoder.layer.1.attention.output            | BertSelfOutput    | 592 K \n",
      "34  | model.encoder.layer.1.attention.output.dense      | Linear            | 590 K \n",
      "35  | model.encoder.layer.1.attention.output.LayerNorm  | LayerNorm         | 1 K   \n",
      "36  | model.encoder.layer.1.attention.output.dropout    | Dropout           | 0     \n",
      "37  | model.encoder.layer.1.intermediate                | BertIntermediate  | 2 M   \n",
      "38  | model.encoder.layer.1.intermediate.dense          | Linear            | 2 M   \n",
      "39  | model.encoder.layer.1.output                      | BertOutput        | 2 M   \n",
      "40  | model.encoder.layer.1.output.dense                | Linear            | 2 M   \n",
      "41  | model.encoder.layer.1.output.LayerNorm            | LayerNorm         | 1 K   \n",
      "42  | model.encoder.layer.1.output.dropout              | Dropout           | 0     \n",
      "43  | model.encoder.layer.2                             | BertLayer         | 7 M   \n",
      "44  | model.encoder.layer.2.attention                   | BertAttention     | 2 M   \n",
      "45  | model.encoder.layer.2.attention.self              | BertSelfAttention | 1 M   \n",
      "46  | model.encoder.layer.2.attention.self.query        | Linear            | 590 K \n",
      "47  | model.encoder.layer.2.attention.self.key          | Linear            | 590 K \n",
      "48  | model.encoder.layer.2.attention.self.value        | Linear            | 590 K \n",
      "49  | model.encoder.layer.2.attention.self.dropout      | Dropout           | 0     \n",
      "50  | model.encoder.layer.2.attention.output            | BertSelfOutput    | 592 K \n",
      "51  | model.encoder.layer.2.attention.output.dense      | Linear            | 590 K \n",
      "52  | model.encoder.layer.2.attention.output.LayerNorm  | LayerNorm         | 1 K   \n",
      "53  | model.encoder.layer.2.attention.output.dropout    | Dropout           | 0     \n",
      "54  | model.encoder.layer.2.intermediate                | BertIntermediate  | 2 M   \n",
      "55  | model.encoder.layer.2.intermediate.dense          | Linear            | 2 M   \n",
      "56  | model.encoder.layer.2.output                      | BertOutput        | 2 M   \n",
      "57  | model.encoder.layer.2.output.dense                | Linear            | 2 M   \n",
      "58  | model.encoder.layer.2.output.LayerNorm            | LayerNorm         | 1 K   \n",
      "59  | model.encoder.layer.2.output.dropout              | Dropout           | 0     \n",
      "60  | model.encoder.layer.3                             | BertLayer         | 7 M   \n",
      "61  | model.encoder.layer.3.attention                   | BertAttention     | 2 M   \n",
      "62  | model.encoder.layer.3.attention.self              | BertSelfAttention | 1 M   \n",
      "63  | model.encoder.layer.3.attention.self.query        | Linear            | 590 K \n",
      "64  | model.encoder.layer.3.attention.self.key          | Linear            | 590 K \n",
      "65  | model.encoder.layer.3.attention.self.value        | Linear            | 590 K \n",
      "66  | model.encoder.layer.3.attention.self.dropout      | Dropout           | 0     \n",
      "67  | model.encoder.layer.3.attention.output            | BertSelfOutput    | 592 K \n",
      "68  | model.encoder.layer.3.attention.output.dense      | Linear            | 590 K \n",
      "69  | model.encoder.layer.3.attention.output.LayerNorm  | LayerNorm         | 1 K   \n",
      "70  | model.encoder.layer.3.attention.output.dropout    | Dropout           | 0     \n",
      "71  | model.encoder.layer.3.intermediate                | BertIntermediate  | 2 M   \n",
      "72  | model.encoder.layer.3.intermediate.dense          | Linear            | 2 M   \n",
      "73  | model.encoder.layer.3.output                      | BertOutput        | 2 M   \n",
      "74  | model.encoder.layer.3.output.dense                | Linear            | 2 M   \n",
      "75  | model.encoder.layer.3.output.LayerNorm            | LayerNorm         | 1 K   \n",
      "76  | model.encoder.layer.3.output.dropout              | Dropout           | 0     \n",
      "77  | model.encoder.layer.4                             | BertLayer         | 7 M   \n",
      "78  | model.encoder.layer.4.attention                   | BertAttention     | 2 M   \n",
      "79  | model.encoder.layer.4.attention.self              | BertSelfAttention | 1 M   \n",
      "80  | model.encoder.layer.4.attention.self.query        | Linear            | 590 K \n",
      "81  | model.encoder.layer.4.attention.self.key          | Linear            | 590 K \n",
      "82  | model.encoder.layer.4.attention.self.value        | Linear            | 590 K \n",
      "83  | model.encoder.layer.4.attention.self.dropout      | Dropout           | 0     \n",
      "84  | model.encoder.layer.4.attention.output            | BertSelfOutput    | 592 K \n",
      "85  | model.encoder.layer.4.attention.output.dense      | Linear            | 590 K \n",
      "86  | model.encoder.layer.4.attention.output.LayerNorm  | LayerNorm         | 1 K   \n",
      "87  | model.encoder.layer.4.attention.output.dropout    | Dropout           | 0     \n",
      "88  | model.encoder.layer.4.intermediate                | BertIntermediate  | 2 M   \n",
      "89  | model.encoder.layer.4.intermediate.dense          | Linear            | 2 M   \n",
      "90  | model.encoder.layer.4.output                      | BertOutput        | 2 M   \n",
      "91  | model.encoder.layer.4.output.dense                | Linear            | 2 M   \n",
      "92  | model.encoder.layer.4.output.LayerNorm            | LayerNorm         | 1 K   \n",
      "93  | model.encoder.layer.4.output.dropout              | Dropout           | 0     \n",
      "94  | model.encoder.layer.5                             | BertLayer         | 7 M   \n",
      "95  | model.encoder.layer.5.attention                   | BertAttention     | 2 M   \n",
      "96  | model.encoder.layer.5.attention.self              | BertSelfAttention | 1 M   \n",
      "97  | model.encoder.layer.5.attention.self.query        | Linear            | 590 K \n",
      "98  | model.encoder.layer.5.attention.self.key          | Linear            | 590 K \n",
      "99  | model.encoder.layer.5.attention.self.value        | Linear            | 590 K \n",
      "100 | model.encoder.layer.5.attention.self.dropout      | Dropout           | 0     \n",
      "101 | model.encoder.layer.5.attention.output            | BertSelfOutput    | 592 K \n",
      "102 | model.encoder.layer.5.attention.output.dense      | Linear            | 590 K \n",
      "103 | model.encoder.layer.5.attention.output.LayerNorm  | LayerNorm         | 1 K   \n",
      "104 | model.encoder.layer.5.attention.output.dropout    | Dropout           | 0     \n",
      "105 | model.encoder.layer.5.intermediate                | BertIntermediate  | 2 M   \n",
      "106 | model.encoder.layer.5.intermediate.dense          | Linear            | 2 M   \n",
      "107 | model.encoder.layer.5.output                      | BertOutput        | 2 M   \n",
      "108 | model.encoder.layer.5.output.dense                | Linear            | 2 M   \n",
      "109 | model.encoder.layer.5.output.LayerNorm            | LayerNorm         | 1 K   \n",
      "110 | model.encoder.layer.5.output.dropout              | Dropout           | 0     \n",
      "111 | model.encoder.layer.6                             | BertLayer         | 7 M   \n",
      "112 | model.encoder.layer.6.attention                   | BertAttention     | 2 M   \n",
      "113 | model.encoder.layer.6.attention.self              | BertSelfAttention | 1 M   \n",
      "114 | model.encoder.layer.6.attention.self.query        | Linear            | 590 K \n",
      "115 | model.encoder.layer.6.attention.self.key          | Linear            | 590 K \n",
      "116 | model.encoder.layer.6.attention.self.value        | Linear            | 590 K \n",
      "117 | model.encoder.layer.6.attention.self.dropout      | Dropout           | 0     \n",
      "118 | model.encoder.layer.6.attention.output            | BertSelfOutput    | 592 K \n",
      "119 | model.encoder.layer.6.attention.output.dense      | Linear            | 590 K \n",
      "120 | model.encoder.layer.6.attention.output.LayerNorm  | LayerNorm         | 1 K   \n",
      "121 | model.encoder.layer.6.attention.output.dropout    | Dropout           | 0     \n",
      "122 | model.encoder.layer.6.intermediate                | BertIntermediate  | 2 M   \n",
      "123 | model.encoder.layer.6.intermediate.dense          | Linear            | 2 M   \n",
      "124 | model.encoder.layer.6.output                      | BertOutput        | 2 M   \n",
      "125 | model.encoder.layer.6.output.dense                | Linear            | 2 M   \n",
      "126 | model.encoder.layer.6.output.LayerNorm            | LayerNorm         | 1 K   \n",
      "127 | model.encoder.layer.6.output.dropout              | Dropout           | 0     \n",
      "128 | model.encoder.layer.7                             | BertLayer         | 7 M   \n",
      "129 | model.encoder.layer.7.attention                   | BertAttention     | 2 M   \n",
      "130 | model.encoder.layer.7.attention.self              | BertSelfAttention | 1 M   \n",
      "131 | model.encoder.layer.7.attention.self.query        | Linear            | 590 K \n",
      "132 | model.encoder.layer.7.attention.self.key          | Linear            | 590 K \n",
      "133 | model.encoder.layer.7.attention.self.value        | Linear            | 590 K \n",
      "134 | model.encoder.layer.7.attention.self.dropout      | Dropout           | 0     \n",
      "135 | model.encoder.layer.7.attention.output            | BertSelfOutput    | 592 K \n",
      "136 | model.encoder.layer.7.attention.output.dense      | Linear            | 590 K \n",
      "137 | model.encoder.layer.7.attention.output.LayerNorm  | LayerNorm         | 1 K   \n",
      "138 | model.encoder.layer.7.attention.output.dropout    | Dropout           | 0     \n",
      "139 | model.encoder.layer.7.intermediate                | BertIntermediate  | 2 M   \n",
      "140 | model.encoder.layer.7.intermediate.dense          | Linear            | 2 M   \n",
      "141 | model.encoder.layer.7.output                      | BertOutput        | 2 M   \n",
      "142 | model.encoder.layer.7.output.dense                | Linear            | 2 M   \n",
      "143 | model.encoder.layer.7.output.LayerNorm            | LayerNorm         | 1 K   \n",
      "144 | model.encoder.layer.7.output.dropout              | Dropout           | 0     \n",
      "145 | model.encoder.layer.8                             | BertLayer         | 7 M   \n",
      "146 | model.encoder.layer.8.attention                   | BertAttention     | 2 M   \n",
      "147 | model.encoder.layer.8.attention.self              | BertSelfAttention | 1 M   \n",
      "148 | model.encoder.layer.8.attention.self.query        | Linear            | 590 K \n",
      "149 | model.encoder.layer.8.attention.self.key          | Linear            | 590 K \n",
      "150 | model.encoder.layer.8.attention.self.value        | Linear            | 590 K \n",
      "151 | model.encoder.layer.8.attention.self.dropout      | Dropout           | 0     \n",
      "152 | model.encoder.layer.8.attention.output            | BertSelfOutput    | 592 K \n",
      "153 | model.encoder.layer.8.attention.output.dense      | Linear            | 590 K \n",
      "154 | model.encoder.layer.8.attention.output.LayerNorm  | LayerNorm         | 1 K   \n",
      "155 | model.encoder.layer.8.attention.output.dropout    | Dropout           | 0     \n",
      "156 | model.encoder.layer.8.intermediate                | BertIntermediate  | 2 M   \n",
      "157 | model.encoder.layer.8.intermediate.dense          | Linear            | 2 M   \n",
      "158 | model.encoder.layer.8.output                      | BertOutput        | 2 M   \n",
      "159 | model.encoder.layer.8.output.dense                | Linear            | 2 M   \n",
      "160 | model.encoder.layer.8.output.LayerNorm            | LayerNorm         | 1 K   \n",
      "161 | model.encoder.layer.8.output.dropout              | Dropout           | 0     \n",
      "162 | model.encoder.layer.9                             | BertLayer         | 7 M   \n",
      "163 | model.encoder.layer.9.attention                   | BertAttention     | 2 M   \n",
      "164 | model.encoder.layer.9.attention.self              | BertSelfAttention | 1 M   \n",
      "165 | model.encoder.layer.9.attention.self.query        | Linear            | 590 K \n",
      "166 | model.encoder.layer.9.attention.self.key          | Linear            | 590 K \n",
      "167 | model.encoder.layer.9.attention.self.value        | Linear            | 590 K \n",
      "168 | model.encoder.layer.9.attention.self.dropout      | Dropout           | 0     \n",
      "169 | model.encoder.layer.9.attention.output            | BertSelfOutput    | 592 K \n",
      "170 | model.encoder.layer.9.attention.output.dense      | Linear            | 590 K \n",
      "171 | model.encoder.layer.9.attention.output.LayerNorm  | LayerNorm         | 1 K   \n",
      "172 | model.encoder.layer.9.attention.output.dropout    | Dropout           | 0     \n",
      "173 | model.encoder.layer.9.intermediate                | BertIntermediate  | 2 M   \n",
      "174 | model.encoder.layer.9.intermediate.dense          | Linear            | 2 M   \n",
      "175 | model.encoder.layer.9.output                      | BertOutput        | 2 M   \n",
      "176 | model.encoder.layer.9.output.dense                | Linear            | 2 M   \n",
      "177 | model.encoder.layer.9.output.LayerNorm            | LayerNorm         | 1 K   \n",
      "178 | model.encoder.layer.9.output.dropout              | Dropout           | 0     \n",
      "179 | model.encoder.layer.10                            | BertLayer         | 7 M   \n",
      "180 | model.encoder.layer.10.attention                  | BertAttention     | 2 M   \n",
      "181 | model.encoder.layer.10.attention.self             | BertSelfAttention | 1 M   \n",
      "182 | model.encoder.layer.10.attention.self.query       | Linear            | 590 K \n",
      "183 | model.encoder.layer.10.attention.self.key         | Linear            | 590 K \n",
      "184 | model.encoder.layer.10.attention.self.value       | Linear            | 590 K \n",
      "185 | model.encoder.layer.10.attention.self.dropout     | Dropout           | 0     \n",
      "186 | model.encoder.layer.10.attention.output           | BertSelfOutput    | 592 K \n",
      "187 | model.encoder.layer.10.attention.output.dense     | Linear            | 590 K \n",
      "188 | model.encoder.layer.10.attention.output.LayerNorm | LayerNorm         | 1 K   \n",
      "189 | model.encoder.layer.10.attention.output.dropout   | Dropout           | 0     \n",
      "190 | model.encoder.layer.10.intermediate               | BertIntermediate  | 2 M   \n",
      "191 | model.encoder.layer.10.intermediate.dense         | Linear            | 2 M   \n",
      "192 | model.encoder.layer.10.output                     | BertOutput        | 2 M   \n",
      "193 | model.encoder.layer.10.output.dense               | Linear            | 2 M   \n",
      "194 | model.encoder.layer.10.output.LayerNorm           | LayerNorm         | 1 K   \n",
      "195 | model.encoder.layer.10.output.dropout             | Dropout           | 0     \n",
      "196 | model.encoder.layer.11                            | BertLayer         | 7 M   \n",
      "197 | model.encoder.layer.11.attention                  | BertAttention     | 2 M   \n",
      "198 | model.encoder.layer.11.attention.self             | BertSelfAttention | 1 M   \n",
      "199 | model.encoder.layer.11.attention.self.query       | Linear            | 590 K \n",
      "200 | model.encoder.layer.11.attention.self.key         | Linear            | 590 K \n",
      "201 | model.encoder.layer.11.attention.self.value       | Linear            | 590 K \n",
      "202 | model.encoder.layer.11.attention.self.dropout     | Dropout           | 0     \n",
      "203 | model.encoder.layer.11.attention.output           | BertSelfOutput    | 592 K \n",
      "204 | model.encoder.layer.11.attention.output.dense     | Linear            | 590 K \n",
      "205 | model.encoder.layer.11.attention.output.LayerNorm | LayerNorm         | 1 K   \n",
      "206 | model.encoder.layer.11.attention.output.dropout   | Dropout           | 0     \n",
      "207 | model.encoder.layer.11.intermediate               | BertIntermediate  | 2 M   \n",
      "208 | model.encoder.layer.11.intermediate.dense         | Linear            | 2 M   \n",
      "209 | model.encoder.layer.11.output                     | BertOutput        | 2 M   \n",
      "210 | model.encoder.layer.11.output.dense               | Linear            | 2 M   \n",
      "211 | model.encoder.layer.11.output.LayerNorm           | LayerNorm         | 1 K   \n",
      "212 | model.encoder.layer.11.output.dropout             | Dropout           | 0     \n",
      "213 | model.pooler                                      | BertPooler        | 590 K \n",
      "214 | model.pooler.dense                                | Linear            | 590 K \n",
      "215 | model.pooler.activation                           | Tanh              | 0     \n",
      "216 | linear_arg1_1                                     | Linear            | 98 K  \n",
      "217 | linear_arg2_1                                     | Linear            | 98 K  \n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=1.0, bar_style='info', description='Validation sanity check', layout=Layout…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss is 0.05623554065823555\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4d62f425c5a240929fb147327f06d620",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=1.0, bar_style='info', description='Training', layout=Layout(flex='2'), max…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "count 0.394\n",
      "count 0.472\n",
      "count 0.512\n",
      "count 0.53075\n",
      "count 0.5502\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=1.0, bar_style='info', description='Validating', layout=Layout(flex='2'), m…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss is 0.006185966543853283\n",
      "count 0.584\n",
      "count 0.601125\n",
      "count 0.6158888888888889\n",
      "count 0.6263\n",
      "count 0.6368181818181818\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=1.0, bar_style='info', description='Validating', layout=Layout(flex='2'), m…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss is 0.0044884891249239445\n",
      "count 0.6524615384615384\n",
      "count 0.6622142857142858\n",
      "count 0.6709333333333334\n",
      "count 0.678125\n",
      "count 0.6859411764705883\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=1.0, bar_style='info', description='Validating', layout=Layout(flex='2'), m…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss is 0.0043035708367824554\n",
      "count 0.6917368421052632\n",
      "count 0.6995\n",
      "count 0.7053333333333334\n",
      "count 0.7119090909090909\n",
      "count 0.716391304347826\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=1.0, bar_style='info', description='Validating', layout=Layout(flex='2'), m…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss is 0.003982427064329386\n",
      "count 0.7265769230769231\n",
      "count 0.7315185185185186\n",
      "count 0.7366785714285714\n",
      "count 0.7408275862068966\n",
      "count 0.7443666666666666\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=1.0, bar_style='info', description='Validating', layout=Layout(flex='2'), m…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss is 0.004099777899682522\n",
      "count 0.7468125\n",
      "count 0.7511515151515151\n",
      "count 0.7543823529411765\n",
      "count 0.7575428571428572\n",
      "count 0.7609444444444444\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=1.0, bar_style='info', description='Validating', layout=Layout(flex='2'), m…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss is 0.0040786387398839\n",
      "count 0.7632368421052631\n",
      "count 0.7667948717948718\n",
      "count 0.769975\n",
      "count 0.7729512195121951\n",
      "count 0.7758809523809523\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=1.0, bar_style='info', description='Validating', layout=Layout(flex='2'), m…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss is 0.004013692028820515\n",
      "count 0.7809333333333334\n",
      "count 0.7837391304347826\n",
      "count 0.786468085106383\n",
      "count 0.7892291666666666\n",
      "count 0.7915102040816326\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=1.0, bar_style='info', description='Validating', layout=Layout(flex='2'), m…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss is 0.0038351286202669144\n",
      "count 0.7932941176470588\n",
      "count 0.7960769230769231\n",
      "count 0.7986603773584906\n",
      "count 0.8006481481481481\n",
      "count 0.8028181818181818\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=1.0, bar_style='info', description='Validating', layout=Layout(flex='2'), m…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss is 0.003929525148123503\n",
      "count 0.8039649122807018\n",
      "count 0.8063793103448276\n",
      "count 0.8083728813559322\n",
      "count 0.8105166666666667\n",
      "count 0.8124098360655738\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=1.0, bar_style='info', description='Validating', layout=Layout(flex='2'), m…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss is 0.004197472240775824\n",
      "count 0.81525\n",
      "count 0.8170307692307692\n",
      "count 0.8188787878787879\n",
      "count 0.8205820895522388\n",
      "count 0.8223823529411765\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=1.0, bar_style='info', description='Validating', layout=Layout(flex='2'), m…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss is 0.003943850751966238\n",
      "count 0.8232714285714285\n",
      "count 0.8249718309859155\n",
      "count 0.8265833333333333\n",
      "count 0.8280958904109589\n",
      "count 0.829554054054054\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=1.0, bar_style='info', description='Validating', layout=Layout(flex='2'), m…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss is 0.004190321546047926\n",
      "count 0.8299078947368421\n",
      "count 0.8315194805194805\n",
      "count 0.8329871794871795\n",
      "count 0.8345569620253165\n",
      "count 0.835825\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=1.0, bar_style='info', description='Validating', layout=Layout(flex='2'), m…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss is 0.004109319299459457\n",
      "count 0.8361219512195122\n",
      "count 0.837578313253012\n",
      "count 0.8391071428571428\n",
      "count 0.8404\n",
      "count 0.8415\n",
      "count 0.8426781609195402\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=1.0, bar_style='info', description='Validating', layout=Layout(flex='2'), m…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss is 0.0042586373165249825\n",
      "count 0.8430112359550562\n",
      "count 0.8443\n",
      "count 0.8455824175824176\n",
      "count 0.8468586956521739\n",
      "count 0.8479247311827957\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=1.0, bar_style='info', description='Validating', layout=Layout(flex='2'), m…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss is 0.0044305105693638325\n",
      "count 0.8481157894736842\n",
      "count 0.8493333333333334\n",
      "count 0.8505051546391753\n",
      "count 0.8516020408163265\n",
      "count 0.8526363636363636\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=1.0, bar_style='info', description='Validating', layout=Layout(flex='2'), m…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss is 0.004474224988371134\n",
      "count 0.8524752475247525\n",
      "count 0.8536470588235294\n",
      "count 0.8547378640776699\n",
      "count 0.8559038461538462\n",
      "count 0.8568857142857143\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=1.0, bar_style='info', description='Validating', layout=Layout(flex='2'), m…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss is 0.004485065117478371\n",
      "count 0.8579166666666667\n",
      "count 0.8589082568807339\n",
      "count 0.8598454545454546\n",
      "count 0.8606396396396396\n",
      "count 0.8615714285714285\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=1.0, bar_style='info', description='Validating', layout=Layout(flex='2'), m…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss is 0.004813128616660833\n",
      "count 0.8613947368421052\n",
      "count 0.8623565217391305\n",
      "count 0.863301724137931\n",
      "count 0.8641880341880341\n",
      "count 0.8649745762711865\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=1.0, bar_style='info', description='Validating', layout=Layout(flex='2'), m…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss is 0.004747570492327213\n",
      "count 0.8648083333333333\n",
      "count 0.8657024793388429\n",
      "count 0.866516393442623\n",
      "count 0.8673414634146341\n",
      "count 0.8680887096774194\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=1.0, bar_style='info', description='Validating', layout=Layout(flex='2'), m…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss is 0.004559141118079424\n",
      "count 0.8687716535433071\n",
      "count 0.869609375\n",
      "count 0.8704108527131783\n",
      "count 0.8711923076923077\n",
      "count 0.8719541984732825\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=1.0, bar_style='info', description='Validating', layout=Layout(flex='2'), m…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss is 0.004539175424724817\n",
      "count 0.8719473684210526\n",
      "count 0.8726641791044776\n",
      "count 0.8733851851851852\n",
      "count 0.8741029411764706\n",
      "count 0.8747664233576642\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=1.0, bar_style='info', description='Validating', layout=Layout(flex='2'), m…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss is 0.00460453238338232\n",
      "count 0.8746043165467626\n",
      "count 0.8753071428571428\n",
      "count 0.8760567375886524\n",
      "count 0.876669014084507\n",
      "count 0.8773216783216783\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2020-11-01 12:56:20.410 INFO    lightning: Detected KeyboardInterrupt, attempting graceful shutdown...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "1"
      ]
     },
     "execution_count": 83,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#model.to(\"cpu\")\n",
    "#model.device = \"cpu\"\n",
    "trainer = Trainer(max_nb_epochs=50,min_nb_epochs=1, gpus = 1)\n",
    "trainer.fit(model)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## model.model.layers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "del model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The use of 5 % ARG1:dextrose and sodium bicarbonate is an effective initial treatment for ARG2:hyperkalemia .\n",
      "-------------------------------\n",
      "Cyclosporine is an immunosuppressant and is used to avoid organ transplant rejection .\n",
      "-------------------------------\n",
      "GOLD ARG1, ARG2: ##rose ##emia\n",
      "all arg1 preds ['an', 'Cyclosporine', 'is', 'transplant', 'organ', 'Cyclosporine', 'is']\n",
      "---------------------------------------------------\n",
      "all arg2 preds ['organ', 'avoid', 'Cyclosporine', '.', '*****', 'an', 'Cyclosporine']\n",
      "---------------------------------------------------\n",
      "===================================================\n",
      "Suppose that a fraction ARG1:Q of all infected individuals is completely isolated and does not transmit the disease to ARG2:anyone .\n",
      "-------------------------------\n",
      "Although the J class is isolated to a negative-pressure room , a few of its members could transmit the virus , by accident , to other people such as healthcare workers .\n",
      "-------------------------------\n",
      "GOLD ARG1, ARG2: q anyone\n",
      "all arg1 preds ['the', 'healthcare', 'few', 'a', 'the', 'a', 'its']\n",
      "---------------------------------------------------\n",
      "all arg2 preds ['the', 'J', 'a', 'healthcare', 'a', '.', 'other']\n",
      "---------------------------------------------------\n",
      "===================================================\n",
      "Moreover , the ARG1:pathogen also spreads to humans through direct ARG2:contact with infected poultry and contaminated surfaces [ 5 ] .\n",
      "-------------------------------\n",
      "The COVID-19 disease can spread in a population through infected symptomatic/asymptomatic individuals who come in contact directly/indirectly [ 4 ] .\n",
      "-------------------------------\n",
      "GOLD ARG1, ARG2: pathogen contact\n",
      "all arg1 preds ['The', 'disease', 'infected', 'symptomatic/asymptomatic', 'individuals', 'can', 'symptomatic/asymptomatic']\n",
      "---------------------------------------------------\n",
      "all arg2 preds ['.', 'The', 'symptomatic/asymptomatic', '*****', 'directly/indirectly', 'infected', 'COVID-19']\n",
      "---------------------------------------------------\n",
      "===================================================\n",
      "The low second trimester plasma MBL ARG1:level is not a risk factor for the development of ARG2:preterm birth .\n",
      "-------------------------------\n",
      "Nevertheless , even 5 - 10 years intervals from the previous gestation do not increase the risk for PE .\n",
      "-------------------------------\n",
      "GOLD ARG1, ARG2: level preterm\n",
      "all arg1 preds ['even', 'the', '5', 'Nevertheless', 'intervals', 'not', '.']\n",
      "---------------------------------------------------\n",
      "all arg2 preds ['PE', 'Nevertheless', '*****', 'the', 'even', 'previous', '.']\n",
      "---------------------------------------------------\n",
      "===================================================\n",
      "However , ARG1:glucose blood levels were reduced and insulin sensitivity was increased in ARG2:MTX2 and MTX4 .\n",
      "-------------------------------\n",
      "Both blood glucose and lipid profiles were reduced in the allogenic group [ 9 ] .\n",
      "-------------------------------\n",
      "GOLD ARG1, ARG2: glucose ##2\n",
      "all arg1 preds ['lipid', 'Both', 'blood', 'glucose', 'profiles', 'allogenic', 'the']\n",
      "---------------------------------------------------\n",
      "all arg2 preds ['the', 'allogenic', '*****', 'blood', '.', 'Both', 'lipid']\n",
      "---------------------------------------------------\n",
      "===================================================\n",
      "It seems likely that the prevention and treatment of ARG1:AEx of IPF must focus on both ARG2:disease-specific ( e.g. , anti-fi brotic therapies ) and non-disease-specific ( e.g. , vaccination , prevention of stress ) areas .\n",
      "-------------------------------\n",
      "Thus , the clinical management of SARS should consider not only antiviral but anti-inflammatory strategies as well .\n",
      "-------------------------------\n",
      "GOLD ARG1, ARG2: ##x specific\n",
      "all arg1 preds ['the', 'clinical', 'of', 'Thus', 'antiviral', 'should', 'management']\n",
      "---------------------------------------------------\n",
      "all arg2 preds ['SARS', '.', 'antiviral', '*****', 'Thus', 'anti-inflammatory', 'strategies']\n",
      "---------------------------------------------------\n",
      "===================================================\n",
      "The results indicate that supplementation of fish with ARG1:rosemary could improve the haematological and immunological properties and increase the survival rate after challenge with ARG2:S. iniae .\n",
      "-------------------------------\n",
      "Recent studies have demonstrated that prolonged treatment with EP can ameliorate experimental ulcerative colitis and slow multiple tumor growth .\n",
      "-------------------------------\n",
      "GOLD ARG1, ARG2: ##y .\n",
      "all arg1 preds ['EP', 'prolonged', 'treatment', 'Recent', 'with', 'ulcerative', 'experimental']\n",
      "---------------------------------------------------\n",
      "all arg2 preds ['EP', 'multiple', 'prolonged', 'slow', '*****', '.', 'ulcerative']\n",
      "---------------------------------------------------\n",
      "===================================================\n",
      "In 2013 , an outbreak of ARG1:MERS-CoV occurred in the ARG2:Middle East , including Jordan ( 10 , 11 ) .\n",
      "-------------------------------\n",
      "An outbreak of severe acute respiratory syndrome ( SARS ) was detected in Singapore at the beginning of March 2003 .\n",
      "-------------------------------\n",
      "GOLD ARG1, ARG2: cov middle\n",
      "all arg1 preds ['severe', 'March', 'An', 'Singapore', 'respiratory', 'was', 'outbreak']\n",
      "---------------------------------------------------\n",
      "all arg2 preds ['Singapore', '.', 'An', 'SARS', 'respiratory', 'the', 'severe']\n",
      "---------------------------------------------------\n",
      "===================================================\n",
      "In this study , we found that the functional mechanism of miR-21 action through ARG1:MyD88 and IRAK1 , which was also modulated by NS3/4A and NS5A protein expression , ARG2:could be another mechanism independent pathway of the TRIF pathway for impairing the type I IFN-associated antiviral response during HCV infection ( Figure S7 ) .\n",
      "-------------------------------\n",
      "1 The mechanism of action for these alkaloids is competitive inhibition of monoamine oxidase ( primarily MAO-A ) resulting in increased serotonin activity .\n",
      "-------------------------------\n",
      "GOLD ARG1, ARG2: ##88 could\n",
      "all arg1 preds ['these', 'primarily', 'competitive', '1', 'alkaloids', 'resulting', 'inhibition']\n",
      "---------------------------------------------------\n",
      "all arg2 preds ['alkaloids', '1', '*****', 'these', '.', 'The', 'competitive']\n",
      "---------------------------------------------------\n",
      "Patients with ARG1:inflammatory bowel disease are more susceptible to ARG2:severe viral infections requiring hospitalization regardless of treatment .\n",
      "-------------------------------\n",
      "Underlying asthma alone was more common among children with HRV infection and less common among children with influenza .\n",
      "-------------------------------\n",
      "GOLD ARG1, ARG2: inflammatory severe\n",
      "all arg1 preds ['Underlying', 'asthma', 'HRV', 'influenza', 'infection', '.', 'children']\n",
      "---------------------------------------------------\n",
      "all arg2 preds ['*****', 'Underlying', 'HRV', 'influenza', '.', 'children', 'asthma']\n",
      "---------------------------------------------------\n",
      "Presenting features of ARG1:cough and fever subacutely progress to respiratory distress and acute respiratory distress sydrome ( ARDS ) in 8 - 19 % of patients , with the elderly and those with underlying comorbidities especially cardiovascular disease , diabetes mellitus , ARG2:chronic pulmonary disorders or renal disease especially at risk https://www.epicentro.iss.it/coronavirus/bollettino/Report-COVID-2019_24_marzo_eng.pdf ( 42 ) ( 43 ) ( 44 ) ( 45 ) .\n",
      "-------------------------------\n",
      "INGOs and UN agencies have a paramount importance role in assisting the ministry of health technically and financially in training of health workers in malnutrition management at outpatient departments and inpatient therapeutic feeding units , Integrated Management of Neonatal and Child-hood Illnesses ( IMNCI ) , and surveillance system and responding to emergencies in the country 34 , 58 .\n",
      "-------------------------------\n",
      "GOLD ARG1, ARG2: cough chronic\n",
      "all arg1 preds ['outpatient', 'malnutrition', 'inpatient', 'health', 'feeding', 'the', 'management']\n",
      "---------------------------------------------------\n",
      "all arg2 preds ['*****', 'emergencies', 'malnutrition', 'health', 'INGOs', 'UN', '.']\n",
      "---------------------------------------------------\n",
      "ARG1:One novel reassortant H1N2 virus appeared to have emerged from ARG2:the A(H1N1)pdm09 virus was reported in swine in Gunma Prefecture while two other H1N2 viruses appeared to have emerged from the Japanese H1N2 viruses with internal genes from A(H1N1)pdm09 virus .\n",
      "-------------------------------\n",
      "Measles virus most closely resembles the rinderpest virus -a recently eradicated pathogen of cattle -and probably evolved from an ancestral virus as a zoonotic infection in communities in which cattle and humans lived in close proximity ( Moss and Griffi n 2006 ) .\n",
      "-------------------------------\n",
      "GOLD ARG1, ARG2: one the\n",
      "all arg1 preds ['Measles', 'a', '-a', 'the', 'cattle', 'most', '*****']\n",
      "---------------------------------------------------\n",
      "all arg2 preds ['*****', 'humans', 'an', 'the', '.', 'cattle', 'Measles']\n",
      "---------------------------------------------------\n",
      "ARG1:RDV is contraindicated in patients with ARG2:known hypersensitivity reactions .\n",
      "-------------------------------\n",
      "This is the reason why the most important international organizations recommend that the dentists adopt a unique preventive approach to the problem : SARS patients should not be treated in the dental office .\n",
      "-------------------------------\n",
      "GOLD ARG1, ARG2: ##v known\n",
      "all arg1 preds ['patients', 'the', ':', 'SARS', 'unique', 'international', 'This']\n",
      "---------------------------------------------------\n",
      "all arg2 preds ['SARS', '*****', '.', 'the', 'This', 'SARS', 'the']\n",
      "---------------------------------------------------\n",
      "ARG1:The 2009 H1N1 pandemic influenza virus emerged from ARG2:pigs as well , but only after complex exchanges of human , swine , and avian influenza genes [ 14 ] .\n",
      "-------------------------------\n",
      "Some new strains of corona viruses like SARS-CoV , MERS-CoV , and a recently identified COVID-2019 virus evolved from corona viruses which are zoonotic in origin and these types can cause cataclysmic ailment in human being .\n",
      "-------------------------------\n",
      "GOLD ARG1, ARG2: the pigs\n",
      "all arg1 preds ['a', 'Some', 'these', 'strains', 'new', 'and', 'identified']\n",
      "---------------------------------------------------\n",
      "all arg2 preds ['Some', 'corona', 'corona', 'zoonotic', 'a', 'COVID-2019', 'new']\n",
      "---------------------------------------------------\n",
      "Adults with ARG1:Down syndrome ( DS ) are particularly susceptible to ARG2:respiratory infections , and respiratory disease is a primary cause of death in individuals with DS over the age of 20 years .\n",
      "-------------------------------\n",
      "According to Wang et al. , 19 patients with severe ill are more prone to laboratory abnormalities , including increased leukocytes , decreased lymphocytes , abnormal liver function , abnormal coagulation function , and increased infection-related indicators , leading to ARDS , acute myocardial injury , acute liver injury , and shock .\n",
      "-------------------------------\n",
      "GOLD ARG1, ARG2: down respiratory\n",
      "all arg1 preds ['laboratory', 'ill', 'patients', 'leukocytes', 'severe', 'lymphocytes', 'infection-related']\n",
      "---------------------------------------------------\n",
      "all arg2 preds ['severe', 'acute', 'acute', 'ill', 'shock', 'ARDS', '*****']\n",
      "---------------------------------------------------\n",
      "Interestingly , we found ARG1:certain HLA genetic polymorphisms that could increase the risk of ARG2:death in patients COVID-19 .\n",
      "-------------------------------\n",
      "No individual SNP showed a significant association with either ALI or sepsis ; however , the carriers of the CC genotype ( rs755622 ) and the carriers of the TT genotype ( rs2070767 ) showed more than twofold increased risk of developing sepsis and ALI , respectively .\n",
      "-------------------------------\n",
      "GOLD ARG1, ARG2: certain death\n",
      "all arg1 preds ['the', 'the', 'the', 'ALI', 'the', 'sepsis', '.']\n",
      "---------------------------------------------------\n",
      "all arg2 preds ['sepsis', 'the', 'ALI', 'the', 'sepsis', 'No', 'ALI']\n",
      "---------------------------------------------------\n",
      "ARG1:Gene polymorphism of the binding domain of surfactant protein A-2 , SP-A2 at codon 223 , increases susceptibility to meningococcal disease , as well as the risk of ARG2:death .\n",
      "-------------------------------\n",
      "IL-10 rs1800872 polymorphism might be a risk factor for colorectal cancer development in European populations and the A/C allele of IL-10 rs1800872 might raise the risk for RA [ 46 , 47 ] .\n",
      "-------------------------------\n",
      "GOLD ARG1, ARG2: gene death\n",
      "all arg1 preds ['the', 'IL-10', 'A/C', 'colorectal', 'polymorphism', 'IL-10', 'RA']\n",
      "---------------------------------------------------\n",
      "all arg2 preds ['RA', 'the', 'colorectal', 'European', 'the', '*****', '.']\n",
      "---------------------------------------------------\n",
      "The ultimate treatment would be liver transplant , but ARG1:this is contraindicated in ARG2:patient with such short sobriety .\n",
      "-------------------------------\n",
      "This could leave us with only 1 antiviral class of drugs ( ie , neuraminidase inhibitors ) and no treatment option for infants , because oseltamivir is contraindicated in children less than 1 year of age based on a study , done by the manufacturer , showing increased central nervous system drug concentrations in a juvenile animal model .\n",
      "-------------------------------\n",
      "GOLD ARG1, ARG2: this patient\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "all arg1 preds ['This', 'infants', 'could', '.', 'age', 'neuraminidase', 'the']\n",
      "---------------------------------------------------\n",
      "all arg2 preds ['This', '.', 'children', '*****', 'no', 'infants', '1']\n",
      "---------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "k = random.choice(range(100))\n",
    "\n",
    "sent1 = \"The use of 5 % ARG1:dextrose and sodium bicarbonate is an effective initial treatment for ARG2:hyperkalemia .\"\n",
    "sent2 = \"Cyclosporine is an immunosuppressant and is used to avoid organ transplant rejection .\"\n",
    "\n",
    "with torch.no_grad():\n",
    "    print(sent1)\n",
    "    print(\"-------------------------------\")\n",
    "    print(sent2)\n",
    "    print(\"-------------------------------\")\n",
    "    get_prediction(sent1, sent2, model.eval())\n",
    "\n",
    "print(\"===================================================\")\n",
    "    \n",
    "    \n",
    "sent1 = \"Suppose that a fraction ARG1:Q of all infected individuals is completely isolated and does not transmit the disease to ARG2:anyone .\"\n",
    "sent2 = \"Although the J class is isolated to a negative-pressure room , a few of its members could transmit the virus , by accident , to other people such as healthcare workers .\"\n",
    "\n",
    "with torch.no_grad():\n",
    "    print(sent1)\n",
    "    print(\"-------------------------------\")\n",
    "    print(sent2)\n",
    "    print(\"-------------------------------\")\n",
    "    get_prediction(sent1, sent2, model.eval())\n",
    "    \n",
    "    \n",
    "print(\"===================================================\")\n",
    "    \n",
    "    \n",
    "sent1 = \"Moreover , the ARG1:pathogen also spreads to humans through direct ARG2:contact with infected poultry and contaminated surfaces [ 5 ] .\"\n",
    "sent2 = \"The COVID-19 disease can spread in a population through infected symptomatic/asymptomatic individuals who come in contact directly/indirectly [ 4 ] .\"\n",
    "\n",
    "with torch.no_grad():\n",
    "    print(sent1)\n",
    "    print(\"-------------------------------\")\n",
    "    print(sent2)\n",
    "    print(\"-------------------------------\")\n",
    "    get_prediction(sent1, sent2, model.eval())\n",
    "    \n",
    "    \n",
    "print(\"===================================================\")\n",
    "    \n",
    "    \n",
    "sent1 = \"The low second trimester plasma MBL ARG1:level is not a risk factor for the development of ARG2:preterm birth .\"\n",
    "sent2 = \"Nevertheless , even 5 - 10 years intervals from the previous gestation do not increase the risk for PE .\"\n",
    "\n",
    "with torch.no_grad():\n",
    "    print(sent1)\n",
    "    print(\"-------------------------------\")\n",
    "    print(sent2)\n",
    "    print(\"-------------------------------\")\n",
    "    get_prediction(sent1, sent2, model.eval())\n",
    "    \n",
    "    \n",
    "print(\"===================================================\")\n",
    "    \n",
    "    \n",
    "sent1 = \"However , ARG1:glucose blood levels were reduced and insulin sensitivity was increased in ARG2:MTX2 and MTX4 .\"\n",
    "sent2 = \"Both blood glucose and lipid profiles were reduced in the allogenic group [ 9 ] .\"\n",
    "\n",
    "with torch.no_grad():\n",
    "    print(sent1)\n",
    "    print(\"-------------------------------\")\n",
    "    print(sent2)\n",
    "    print(\"-------------------------------\")\n",
    "    get_prediction(sent1, sent2, model.eval())\n",
    "    \n",
    "    \n",
    "print(\"===================================================\")\n",
    "    \n",
    "    \n",
    "sent1 = \"It seems likely that the prevention and treatment of ARG1:AEx of IPF must focus on both ARG2:disease-specific ( e.g. , anti-fi brotic therapies ) and non-disease-specific ( e.g. , vaccination , prevention of stress ) areas .\"\n",
    "sent2 = \"Thus , the clinical management of SARS should consider not only antiviral but anti-inflammatory strategies as well .\"\n",
    "\n",
    "with torch.no_grad():\n",
    "    print(sent1)\n",
    "    print(\"-------------------------------\")\n",
    "    print(sent2)\n",
    "    print(\"-------------------------------\")\n",
    "    get_prediction(sent1, sent2, model.eval())\n",
    "    \n",
    "    \n",
    "    \n",
    "print(\"===================================================\")\n",
    "    \n",
    "    \n",
    "sent1 = \"The results indicate that supplementation of fish with ARG1:rosemary could improve the haematological and immunological properties and increase the survival rate after challenge with ARG2:S. iniae .\"\n",
    "sent2 = \"Recent studies have demonstrated that prolonged treatment with EP can ameliorate experimental ulcerative colitis and slow multiple tumor growth .\"\n",
    "\n",
    "with torch.no_grad():\n",
    "    print(sent1)\n",
    "    print(\"-------------------------------\")\n",
    "    print(sent2)\n",
    "    print(\"-------------------------------\")\n",
    "    get_prediction(sent1, sent2, model.eval())\n",
    "    \n",
    "    \n",
    "print(\"===================================================\")\n",
    "    \n",
    "    \n",
    "sent1 = \"In 2013 , an outbreak of ARG1:MERS-CoV occurred in the ARG2:Middle East , including Jordan ( 10 , 11 ) .\"\n",
    "sent2 = \"An outbreak of severe acute respiratory syndrome ( SARS ) was detected in Singapore at the beginning of March 2003 .\"\n",
    "\n",
    "with torch.no_grad():\n",
    "    print(sent1)\n",
    "    print(\"-------------------------------\")\n",
    "    print(sent2)\n",
    "    print(\"-------------------------------\")\n",
    "    get_prediction(sent1, sent2, model.eval())\n",
    "    \n",
    "    \n",
    "print(\"===================================================\")\n",
    "    \n",
    "\n",
    "for i in range(10):\n",
    "\n",
    "    sent1 = data[i][\"first\"]\n",
    "    sent2 = data[i][\"second\"].replace(\"ARG1:\", \"\").replace(\"ARG2:\",\"\")\n",
    "    with torch.no_grad():\n",
    "        print(sent1)\n",
    "        print(\"-------------------------------\")\n",
    "        print(sent2)\n",
    "        print(\"-------------------------------\")\n",
    "        get_prediction(sent1, sent2, model.eval())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "del model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.randn(1)*0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
